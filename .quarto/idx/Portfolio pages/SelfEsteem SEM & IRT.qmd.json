{"title":"Psychometric Properties of Self Esteem via SEM and IRT","markdown":{"yaml":{"title":"Psychometric Properties of Self Esteem via SEM and IRT","editor":"visual","author":"Matthew Swanson","categories":["Structural Equation Modeling","Item Response Theory","R","lavaan"],"format":{"html":{"page-layout":"full"}}},"headingText":"**Project Goal**","containsRefs":false,"markdown":"\n\n::: text-center\n:::\n\nThe data for this project was downloaded from Kaggle [here](https://www.kaggle.com/datasets/lucasgreenwell/rosenberg-self-esteem-scale-responses?select=data.csv) and originally housed on [OpenPsychometrics.org](https://openpsychometrics.org/). The data set contains approximately 48,000 participants who took the Rosenberg Self-Esteem Scale. Participant's gender, age, and country were also collected. This scale contains 10 items, of which five items are positively worded (Q1, Q2, Q4, Q6, & Q7) and five items are negatively worded (Q3, Q5, & Q8-10) on a 1-4 scale (anchors ranged from strongly disagree (1) to strongly agree (4)).\n\nFor this data, I will first compute descriptive values for the data set and then I will look at the psychometric properties of this data using both structural equation modeling (SEM) and Item Response Theory (IRT) principals.\n\n::: text-center\n# **Data Descriptive Analysis**\n:::\n\nFirst, I will load in the data and check for missing values. (Data file location is hidden from code chunk)\n\n```{r}\nlibrary(dplyr)\nData <- read.csv(\"C:/Users/matts/OneDrive/Desktop/002 Matt Desktop/WebsiteData/SelfEsteem Data/data.csv\", na.strings = \"\")\nsum(is.na(Data))\n```\n\nNo cells have been flagged as missing. However, the data originally coded all missing values as \"0\" so I will need to filter these values out to get complete responses before moving on to calculating data descriptives.\n\nNote: Original results suggest that there are four missing values in the data, however, looking at the rows that contain these four values, it becomes clear that r detected the country code of NA (Nambia) and incorrectly read those values as missing. I specified that the data be read in with the argument na.strings = \"\" to solve this problem and reloaded the data in.\n\n```{r}\nlibrary(psych)\nstr(Data) #checking for numeric status\nData_new <- Data[apply(Data!=0, 1, all),]\n#Get means, sd, and range\ndescribe(Data_new)\n```\n\nGlancing at the age row suggests that age ranged from 1 - 100,000 years of age, which is, of course, impossible. Thus, I will filter for a reasonable adult age range (18 - 100). This step is important as participants who reported being a single year old or 100,000 years old likely did not pay attention to other items in this scale and so I want to remove their responses.\n\n```{r}\nData_new <- Data_new %>%\n  filter(between(age, 18, 100))\ndescribe(Data_new)\nData_new %>%\n  count(Data_new$gender)\n```\n\nLooking at the means, most items hover around the mid point of the scale (between scores of 2-3). The average age of participants is 30 with a standard deviation of about 12 years and 59% of participants identify as female, 40% identify as male, and about 1% identify as non-binary.\n\n::: text-center\n## **Item Correlations**\n:::\n\nNow to calculate correlations between scale items and visualize them.\n\n```{r}\nlibrary(Hmisc)\nlibrary(corrplot)\nCorrelation <- rcorr(as.matrix(Data_new[, 1:10]))\nCorrelation\n\ncorrplot.mixed(Correlation$r, tl.pos = 'lt')\n```\n\nPerhaps unsurprising, it appears as though negatively worded items negatively correlate with positively worded items and all items correlate with each other. Now that I have a sense of the data and how the items play with each other, I am going to use both SEM and IRT principals to assess the psychometric properties of this scale.\n\n::: text-center\n# **Structural Equation Modeling**\n:::\n\nSEM is preferred here over CFA as SEM relaxes assumptions around cross loadings and error terms, which aid in reproducing more accurate fit statistics. SEM also allows for the estimation of paths between latent variables. First, I am going to run a simple SEM using the lavaan package where by all 10 self-esteem items are loaded onto a latent factor of general self-esteem.\n\n```{r}\nlibrary(lavaan)\nlibrary(semPlot)\nData_new <- Data_new %>%\n  filter(gender != \"3\")\n\nSEM1Fac <- 'SE =~ Q1 + Q2 + Q3 + Q4 + Q5 + Q6 + Q7 + Q8 + Q9 + Q10'\nfitSEM1 <- sem(SEM1Fac, Data_new, estimator = \"MLR\")\nsummary(fitSEM1, standardized = TRUE, fit.measures = TRUE)\nsemPaths(fitSEM1, what = \"std\", edge.label.cex = 0.7, esize = 1,\nintercepts = FALSE,rotation = 4, edge.color = 1, asize = 2.5,\nsizeMan = 5, mar = c(1, 1.5, 1.5, 3), fade = FALSE)\n```\n\nWhile all items do significantly load onto the latent factor of self-esteem and have decently sized factor loadings (all factor loadings are greater than .58), model fit does not meet acceptable standards. (cite acceptable standards). Since items 4 and 8 have the lowest loadings, I will drop those two items and test if model fit improves.\n\n```{r}\nSEM1.8Fac <- 'SE =~ Q1 + Q2 + Q3 + Q5 + Q6 + Q7 + Q9 + Q10'\nfitSEM1.8 <- sem(SEM1.8Fac, Data_new, estimator = \"MLR\")\nsummary(fitSEM1.8, standardized = TRUE, fit.measures = TRUE)\nsemPaths(fitSEM1.8, what = \"std\", edge.label.cex = 0.7, esize = 1,\nintercepts = FALSE,rotation = 4, edge.color = 1, asize = 2.5,\nsizeMan = 5, mar = c(1, 1.5, 1.5, 3), fade = FALSE)\n```\n\nModel fit worsened. Thus, the SEM model with all ten items is retained.\n\nLastly, I want to test that there is truly just one latent factor contained in these 10 items. For the sake of exploratory analyses, I will break items into two separate factors: one factor will contain the five positively worded items and a second factor will contain the five negatively worded items.\n\n```{r}\nSEM2Fac <- 'PosSE =~ Q1 + Q2 + Q4 + Q6 + Q7\n            NegSE =~ Q3 + Q5 + Q8 + Q9 + Q10'\nfitSEM2 <- sem(SEM2Fac, Data_new, estimator = \"MLR\")\nsummary(fitSEM2, standardized = TRUE, fit.measures = TRUE)\nsemPaths(fitSEM2, what = \"std\", edge.label.cex = 0.7, esize = 1,\nintercepts = FALSE,rotation = 4, edge.color = 1, asize = 2.5,\nsizeMan = 5, mar = c(1, 1.5, 1.5, 3), fade = FALSE)\n```\n\nWhile model fit may have slightly improved, it still does not fit industry standards nor was this model originally conceived to possess two factors. Thus, I will retain the 10 item single factor self-esteem scale. Since I have gender data collected as well, I will conduct a multigroup SEM to determine how or if parameter estimates differ for men and women.\n\n::: text-center\n## **Multigroup SEM**\n:::\n\nTo determine if men and women differ in how they responded to the self-esteem items, first I need to add in a grouping variable to the model I settled on above (the single factor, 10 item self-esteem scale). All loadings and parameters of the structural model are set to be free with each subsequent model imposing a constraint on aspects of the model. Model fit changes of .01 ∆CFI/TLI and .015 ∆RMSEA suggests evidence for differences between men and women. This first model with zero constraints imposed on the data structure is considered the configural model. The fit for this model will be the same as the model estimated above, however, it will provide estimates for the model for both men and women.\n\n```{r}\nConfigural <- sem(SEM1Fac, group = \"gender\", data = Data_new, \n                  estimator = \"MLR\")\n#summary(Configural, standardized = TRUE, fit.measures = TRUE)\n\n```\n\nTo test for metric invariance, that is, that the relationship between the ten items and the latent self-esteem factor are the same for men and women, I will set factor loadings to be invariant. The model fit from the model will be compared to the configural model and detriments in fit greater than the change values above will provide evidence that men and women differ in how strongly each item loads onto the latent factor.\n\n```{r}\nMetric <- sem(SEM1Fac, group = \"gender\", group.equal = c(\"loadings\"), \n              data = Data_new, estimator = \"MLR\")\nsummary(Metric, standardized = TRUE, fit.measures = TRUE)\n```\n\nModel fit for the metric model is:\n\nThis is\n\nNext, I will also hold item intercepts invariate to test for scalar invariance. Scalar invariance suggests that item responses are equivalent at the absolute level of the self-esteem trait.\n\n```{r}\nScalar <- sem(SEM1Fac, group = \"gender\", group.equal = c(\"loadings\", \"intercepts\"), data = Data_new, estimator = \"MLR\")\nsummary(Scalar, standardized = TRUE, fit.measures = TRUE)\n```\n\nModel fit for the scalar model is:\n\nThis indicates that\n\nLast, I will add item uniqueness (also called item residual) as the next invariate parameter as a test for strict invariance. Evidence of strict invariance would indicate that each item's residual is equal across gender groups.\n\n```{r}\nStrict <- sem(SEM1Fac, group = \"gender\", group.equal = c(\"loadings\", \"intercepts\", \"residuals\"), data = Data_new, estimator = \"MLR\")\nsummary(Strict, standardized = TRUE, fit.measures = TRUE)\n```\n\nModel fit for the strict model is:\n\nI have been comparing each model using model fit indicies but there is another way to compare models that compares AIC, BIC, and Chi-Square test of differences. This route also provides probability estimates for each parameter restriction.\n\n::: text-center\n### **Nested Model Comparison**\n:::\n\nJust as with model fit indicies, the more restrictive model will be compared to a less restrictive model. Using the four models I computed above, the code is relatively simple using the compareFit function in the semTools package.\n\n```{r}\nlibrary(semTools)\nsummary(compareFit(Configural, Metric))\n```\n","srcMarkdownNoYaml":"\n\n::: text-center\n# **Project Goal**\n:::\n\nThe data for this project was downloaded from Kaggle [here](https://www.kaggle.com/datasets/lucasgreenwell/rosenberg-self-esteem-scale-responses?select=data.csv) and originally housed on [OpenPsychometrics.org](https://openpsychometrics.org/). The data set contains approximately 48,000 participants who took the Rosenberg Self-Esteem Scale. Participant's gender, age, and country were also collected. This scale contains 10 items, of which five items are positively worded (Q1, Q2, Q4, Q6, & Q7) and five items are negatively worded (Q3, Q5, & Q8-10) on a 1-4 scale (anchors ranged from strongly disagree (1) to strongly agree (4)).\n\nFor this data, I will first compute descriptive values for the data set and then I will look at the psychometric properties of this data using both structural equation modeling (SEM) and Item Response Theory (IRT) principals.\n\n::: text-center\n# **Data Descriptive Analysis**\n:::\n\nFirst, I will load in the data and check for missing values. (Data file location is hidden from code chunk)\n\n```{r}\nlibrary(dplyr)\nData <- read.csv(\"C:/Users/matts/OneDrive/Desktop/002 Matt Desktop/WebsiteData/SelfEsteem Data/data.csv\", na.strings = \"\")\nsum(is.na(Data))\n```\n\nNo cells have been flagged as missing. However, the data originally coded all missing values as \"0\" so I will need to filter these values out to get complete responses before moving on to calculating data descriptives.\n\nNote: Original results suggest that there are four missing values in the data, however, looking at the rows that contain these four values, it becomes clear that r detected the country code of NA (Nambia) and incorrectly read those values as missing. I specified that the data be read in with the argument na.strings = \"\" to solve this problem and reloaded the data in.\n\n```{r}\nlibrary(psych)\nstr(Data) #checking for numeric status\nData_new <- Data[apply(Data!=0, 1, all),]\n#Get means, sd, and range\ndescribe(Data_new)\n```\n\nGlancing at the age row suggests that age ranged from 1 - 100,000 years of age, which is, of course, impossible. Thus, I will filter for a reasonable adult age range (18 - 100). This step is important as participants who reported being a single year old or 100,000 years old likely did not pay attention to other items in this scale and so I want to remove their responses.\n\n```{r}\nData_new <- Data_new %>%\n  filter(between(age, 18, 100))\ndescribe(Data_new)\nData_new %>%\n  count(Data_new$gender)\n```\n\nLooking at the means, most items hover around the mid point of the scale (between scores of 2-3). The average age of participants is 30 with a standard deviation of about 12 years and 59% of participants identify as female, 40% identify as male, and about 1% identify as non-binary.\n\n::: text-center\n## **Item Correlations**\n:::\n\nNow to calculate correlations between scale items and visualize them.\n\n```{r}\nlibrary(Hmisc)\nlibrary(corrplot)\nCorrelation <- rcorr(as.matrix(Data_new[, 1:10]))\nCorrelation\n\ncorrplot.mixed(Correlation$r, tl.pos = 'lt')\n```\n\nPerhaps unsurprising, it appears as though negatively worded items negatively correlate with positively worded items and all items correlate with each other. Now that I have a sense of the data and how the items play with each other, I am going to use both SEM and IRT principals to assess the psychometric properties of this scale.\n\n::: text-center\n# **Structural Equation Modeling**\n:::\n\nSEM is preferred here over CFA as SEM relaxes assumptions around cross loadings and error terms, which aid in reproducing more accurate fit statistics. SEM also allows for the estimation of paths between latent variables. First, I am going to run a simple SEM using the lavaan package where by all 10 self-esteem items are loaded onto a latent factor of general self-esteem.\n\n```{r}\nlibrary(lavaan)\nlibrary(semPlot)\nData_new <- Data_new %>%\n  filter(gender != \"3\")\n\nSEM1Fac <- 'SE =~ Q1 + Q2 + Q3 + Q4 + Q5 + Q6 + Q7 + Q8 + Q9 + Q10'\nfitSEM1 <- sem(SEM1Fac, Data_new, estimator = \"MLR\")\nsummary(fitSEM1, standardized = TRUE, fit.measures = TRUE)\nsemPaths(fitSEM1, what = \"std\", edge.label.cex = 0.7, esize = 1,\nintercepts = FALSE,rotation = 4, edge.color = 1, asize = 2.5,\nsizeMan = 5, mar = c(1, 1.5, 1.5, 3), fade = FALSE)\n```\n\nWhile all items do significantly load onto the latent factor of self-esteem and have decently sized factor loadings (all factor loadings are greater than .58), model fit does not meet acceptable standards. (cite acceptable standards). Since items 4 and 8 have the lowest loadings, I will drop those two items and test if model fit improves.\n\n```{r}\nSEM1.8Fac <- 'SE =~ Q1 + Q2 + Q3 + Q5 + Q6 + Q7 + Q9 + Q10'\nfitSEM1.8 <- sem(SEM1.8Fac, Data_new, estimator = \"MLR\")\nsummary(fitSEM1.8, standardized = TRUE, fit.measures = TRUE)\nsemPaths(fitSEM1.8, what = \"std\", edge.label.cex = 0.7, esize = 1,\nintercepts = FALSE,rotation = 4, edge.color = 1, asize = 2.5,\nsizeMan = 5, mar = c(1, 1.5, 1.5, 3), fade = FALSE)\n```\n\nModel fit worsened. Thus, the SEM model with all ten items is retained.\n\nLastly, I want to test that there is truly just one latent factor contained in these 10 items. For the sake of exploratory analyses, I will break items into two separate factors: one factor will contain the five positively worded items and a second factor will contain the five negatively worded items.\n\n```{r}\nSEM2Fac <- 'PosSE =~ Q1 + Q2 + Q4 + Q6 + Q7\n            NegSE =~ Q3 + Q5 + Q8 + Q9 + Q10'\nfitSEM2 <- sem(SEM2Fac, Data_new, estimator = \"MLR\")\nsummary(fitSEM2, standardized = TRUE, fit.measures = TRUE)\nsemPaths(fitSEM2, what = \"std\", edge.label.cex = 0.7, esize = 1,\nintercepts = FALSE,rotation = 4, edge.color = 1, asize = 2.5,\nsizeMan = 5, mar = c(1, 1.5, 1.5, 3), fade = FALSE)\n```\n\nWhile model fit may have slightly improved, it still does not fit industry standards nor was this model originally conceived to possess two factors. Thus, I will retain the 10 item single factor self-esteem scale. Since I have gender data collected as well, I will conduct a multigroup SEM to determine how or if parameter estimates differ for men and women.\n\n::: text-center\n## **Multigroup SEM**\n:::\n\nTo determine if men and women differ in how they responded to the self-esteem items, first I need to add in a grouping variable to the model I settled on above (the single factor, 10 item self-esteem scale). All loadings and parameters of the structural model are set to be free with each subsequent model imposing a constraint on aspects of the model. Model fit changes of .01 ∆CFI/TLI and .015 ∆RMSEA suggests evidence for differences between men and women. This first model with zero constraints imposed on the data structure is considered the configural model. The fit for this model will be the same as the model estimated above, however, it will provide estimates for the model for both men and women.\n\n```{r}\nConfigural <- sem(SEM1Fac, group = \"gender\", data = Data_new, \n                  estimator = \"MLR\")\n#summary(Configural, standardized = TRUE, fit.measures = TRUE)\n\n```\n\nTo test for metric invariance, that is, that the relationship between the ten items and the latent self-esteem factor are the same for men and women, I will set factor loadings to be invariant. The model fit from the model will be compared to the configural model and detriments in fit greater than the change values above will provide evidence that men and women differ in how strongly each item loads onto the latent factor.\n\n```{r}\nMetric <- sem(SEM1Fac, group = \"gender\", group.equal = c(\"loadings\"), \n              data = Data_new, estimator = \"MLR\")\nsummary(Metric, standardized = TRUE, fit.measures = TRUE)\n```\n\nModel fit for the metric model is:\n\nThis is\n\nNext, I will also hold item intercepts invariate to test for scalar invariance. Scalar invariance suggests that item responses are equivalent at the absolute level of the self-esteem trait.\n\n```{r}\nScalar <- sem(SEM1Fac, group = \"gender\", group.equal = c(\"loadings\", \"intercepts\"), data = Data_new, estimator = \"MLR\")\nsummary(Scalar, standardized = TRUE, fit.measures = TRUE)\n```\n\nModel fit for the scalar model is:\n\nThis indicates that\n\nLast, I will add item uniqueness (also called item residual) as the next invariate parameter as a test for strict invariance. Evidence of strict invariance would indicate that each item's residual is equal across gender groups.\n\n```{r}\nStrict <- sem(SEM1Fac, group = \"gender\", group.equal = c(\"loadings\", \"intercepts\", \"residuals\"), data = Data_new, estimator = \"MLR\")\nsummary(Strict, standardized = TRUE, fit.measures = TRUE)\n```\n\nModel fit for the strict model is:\n\nI have been comparing each model using model fit indicies but there is another way to compare models that compares AIC, BIC, and Chi-Square test of differences. This route also provides probability estimates for each parameter restriction.\n\n::: text-center\n### **Nested Model Comparison**\n:::\n\nJust as with model fit indicies, the more restrictive model will be compared to a less restrictive model. Using the four models I computed above, the code is relatively simple using the compareFit function in the semTools package.\n\n```{r}\nlibrary(semTools)\nsummary(compareFit(Configural, Metric))\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"SelfEsteem SEM & IRT.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","editor":"visual","theme":{"dark":"Superhero"},"title":"Psychometric Properties of Self Esteem via SEM and IRT","author":"Matthew Swanson","categories":["Structural Equation Modeling","Item Response Theory","R","lavaan"],"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}