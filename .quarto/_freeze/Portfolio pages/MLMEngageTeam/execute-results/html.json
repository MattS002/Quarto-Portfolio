{
  "hash": "aa3da70d0dee45b65db74d7688880ce9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using Multilevel Modeling To Understand Engagement, Autonomy, and Team Cohesion\"\neditor: visual\nauthor: Matthew Swanson\ncategories: ['Multilevel Modeling', 'R', 'lavaan', 'ICC1 & 2', 'Engagement', 'Team Cohesion', 'Inter-rater Reliability', 'Simple Slopes']\nwarning: FALSE\nmessage: FALSE\n---\n\n\n\n::: text-center\n# **Project Goal**\n:::\n\nA company has collected employee data and wants to understand the factors that shape the engagement of their workers. They collected data on the pay structure, autonomy level, and team cohesion each employee has with the overall goal of relating these variables to individual level engagement. Unique to this data is the level 1 / level 2 structure. For example, pay, engagement, and job autonomy (all level 1 variables) are assessed at the individual level, while team cohesion (a level 2 variable) is assessed at the team level. Thus, individuals are nested in teams. My goal is to use these variables to predict engagement.\n\n::: text-center\n## **Preparing Data for Model Building**\n:::\n\nVariables need to be centered and scaled prior to entering them into a multilevel model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(multilevel)\nlibrary(readxl)\nlibrary(robumeta)\n\n\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  level1_id grpid      engage      cohes      jobsat        pay     jobauto\n1         1     1  0.76164141 -0.5461742  0.73576787 -0.2145807 -0.10330841\n2         2     1 -0.05155921 -0.5461742  0.09589171 -1.1725662  0.01494606\n3         3     1  1.60837420 -0.5461742  0.47694372 -0.9820727 -0.04202197\n4         4     1  1.23486381 -0.5461742  0.58489184 -0.4141129 -0.42891177\n5         5     1  6.73776145 -0.5461742 -0.83047804  1.9041059  0.68604898\n6         6     1  6.54714955 -0.5461742  1.58131185  0.2765618  1.19430414\n  commitment1 commitment2 commitment3\n1           4           5           4\n2           5           5           5\n3           1           2           2\n4           3           4           3\n5           5           5           5\n6           3           4           4\n```\n\n\n:::\n\n```{.r .cell-code}\noptions(scipen=999)\n\ndata$cohesion.grand.c <- scale(data$cohes, scale = FALSE)\ndata$autonomy.grp.c <- group.center(data$jobauto, data$grpid)\ndata$jobsat.grp.c <- group.center(data$jobsat, data$grpid)\ndata$pay.grp.c <- group.center(data$pay, data$grpid)\n```\n:::\n\n\n\n::: text-center\n# **Running Multilevel Models to Predict Level 1 Engagement**\n:::\n\nNow that I have group and grand mean centered the data, I will begin building some models to predict engagement. First I will add the predictors into a model with engagement as the dependent variable. I also added in interactions between autonomy and pay and cohesion and pay to the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nModel1 <- lme(engage~ 1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c + cohesion.grand.c + pay.grp.c:cohesion.grand.c, random = ~1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c|grpid,\ndata = data, control = lmeControl(opt = \"optim\"))\n\nsummary(Model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed-effects model fit by REML\n  Data: data \n       AIC      BIC    logLik\n  3599.774 3678.179 -1782.887\n\nRandom effects:\n Formula: ~1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n                         StdDev    Corr                \n(Intercept)              0.4298969 (Intr) py.gr. atnm..\npay.grp.c                0.7669658 -0.169              \nautonomy.grp.c           0.6277085 -0.215  0.131       \npay.grp.c:autonomy.grp.c 1.2852694  0.317  0.288  0.117\nResidual                 2.3189244                     \n\nFixed effects:  engage ~ 1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c +      cohesion.grand.c + pay.grp.c:cohesion.grand.c \n                               Value Std.Error  DF   t-value p-value\n(Intercept)                2.7311089 0.1061344 696 25.732554  0.0000\npay.grp.c                  0.3836225 0.1410103 696  2.720528  0.0067\nautonomy.grp.c             0.6181183 0.1337924 696  4.619980  0.0000\ncohesion.grand.c           0.1544943 0.1241618  48  1.244298  0.2194\npay.grp.c:autonomy.grp.c   0.3487103 0.2123779 696  1.641933  0.1011\npay.grp.c:cohesion.grand.c 0.5352599 0.1663569 696  3.217540  0.0014\n Correlation: \n                           (Intr) py.gr. atnm.. chsn.. py.grp.c:t..\npay.grp.c                  -0.074                                  \nautonomy.grp.c             -0.083  0.070                           \ncohesion.grand.c            0.007 -0.003 -0.001                    \npay.grp.c:autonomy.grp.c    0.166  0.182  0.012  0.014             \npay.grp.c:cohesion.grand.c -0.001  0.001  0.008 -0.112  0.032      \n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.4868889 -0.6959695 -0.1058310  0.5644816  3.9079997 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n```\n\n\n:::\n\n```{.r .cell-code}\nVarCorr(Model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ngrpid = pdLogChol(1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c) \n                         Variance  StdDev    Corr                \n(Intercept)              0.1848113 0.4298969 (Intr) py.gr. atnm..\npay.grp.c                0.5882365 0.7669658 -0.169              \nautonomy.grp.c           0.3940179 0.6277085 -0.215  0.131       \npay.grp.c:autonomy.grp.c 1.6519175 1.2852694  0.317  0.288  0.117\nResidual                 5.3774103 2.3189244                     \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(interactions)\nlibrary(jtools)\nlibrary(lmerTest)\n\nMod1 <- lmer(engage ~ 1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c + cohesion.grand.c + pay.grp.c:cohesion.grand.c + (1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c|grpid), data = data, control = lmerControl(calc.derivs = FALSE))\n```\n:::\n\n\n\nSeveral significant results emerged from these models. Specifically, employee pay was significantly related to individual levels of work engagement b=0.384, t(696)=2.721, p=.007. Additionally, results suggest that for every unit increase in pay, work engagement will increase by a value of 0.384, when autonomy and team cohesion are zero. However, job autonomy was did not moderate the relationship between pay and work engagement, b=0.349, t(696)=1.642, p=.101.\n\nRegarding the level 2 predictor, team cohesion, results indicate that team cohesion was found to moderate the relationship between pay and work engagement, b=0.535, t(696)=3.218, p=.001.\n\n::: text-center\n# **Plotting The Multilevel Interaction**\n:::\n\nGiven the significant interaction, I will now plot the interaction and calculate the simple slopes of this interaction to aid in interpretation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteract_plot(model = Mod1, pred = pay.grp.c, modx = cohesion.grand.c,\nx.label = \"Pay\",\nmain.title = \"Interaction Between Team Cohesion and Pay Predicting Engagement\",\ny.label = \"Engagement\", legend.main = \"Team Cohesion\",\ncolors = c(\"Green\",\"Blue\")) + theme_apa(legend.use.title = T)\n```\n\n::: {.cell-output-display}\n![](MLMEngageTeam_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsim_slopes(model = Mod1, pred = pay.grp.c, modx = cohesion.grand.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nJOHNSON-NEYMAN INTERVAL\n\nWhen cohesion.grand.c is OUTSIDE the interval [-2.10, -0.19], the slope of\npay.grp.c is p < .05.\n\nNote: The range of observed values of cohesion.grand.c is [-2.23, 1.69]\n\nSIMPLE SLOPES ANALYSIS\n\nSlope of pay.grp.c when cohesion.grand.c = -0.83100000291645215177994 (- 1 SD): \n\n   Est.   S.E.   t val.      p\n------- ------ -------- ------\n  -0.06   0.20    -0.31   0.76\n\nSlope of pay.grp.c when cohesion.grand.c =  0.00000000000000001276756 (Mean): \n\n  Est.   S.E.   t val.      p\n------ ------ -------- ------\n  0.38   0.14     2.72   0.01\n\nSlope of pay.grp.c when cohesion.grand.c =  0.83100000291645215177994 (+ 1 SD): \n\n  Est.   S.E.   t val.      p\n------ ------ -------- ------\n  0.83   0.20     4.19   0.00\n```\n\n\n:::\n:::\n\n\n\nThe relationship between pay and work engagement is stronger for individuals with higher levels of team cohesion. The slope for pay will increase by 0.535 with every unit change of team cohesion. In other words, the simple effect of engagement on pay gets strengthened, or more positive, p=.001.\n\nSimple slopes analysis reveals a significant moderated relationship between pay and engagement when autonomy is at its mean (b=0.38, t=2.72, p=.01) and when autonomy is one standard deviation above its mean (b=0.83, t=4.19, p\\<.01), but not for those who indicated having levels of autonomy at work that was at least one standard deviation below the mean (b-0.06, t=-0.31, p=.76).\n\n::: text-center\n# **Running Multilevel Models to Predict Level 1 Job Satisfaction**\n:::\n\nThe client also collected data on job satisfaction and is interested in knowing if job satisfaction, at the individual level, also interacts with team-level cohesion in predicting work engagement. I also swapped dependent variables to test if pay was a significant predictor of job satisfaction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2.1 <- lme(engage ~pay.grp.c, random = ~1 + pay.grp.c|grpid, data = data, control = lmeControl(opt = \"optim\"))\nsummary(model2.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed-effects model fit by REML\n  Data: data \n       AIC      BIC    logLik\n  3768.164 3795.868 -1878.082\n\nRandom effects:\n Formula: ~1 + pay.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev    Corr  \n(Intercept) 0.2572344 (Intr)\npay.grp.c   0.8923049 0.552 \nResidual    2.8579445       \n\nFixed effects:  engage ~ pay.grp.c \n                Value Std.Error  DF   t-value p-value\n(Intercept) 2.9035266 0.1105163 699 26.272382  0.0000\npay.grp.c   0.4368898 0.1639982 699  2.663991  0.0079\n Correlation: \n          (Intr)\npay.grp.c 0.14  \n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.1116006 -0.6941114 -0.1975845  0.4728133  6.5971460 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n```\n\n\n:::\n\n```{.r .cell-code}\nmodel2.2 <- lme(jobsat ~ pay.grp.c, random = ~1 + pay.grp.c|grpid, data = data, control = lmeControl(opt = \"optim\"))\nsummary(model2.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed-effects model fit by REML\n  Data: data \n       AIC      BIC    logLik\n  2168.444 2196.148 -1078.222\n\nRandom effects:\n Formula: ~1 + pay.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev     Corr  \n(Intercept) 0.13429577 (Intr)\npay.grp.c   0.03052776 0.003 \nResidual    1.00544251       \n\nFixed effects:  jobsat ~ pay.grp.c \n                  Value  Std.Error  DF    t-value p-value\n(Intercept) -0.06326777 0.04133513 699 -1.5306053  0.1263\npay.grp.c    0.03569705 0.03633069 699  0.9825591  0.3262\n Correlation: \n          (Intr)\npay.grp.c 0     \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.80428971 -0.67306262  0.02052851  0.70766759  2.69852694 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n```\n\n\n:::\n\n```{.r .cell-code}\nmodel2.3 <- lme(engage ~ pay.grp.c + jobsat.grp.c, random = ~1 + pay.grp.c + jobsat.grp.c|grpid, data = data,control = lmeControl(opt = \"optim\"))\nsummary(model2.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed-effects model fit by REML\n  Data: data \n      AIC      BIC    logLik\n  3758.69 3804.851 -1869.345\n\nRandom effects:\n Formula: ~1 + pay.grp.c + jobsat.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n             StdDev    Corr         \n(Intercept)  0.3136581 (Intr) py.gr.\npay.grp.c    0.9135909  0.425       \njobsat.grp.c 0.5947158 -0.321  0.388\nResidual     2.7700579              \n\nFixed effects:  engage ~ pay.grp.c + jobsat.grp.c \n                 Value Std.Error  DF   t-value p-value\n(Intercept)  2.9035266 0.1104472 698 26.288815  0.0000\npay.grp.c    0.4211243 0.1653490 698  2.546882  0.0111\njobsat.grp.c 0.3767563 0.1374256 698  2.741530  0.0063\n Correlation: \n             (Intr) py.gr.\npay.grp.c     0.133       \njobsat.grp.c -0.079  0.175\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.1932653 -0.6760609 -0.1646372  0.4790537  6.6411560 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n```\n\n\n:::\n:::\n\n\n\nWhile both pay (b=0.421, t(698)=2.547, p=.011) and job satisfaction (b=0.377, t(698)=2.742, p=.006) significantly predicted work engagement, pay was not a significant predictor of job satisfaction (b=0.036, t(699)=.983, p=.326).\n\n::: text-center\n# **Effect Size**\n:::\n\nNow that I have determined which variables predict engagement, the question still remains of how strong these effects are. Given the multilevel nature of this data, I will analyze the ICC1 values which tells me the proportion of individual ratings that are due to group membership. I will also look at ICC2 values to establish the stability of mean ratings in discriminating between groups (participants are grouped by their work teams).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmult.icc(data[, c(\"jobsat\", \"jobauto\")], data$grpid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Variable       ICC1      ICC2\n1   jobsat 0.01743368 0.2102011\n2  jobauto 0.01826727 0.2182050\n```\n\n\n:::\n:::\n\n\n\nICC1 for both job satisfaction (ICC1=.017) and autonomy (ICC1=.018), both of which would be considered \"small\" effects. The proportion of variance in ratings that is due to between-target differences is small, suggesting that individuals rating are only slightly attributable to group membership.\n\nThe ICC2 for job satisfaction (ICC2=.210) is larger than the ICC2 for autonomy (ICC2=.218), suggesting that the groups' mean ratings were more stable and reliable for ratings of autonomy than for ratings of job satisfaction. In other words, the mean ratings of autonomy were better able to distinguish between groups than the mean ratings of job satisfaction.\n\n::: text-center\n# **Inter-rater Reliability**\n:::\n\nWhen looking at the data, I noticed that the commitment scale was created by aggregating three commitment items into an overall scale. To double-check that employees tended to rate similarly across the three items (i.e., an individual rating a score of 4 on the first commitment item would likely rate similarly for commitment items 2 & 3) and that it is appropriate to use an aggregate commitment scale, I will assess inter-rater agreement. Note: rwg is the symbol used to denote this form of inter-rater agreement and will be utilized in the code and interpretation below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrwg.commit1.un = rwg(data$commitment1, data$grpid, ranvar = 2.00)\nsummary(rwg.commit1.un)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    grpid                rwg             gsize   \n Length:50          Min.   :0.0000   Min.   :15  \n Class :character   1st Qu.:0.2345   1st Qu.:15  \n Mode  :character   Median :0.4333   Median :15  \n                    Mean   :0.3962   Mean   :15  \n                    3rd Qu.:0.5571   3rd Qu.:15  \n                    Max.   :0.7952   Max.   :15  \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(rwg.commit1.un$rwg, xlab = \"Estimate of rwg\", ylab = \"Frequency\", main = \"Histogram of 1st Commitment Item's rwg Values\")\n```\n\n::: {.cell-output-display}\n![](MLMEngageTeam_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nrwgj.commit.un = rwg.j(data[, c(8:10)], data$grpid, ranvar = 2.00)\nsummary(rwgj.commit.un)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    grpid               rwg.j            gsize   \n Length:50          Min.   :0.0000   Min.   :15  \n Class :character   1st Qu.:0.5202   1st Qu.:15  \n Mode  :character   Median :0.6825   Median :15  \n                    Mean   :0.6040   Mean   :15  \n                    3rd Qu.:0.7884   3rd Qu.:15  \n                    Max.   :0.8996   Max.   :15  \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(rwgj.commit.un$rwg, xlab = \"Estimate of rwg\", ylab = \"Frequency\", main = \"Histogram of Commitment Scale's rwg Values\")\n```\n\n::: {.cell-output-display}\n![](MLMEngageTeam_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n\nThe mean rwg value for the first commitment item is 0.396 and the median is .433. Since this value is below the standard cutoff of .70, it is apparent that raters had low levels of agreement for the first commitment item. The mean rwg.j value for the commitment scale is .604 and the median is .683. While still below the cutoff score of .70 for high inter-rater agreement, the agreement level did increase when all three commitment items were considered, as compared to a single commitment item, helping support the usability of the composite score over a particular commitment item.\n",
    "supporting": [
      "MLMEngageTeam_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}