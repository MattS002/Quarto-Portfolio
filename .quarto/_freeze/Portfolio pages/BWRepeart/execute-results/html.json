{
  "hash": "ef2b01245646d15b798b882b57817735",
  "result": {
    "markdown": "---\ntitle: \"Between and Within Repeated Measures ANOVA in R\"\neditor: visual\nauthor: Matthew Swanson\ncategories: ['Repeated Measures ANOVA', 'R', 'Emmeans']\nwarning: FALSE\nmessage: FALSE\n---\n\n\n::: text-center\n# **Project Goal**\n:::\n\nA researcher is interested in how memory for a list of words can be influenced by instructions on how to process the words. She assigns participants to one of three instruction conditions (COND): no instructions (coded as 1), rote memorization (told to just rehearse each word, coded as 2), and image (told to form an image for each word, coded as 3). Participants are presented with a list of 30 words and the researcher records the number out of 30 words that each participant recalls correctly. Because she is interested in practice effects, she presents each subject with two lists, one after another, and records performance on each list (LIST1 and LIST2).\n\nFirst, I will read in the data and check the data type (i.e., is the data wide or long?).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ez)\nlibrary(tidyr)\nlibrary(tidyverse)\n\nhead(Data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  subjid  cond list1 list2\n   <dbl> <dbl> <dbl> <dbl>\n1      1     1    21    25\n2      2     1    11    12\n3      3     1    15    20\n4      4     1    11    12\n5      5     1    18    15\n6      6     1    12    12\n```\n:::\n\n```{.r .cell-code}\n#Need to convert data set to long format - it is currently in wide format\n\n#Changing data to long format - we want to gather by list as this is the repeated variable\nDataLong <- Data %>%\ngather(key = \"list\", value = \"score\", list1, list2)\nDataLong$list <- as.factor(DataLong$list)\nDataLong$cond <- as.factor(DataLong$cond)\nDataLong$subjid <- as.factor(DataLong$subjid)\nhead(DataLong)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  subjid cond  list  score\n  <fct>  <fct> <fct> <dbl>\n1 1      1     list1    21\n2 2      1     list1    11\n3 3      1     list1    15\n4 4      1     list1    11\n5 5      1     list1    18\n6 6      1     list1    12\n```\n:::\n:::\n\n\nNow, let's double check that the design is balanced.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDataLong %>%\ngroup_by(list, cond) %>%\nsummarise(n = n(), sd = sd(score), var = var(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n# Groups:   list [2]\n  list  cond      n    sd   var\n  <fct> <fct> <int> <dbl> <dbl>\n1 list1 1        10  3.33 11.1 \n2 list1 2        10  2.59  6.71\n3 list1 3        10  4.06 16.5 \n4 list2 1        10  4.37 19.1 \n5 list2 2        10  2.42  5.88\n6 list2 3        10  3.73 13.9 \n```\n:::\n:::\n\n\n::: text-center\n# **Model Building**\n:::\n\nWe have a balanced design. Now let's analyze the data. We are interested in how memory for a list of words can be influenced by instructions on how to process the words.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\nRepeated <- ezANOVA(DataLong, dv = score, wid = subjid, within = list, between = cond, detailed = TRUE, return_aov = TRUE, type = 3)\nRepeated\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$ANOVA\n       Effect DFn DFd         SSn    SSd          F            p p<.05\n1 (Intercept)   1  27 13053.75000 584.35 603.150937 5.272153e-20     *\n2        cond   2  27   206.40000 584.35   4.768375 1.684833e-02     *\n3        list   1  27   198.01667  73.95  72.298174 4.077683e-09     *\n4   cond:list   2  27    32.53333  73.95   5.939148 7.283889e-03     *\n         ges\n1 0.95199113\n2 0.23869550\n3 0.23124234\n4 0.04709288\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 14.75\n\nStratum 1: subjid\n\nTerms:\n                  cond Residuals\nSum of Squares  206.40    584.35\nDeg. of Freedom      2        27\n\nResidual standard error: 4.65216\n2 out of 4 effects not estimable\nEstimated effects may be unbalanced\n\nStratum 2: subjid:list\n\nTerms:\n                     list cond:list Residuals\nSum of Squares  198.01667  32.53333  73.95000\nDeg. of Freedom         1         2        27\n\nResidual standard error: 1.654959\nEstimated effects may be unbalanced\n```\n:::\n\n```{.r .cell-code}\n#Additional ways to estimate this model\nModel <- aov(score ~ list*cond + Error(subjid/list), DataLong)\n#summary(Model)\n\n#SphereCorr <- anova_test(DataLong, dv = score, wid = subjid, within = list, between = cond)\n#SphereCorr\n\nlibrary(ggpubr)\n\nbxp <- ggboxplot(DataLong, x = \"list\", y = \"score\",color = \"cond\", palette = \"jco\")\nbxp\n```\n\n::: {.cell-output-display}\n![](BWRepeart_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nSince the interaction term is significant, F(2,27) = 5.94, p = .047, that means that values in one factor depend, in part, on the values in the other factor so we must look at pairwise comparisons (simple effects and simple effects comparison). As denoted in the figure and output, there are some significant mean memory score differences between list 1 and list 2 of words for each condition.\n\n::: text-center\n## **Marginal Means**\n:::\n\nLet's directly calculate these means and the marginal means to aid in our interpretation of this data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\n\n#the pairs function comes from the emmeans package - verbiage should feel similar to emmeans commands in SPSS\nSimpleCond <- emmeans(Model, pairwise ~ cond, adjust = \"bonferroni\")\nSimpleCond\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$emmeans\n cond emmean   SE df lower.CL upper.CL\n 1      15.8 1.04 27     13.6     17.9\n 2      12.2 1.04 27     10.0     14.3\n 3      16.4 1.04 27     14.2     18.5\n\nResults are averaged over the levels of: list \nWarning: EMMs are biased unless design is perfectly balanced \nConfidence level used: 0.95 \n\n$contrasts\n contrast      estimate   SE df t.ratio p.value\n cond1 - cond2      3.6 1.47 27   2.447  0.0636\n cond1 - cond3     -0.6 1.47 27  -0.408  1.0000\n cond2 - cond3     -4.2 1.47 27  -2.855  0.0245\n\nResults are averaged over the levels of: list \nP value adjustment: bonferroni method for 3 tests \n```\n:::\n\n```{.r .cell-code}\nSimpleList <- emmeans(Model, pairwise ~ list, adjust = \"bonferroni\")\nSimpleList\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$emmeans\n list  emmean    SE   df lower.CL upper.CL\n list1   12.9 0.637 33.7     11.6     14.2\n list2   16.6 0.637 33.7     15.3     17.9\n\nResults are averaged over the levels of: cond \nWarning: EMMs are biased unless design is perfectly balanced \nConfidence level used: 0.95 \n\n$contrasts\n contrast      estimate    SE df t.ratio p.value\n list1 - list2    -3.63 0.427 27  -8.503  <.0001\n\nResults are averaged over the levels of: cond \n```\n:::\n:::\n\n\n::: text-center\n# **Solution**\n:::\n\nLet's interpret a few of these results. Across lists, participants told to form an image of the words in the mind recalled significantly greater words (M = 16.4) than those who practice rote memorization of the words (M = 12.2), t(27) = -2.86, p = 03. Additionally, the practice effect has strongest for participants in the rote memory condition as more words were recalled in the second list (M = 14.9) as compared to the first list (M = 9.4), t(27) = -7.43, p \\<.001. In other words, participants recalled more words overall when asked to assign an image to each word, however, they learned the best (i.e., the practice effect was the strongest) when they were asked to recall words via rote memory.\n",
    "supporting": [
      "BWRepeart_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}