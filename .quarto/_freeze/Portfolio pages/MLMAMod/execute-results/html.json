{
  "hash": "709da66e9ff2d5c47a8bdef057d75e72",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Performing Moderation Analysis Within Multilevel Meta-Analysis\"\neditor: visual\nauthor: Matthew Swanson\ncategories: ['Multilevel Meta-Analysis', 'R', 'Organizational Training', 'Moderation', 'Engagement', 'Data Science']\nwarning: FALSE\nmessage: FALSE\nformat: \n  html: \n    page-layout: full\n---\n\n\n\n\n::: text-center\n# **Project Goal**\n:::\n\n![](images/EmployeeGroup1.jpg)\n\nContinuing the evaluation of teamwork training effects as discussed in my project on multilevel meta-analysis (MLMA), which can be found [here](/Portfolio pages/MLMAEffect.qmd), I consider how these MLMA effects may depend on the presence of moderators. Specifically, I am interested in understanding if the positive training effects found when comparing pre and post-test scores *depends*, in part, on the employee group assessed. In the data set for this project, there is a variable called \"Mod1\" which is a categorical variable denoting the employee group that is providing the data for each effect. The key for this variable is as follows: 1 = frontline staff, 2 = care management staff, 3 = top-level management staff.\n\n::: text-center\n# *Data Preparation*\n:::\n\nFirst, I will rename and add labels for the moderating variable from the dataset I created when calculating Hedges *g* using the pre vs. post standardized mean difference. I will save these changes as a new dataset.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ez)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(metafor)\n\nData <- read_csv(\"C:/Users/matts/OneDrive/Desktop/002 Matt Desktop/WebsiteData/Data/PreVPostAggData.csv\")\n\nDataMod <- Data %>%\n  rename(Employee_Group = Mod1) %>%\n  mutate(Employee_Group = factor(Employee_Group, levels = c(1,2,3),\n                                 labels = c(\"Frontline\", \"CareManage\", \"TopManage\")))\nstr(DataMod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [30 Ã— 23] (S3: tbl_df/tbl/data.frame)\n $ ...1               : num [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n $ Study_ID           : num [1:30] 1 1 1 2 2 2 3 3 3 4 ...\n $ Effect_ID          : num [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n $ Employee_Group     : Factor w/ 3 levels \"Frontline\",\"CareManage\",..: 1 2 3 1 2 3 1 2 3 1 ...\n $ Months.since.follow: num [1:30] 2 6 12 4 2 1 1 4 12 12 ...\n $ N                  : num [1:30] 306 248 329 82 418 309 244 429 462 121 ...\n $ Mean_pre           : num [1:30] 3.5 2.71 2.48 3.78 3.07 4.12 5.11 3.22 6.13 2.67 ...\n $ Mean_post          : num [1:30] 5.86 5.79 3.3 4.42 6.4 6.63 5.28 5.49 5.99 3.25 ...\n $ Mean_follow        : num [1:30] 4.84 3.1 2.14 3.9 5.21 3.42 4.98 4.78 6.45 4.31 ...\n $ SD1                : num [1:30] 0.43 1.06 0.71 1.49 1.55 1.56 0.81 1.26 1.79 1.3 ...\n $ SD2                : num [1:30] 0.72 0.87 1.4 1.2 1.16 1.61 1.06 1.41 0.63 1.41 ...\n $ SD3                : num [1:30] 1.19 1.61 0.88 0.85 1.82 1.97 0.25 0.98 1.79 1.19 ...\n $ ri                 : num [1:30] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n $ yi                 : num [1:30] 5.475 2.897 1.152 0.426 2.145 ...\n $ vi                 : num [1:30] 0.05225 0.02095 0.00506 0.0133 0.00789 ...\n $ df                 : num [1:30] 305 247 328 81 417 308 243 428 461 120 ...\n $ std_error_d        : num [1:30] 0.01307 0.00919 0.00392 0.01274 0.00435 ...\n $ j                  : num [1:30] 0.998 0.997 0.998 0.991 0.998 ...\n $ hedges_g           : num [1:30] 5.461 2.888 1.15 0.422 2.141 ...\n $ std_error_g        : num [1:30] 0.01303 0.00916 0.00391 0.01262 0.00434 ...\n $ var_g              : num [1:30] 0.05212 0.02089 0.00505 0.01318 0.00788 ...\n $ se_cor             : num [1:30] 0.1143 0.127 0.1103 0.2209 0.0978 ...\n $ agg_effect         : num [1:30] 3.17 3.17 3.17 1.39 1.39 ...\n```\n\n\n:::\n:::\n\n\n\n\nYou will notice in this dataset that each row of data already has yi, vi, and Hedges *g* values calculated. I did this step [here](/Portfolio pages/MLMAEffect.qmd) and would have to be conducted prior to adding any moderating variables to the meta models. Also note that these values correspond to pre vs. post standardized mean differences; if I wanted to add a moderator to a MLMA model that compares the effect sizes for pre and follow-up time points, I would have to calculate the yi, vi, and Hedges *g* for this comparison prior to any moderation analyses.\n\n::: text-center\n# *MLMA Moderation Analysis*\n:::\n\nI will now add in the moderating variable, Employee_Group, to the MLMA model that compares scores between the pre and post time points. I will also run a model that does not include the intercept as that aids in interpreting the effect sizes for each level of the moderator.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPrevPost_EmployTypeMod <- rma.mv(yi = hedges_g, \n                        V = var_g,\n                        mods = ~ factor(Employee_Group),\n                        random = ~ 1 | Study_ID/Effect_ID, \n                        data = DataMod)\nPrevPost_EmployTypeMod\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 30; method: REML)\n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed              factor \nsigma^2.1  0.6611  0.8131     10     no            Study_ID \nsigma^2.2  2.5181  1.5868     30     no  Study_ID/Effect_ID \n\nTest for Residual Heterogeneity:\nQE(df = 27) = 3173.2511, p-val < .0001\n\nTest of Moderators (coefficients 2:3):\nQM(df = 2) = 5.0769, p-val = 0.0790\n\nModel Results:\n\n                                  estimate      se     zval    pval    ci.lb \nintrcpt                             1.7092  0.5662   3.0186  0.0025   0.5994 \nfactor(Employee_Group)CareManage   -0.4895  0.7126  -0.6870  0.4921  -1.8861 \nfactor(Employee_Group)TopManage    -1.5734  0.7145  -2.2020  0.0277  -2.9738 \n                                    ci.ub     \nintrcpt                            2.8189  ** \nfactor(Employee_Group)CareManage   0.9070     \nfactor(Employee_Group)TopManage   -0.1730   * \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n##moderator w/o intercept\nPrevPost_EmployTypeMod_Nointer <- rma.mv(yi = hedges_g, \n            V = var_g,\n            mods =  ~0 + factor(Employee_Group),\n            random = ~ 1 | Study_ID/Effect_ID, \n            data = DataMod)\n\nPrevPost_EmployTypeMod_Nointer\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 30; method: REML)\n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed              factor \nsigma^2.1  0.6611  0.8131     10     no            Study_ID \nsigma^2.2  2.5181  1.5868     30     no  Study_ID/Effect_ID \n\nTest for Residual Heterogeneity:\nQE(df = 27) = 3173.2511, p-val < .0001\n\nTest of Moderators (coefficients 1:3):\nQM(df = 3) = 12.0177, p-val = 0.0073\n\nModel Results:\n\n                                  estimate      se    zval    pval    ci.lb \nfactor(Employee_Group)Frontline     1.7092  0.5662  3.0186  0.0025   0.5994 \nfactor(Employee_Group)CareManage    1.2196  0.5651  2.1581  0.0309   0.1120 \nfactor(Employee_Group)TopManage     0.1358  0.5676  0.2392  0.8109  -0.9767 \n                                   ci.ub     \nfactor(Employee_Group)Frontline   2.8189  ** \nfactor(Employee_Group)CareManage  2.3273   * \nfactor(Employee_Group)TopManage   1.2483     \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nI tested for the moderating effect of employee group (i.e., frontline staff, care management staff, & top-level management staff) on the standardized mean difference between pre and post-test scores. Results of the test of moderators reveals that employee group did not significantly moderate the pre vs. post difference, *Q~m~*(2) = 5.077, *p* = .079.\n\n##Pairwise Comparisons\n\nAlthough the omnibus test indicates no difference in levels of employee group as a moderating factor explaining variance in the pre vs. post score difference, I will provide some code here to run pairwise comparisons of the each of the three levels of this moderator for the sake of illustration. This is also useful if a specific comparison between levels of the moderator needs to be reported on.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairmat(PrevPost_EmployTypeMod_Nointer, btt = 1:3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                                                 [,1] [,2] [,3]\nfactor(Employee_Group)Frontline-factor(Employee_Group)CareManage   -1    1    0\nfactor(Employee_Group)Frontline-factor(Employee_Group)TopManage    -1    0    1\nfactor(Employee_Group)CareManage-factor(Employee_Group)TopManage    0   -1    1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(PrevPost_EmployTypeMod_Nointer, X=pairmat(btt=1:3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nHypotheses:                                                                           \n1: -factor(Employee_Group)Frontline + factor(Employee_Group)CareManage = 0 \n2:  -factor(Employee_Group)Frontline + factor(Employee_Group)TopManage = 0 \n3: -factor(Employee_Group)CareManage + factor(Employee_Group)TopManage = 0 \n\nResults:\n   estimate     se    zval   pval   \n1:  -0.4895 0.7126 -0.6870 0.4921   \n2:  -1.5734 0.7145 -2.2020 0.0277 * \n3:  -1.0838 0.7137 -1.5187 0.1288   \n```\n\n\n:::\n:::",
    "supporting": [
      "MLMAMod_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}