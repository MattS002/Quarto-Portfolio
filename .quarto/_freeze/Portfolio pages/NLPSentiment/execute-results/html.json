{
  "hash": "86655031ca6ef87236a478b331a6df14",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"NLP Sentiment Analysis\"\neditor: visual\nauthor: Matthew Swanson\ncategories: ['Natural Language Processing', 'Sentiment Analysis', 'R', 'Visualizations', 'Tokenization']\nwarning: FALSE\nmessage: FALSE\n---\n\n\n\n::: text-center\n# **Project Goal**\n:::\n\nFor this project, I am working with a large scale qualitative data set of responses to a research question by adult employees in the United States. There are over 50,000 words housed in several hundred rows of participant responses and it is of interest to the researcher (me) to understand if there are unique words used in one particular condition. It was also of interest to determine if the characteristics of participant's shaped what words they utilized to respond to the experimental prompt.\n\n::: text-center\n# **Tokenization and Data Cleaning**\n:::\n\nI decided to use Natural Language Processing, in particular sentiment analysis, to analyze the words present in the data set. I also decided to set my tokenization parameter at the word level.\n\nFirst, I need to load in the data and set the tokenization of the text corpus.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(readxl)\nlibrary(tidyverse)\nglimpse(HealthResp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 595\nColumns: 2\n$ ProlificID             <chr> \"5e8ea20ad1aa0d164f407023\", \"6029785ce4c6ff34c7…\n$ Healthy_Work_Condition <chr> NA, NA, NA, \"Last week one of the employees hus…\n```\n\n\n:::\n\n```{.r .cell-code}\nHealthResp_tidy <- HealthResp %>%\nunnest_tokens(output = word, input = Healthy_Work_Condition, token = \"words\")\nhead(HealthResp_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  ProlificID               word \n  <chr>                    <chr>\n1 5e8ea20ad1aa0d164f407023 <NA> \n2 6029785ce4c6ff34c77a50ea <NA> \n3 60380d3c5275b918ad26e8b5 <NA> \n4 5d9e9204340c7700150ab74c last \n5 5d9e9204340c7700150ab74c week \n6 5d9e9204340c7700150ab74c one  \n```\n\n\n:::\n:::\n\n\n\nI can see that the tokenization was successful since each word has been separated as its own row, grouped at the participant level. Now lets look at some basic things such as word frequencies and counts.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(HealthResp_tidy %>%\ncount(word, sort= TRUE), n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 2\n   word      n\n   <chr> <int>\n 1 to     1008\n 2 and     988\n 3 i       952\n 4 the     746\n 5 a       732\n 6 my      562\n 7 was     489\n 8 of      410\n 9 me      407\n10 that    376\n```\n\n\n:::\n:::\n\n\n\nAs revealed in the tibble above, the 10 most used words are articles and connectives, and likely will not be of use to my analysis. I want to remove these words but also take a conservative approach so that I don't remove too many words that might be of interest. The tidytext package has a data set called \"stop_words\" containing a lexicon of words comprised of article words such as \"to\", \"and\", \"the\" which I would like to remove.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"stop_words\")\n\nHealthResp_tidy <- anti_join(HealthResp_tidy, stop_words)\n\nHealthResp_Freq <- HealthResp_tidy %>%\n  count(word, sort = TRUE) %>%\n  filter(word != \"NA\")\n\nhead(HealthResp_Freq, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 2\n   word            n\n   <chr>       <int>\n 1 time          110\n 2 job            95\n 3 environment    87\n 4 feel           83\n 5 team           77\n 6 healthy        74\n 7 stands         72\n 8 boss           67\n 9 day            65\n10 moment         56\n```\n\n\n:::\n:::\n\n\n\nNow the most frequent words better reflect words of interest to my sentiment analysis. Before moving forward, I visualized the frequency of words that occurred over 50 times in participant's responses.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggthemes)\nHealthResp_Freq %>%\n  filter(n > 50) %>%\n  filter(word != \"NA\") %>%\n  mutate(word = reorder(word, n)) %>%\n    ggplot(aes(word, n)) +\n    geom_bar(stat = \"identity\") +\n    xlab(NULL) +\n    coord_flip() +\n    ggtitle(\"Most Commonly Used Words\\n in Healthy Condition\") +\n    theme_clean()\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nI also created a word cloud visualization of these words, setting the parameters to a max of 50 words used in the visualization.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(wordcloud)\nlibrary(RColorBrewer)\n\nHealthResp_Freq %>%\nwith(wordcloud(word, n, max.words = 100, colors = brewer.pal(12, \"Paired\"), scale=c(3.5,0.25)))\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nYou may have noticed that I have only been analyzing words from one condition, called healthy. It is now time to repeat the above analysis for the second condition, called unhealthy.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(UnhealthResp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 595\nColumns: 2\n$ ProlificID               <chr> \"5e8ea20ad1aa0d164f407023\", \"6029785ce4c6ff34…\n$ Unhealthy_Work_Condition <chr> \"My job involves processing payroll, however,…\n```\n\n\n:::\n\n```{.r .cell-code}\nUnhealthResp_tidy <- UnhealthResp %>%\n  unnest_tokens(output = word, input = Unhealthy_Work_Condition, token = \"words\") %>%\n    anti_join(stop_words, by = \"word\")\n\nUnhealthResp_Freq <- UnhealthResp_tidy %>%\n  count(word, sort = TRUE) %>%\n  filter(word != \"NA\")\nhead(UnhealthResp_Freq, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 2\n   word            n\n   <chr>       <int>\n 1 job           149\n 2 time          106\n 3 feel          102\n 4 environment    79\n 5 unhealthy      76\n 6 people         74\n 7 stands         73\n 8 boss           72\n 9 supervisor     65\n10 manager        61\n```\n\n\n:::\n:::\n\n\n\nI will now generate some visualizations of this condition before comparing the two conditions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nUnhealthResp_Freq %>%\n  filter(n > 50) %>%\n  filter(word != \"NA\") %>%\n  mutate(word = reorder(word, n)) %>%\n    ggplot(aes(word, n)) +\n    geom_bar(stat = \"identity\") +\n    xlab(NULL) +\n    coord_flip() +\n    ggtitle(\"Most Commonly Used Words\\n in Unhealthy Condition\") +\n    theme_clean()\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nUnhealthResp_Freq %>%\nwith(wordcloud(word, n, max.words = 100, colors = brewer.pal(9, \"Set1\"), scale=c(3.5,0.25)))\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n\nI've looked at each condition separately, now I will merge the two cleaned data sets back together and run analyses on this new data set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(HealthResp_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"ProlificID\" \"word\"      \n```\n\n\n:::\n\n```{.r .cell-code}\nnames(UnhealthResp_tidy) #Both data sets now have the same names for all variables in the same order\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"ProlificID\" \"word\"      \n```\n\n\n:::\n\n```{.r .cell-code}\nwordfreq <- bind_rows(mutate(HealthResp_tidy, condition = \"Healthy\"),mutate(UnhealthResp_tidy, condition = \"Unhealthy\"))\n\nwordfreqtotal <- wordfreq %>%\n  count(condition, word) %>%\n  group_by(condition) %>%\n  mutate(proportion = n / sum(n)) %>%\n  select(condition, word, proportion) %>%\n  spread(condition, proportion) %>%\n    filter(Healthy > .002 | Unhealthy > .002)\n\nhead(wordfreqtotal, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 3\n   word         Healthy Unhealthy\n   <chr>          <dbl>     <dbl>\n 1 ago         0.00333   0.00325 \n 2 angry       0.000513  0.00302 \n 3 bad         0.00154   0.00290 \n 4 boss        0.00859   0.00835 \n 5 call        0.00128   0.00209 \n 6 called      0.00179   0.00255 \n 7 care        0.00359   0.00104 \n 8 cared       0.00218   0.000696\n 9 client      0.000897  0.00290 \n10 comfortable 0.00205   0.00139 \n```\n\n\n:::\n:::\n\n\n\nThis new data frame contains three columns: the first column contains the utilized words, the second column is the proportion that a particular word appears across all words used in the healthy condition, the third column is the same as the second column except the proportion is compared to words used in the unhealthy condition. Like above, it is important to visualize these words in conjunction to each other.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = wordfreqtotal, mapping = aes(x = Healthy, y = Unhealthy, label = word)) +\n  scale_x_log10() + scale_y_log10() +\n  geom_text(alpha = .7, size = 3) +\n  geom_abline(lty = 2) +\n  theme_few()\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\nWords closer to the diagonal line appear at similar rates in both conditions while words farther out to the top-left or bottom-right occur more in the unhealthy or healthy condition, respectively. For example, words like coworker, manager, job, and COVID are right on the diagonal line, indicating that they occurred for similar proportions in both conditions. This makes sense as the original prompt presented to participants asked about their job experiences in 2020-21. However, words like care, supportive, and understanding occurred more frequently in the healthy condition while words like angry, uncomfortable, and bad occurred more often in the unhealthy condition.\n\n::: text-center\n# **Sentiment Analysis**\n:::\n\nNow that I have a good feel about the sorts of words that participants used to describe their work experiences across and within conditions, I want to analyze the word tokens for emotional valance (i.e., the general perception of positive or negative contained within the words used in each condition).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(textdata)\n\nnrc <- get_sentiments(\"nrc\")\nAFINN <- get_sentiments(\"afinn\")\nBING <- get_sentiments(\"bing\")\n\nsort(unique(nrc$sentiment)) #Use this to see the unique codes that are present in the nrc sentiment column\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"anger\"        \"anticipation\" \"disgust\"      \"fear\"         \"joy\"         \n [6] \"negative\"     \"positive\"     \"sadness\"      \"surprise\"     \"trust\"       \n```\n\n\n:::\n\n```{.r .cell-code}\nwordfreq <- bind_rows(mutate(HealthResp_tidy, condition = \"Healthy\"),\n  mutate(UnhealthResp_tidy, condition = \"Unhealthy\"))%>%\n    count(condition, word) %>%\n    group_by(condition) %>%\n  mutate(proportion = n / sum(n))\n```\n:::\n\n\n\nThe nrc, afinn, and bing sentiments compare a corpus of words to their predefined emotions or word valance lexicons. For example, evaluating corpus sentiments using the nrc column evaluates the degree of emotions or feelings like anger, anticipation, and disgust present in the analyzed corpus. You can find more detailed information about the nrc sentiment data frame [here](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm).\n\nBecause I want to provide evidence that the experimental conditions produced differently valanced words in either condition, determining how positive or negative the overall words used in either condition is important. I will first analyze by a particular emotion and then will use all three popular sentiment lexicons to get a more complete understanding of the sentiments that participants had in both conditions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Look at the proportion of fear based words per condition\n\ncondition_fear <- nrc %>%\n  filter(sentiment == \"fear\") %>%\n    inner_join(wordfreq, by = \"word\") %>%\n    arrange(desc(proportion))\nhead(condition_fear, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 5\n   word      sentiment condition     n proportion\n   <chr>     <chr>     <chr>     <int>      <dbl>\n 1 unhealthy fear      Unhealthy    76   0.00882 \n 2 feeling   fear      Healthy      27   0.00346 \n 3 bad       fear      Unhealthy    25   0.00290 \n 4 pandemic  fear      Healthy      14   0.00179 \n 5 feeling   fear      Unhealthy    15   0.00174 \n 6 pandemic  fear      Unhealthy    15   0.00174 \n 7 bad       fear      Healthy      12   0.00154 \n 8 difficult fear      Healthy      11   0.00141 \n 9 worry     fear      Healthy      10   0.00128 \n10 insecure  fear      Unhealthy    10   0.00116 \n11 change    fear      Healthy       9   0.00115 \n12 difficult fear      Unhealthy     9   0.00104 \n13 fire      fear      Unhealthy     9   0.00104 \n14 hospital  fear      Healthy       8   0.00103 \n15 hostile   fear      Unhealthy     8   0.000928\n16 nervous   fear      Healthy       7   0.000897\n17 punished  fear      Unhealthy     6   0.000696\n18 afraid    fear      Healthy       5   0.000641\n19 honest    fear      Healthy       5   0.000641\n20 medical   fear      Healthy       5   0.000641\n```\n\n\n:::\n:::\n\n\n\nJust by looking at the fear emotion alone, I have determined that both conditions use fear words pretty regularly. This likely captures some of the COVID anxiety that participants described in their responses across both conditions. However, looking at the proportion of these words, the most used fear word, \"unhealthy\", occurs three or more times as much as any other word and occurred at this rate in the unhealthy condition. While expected, this does provide evidence that participants are at least paying attention to the instruction prompts in their respective conditions.\n\n::: text-center\n## **Visualization**\n:::\n\nNow I will expand this analysis to all sentiment categories contained in the nrc lexicon and provide some visualizations of this data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Distribution of sentiments across both conditions using nrc (this uses positive/negative/ and 8 emotion words)\n\ndist_sentiments <- nrc %>%\n  inner_join(wordfreq, by = \"word\") %>%\n  group_by(condition, sentiment) %>%\n  summarize(n = sum(n)) %>%\n  mutate(prop = n/sum(n)) %>%\n  arrange(desc(prop))\ndist_sentiments\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 4\n# Groups:   condition [2]\n   condition sentiment        n   prop\n   <chr>     <chr>        <int>  <dbl>\n 1 Healthy   positive      1232 0.283 \n 2 Unhealthy positive      1002 0.197 \n 3 Unhealthy negative       941 0.185 \n 4 Healthy   trust          714 0.164 \n 5 Healthy   anticipation   517 0.119 \n 6 Healthy   negative       469 0.108 \n 7 Unhealthy trust          528 0.104 \n 8 Unhealthy sadness        501 0.0986\n 9 Unhealthy fear           457 0.0900\n10 Unhealthy anticipation   448 0.0882\n11 Healthy   joy            377 0.0865\n12 Unhealthy anger          438 0.0862\n13 Unhealthy disgust        350 0.0689\n14 Healthy   sadness        299 0.0686\n15 Healthy   fear           270 0.0619\n16 Unhealthy joy            254 0.05  \n17 Healthy   anger          189 0.0434\n18 Healthy   surprise       169 0.0388\n19 Unhealthy surprise       161 0.0317\n20 Healthy   disgust        123 0.0282\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dist_sentiments, mapping = aes(x = condition, y = prop, fill = sentiment)) +\ngeom_bar(stat = \"identity\")\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\nResults of this sentiment analysis support the effectiveness of the experiment: that is, participants in the healthy condition provided a greater proportion of positively-valanced words than participants in the unhealthy condition (28.3% vs. 19.7% of words), and participants provided a greater proportion of negatively-valanced words in the unhealthy condition than those in the healthy condition (18.7% vs. 10.8%). Glancing at the ggplot also highlights a greater proportion of anger, disgust, fear and sadness words in the unhealthy condition and a greater proportion of anticipation, joy, and trust words in the healthy condition.\n\nFor the sake of robustness, I will also analyse the corpus of words using the BING and AFINN lexicons. The results should converge on the same point but may be slightly different as different words are used to create each specific lexicon.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Look at different sentiment lexicons - BING (just positive/negative)\n\ndist_sentimentsbing <- BING %>%\n  inner_join(wordfreq, by = \"word\") %>%\n  group_by(condition, sentiment) %>%\n  summarize(n = sum(n)) %>%\n  mutate(prop = n/sum(n))\ndist_sentimentsbing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n# Groups:   condition [2]\n  condition sentiment     n  prop\n  <chr>     <chr>     <int> <dbl>\n1 Healthy   negative    525 0.414\n2 Healthy   positive    744 0.586\n3 Unhealthy negative   1097 0.758\n4 Unhealthy positive    351 0.242\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dist_sentimentsbing, mapping = aes(x = condition, y = prop, fill = sentiment)) +\ngeom_bar(stat = \"identity\")\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#AFINN lexicon - This uses a scale ranging from 5- -5 with higher values indicating more positively associated words; 0 is neutral\n\ndist_sentimentsAFINN <- AFINN %>%\n  inner_join(wordfreq, by = \"word\") %>%\n  group_by(condition, value) %>%\n  summarize(n = sum(n)) %>%\n  mutate(prop = n/sum(n))\n  dist_sentimentsAFINN\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 17 × 4\n# Groups:   condition [2]\n   condition value     n     prop\n   <chr>     <dbl> <int>    <dbl>\n 1 Healthy      -4     2 0.00177 \n 2 Healthy      -3    74 0.0655  \n 3 Healthy      -2   212 0.188   \n 4 Healthy      -1    92 0.0814  \n 5 Healthy       1   195 0.173   \n 6 Healthy       2   443 0.392   \n 7 Healthy       3    95 0.0841  \n 8 Healthy       4    17 0.0150  \n 9 Unhealthy    -4    11 0.00828 \n10 Unhealthy    -3   155 0.117   \n11 Unhealthy    -2   606 0.456   \n12 Unhealthy    -1   174 0.131   \n13 Unhealthy     1   137 0.103   \n14 Unhealthy     2   202 0.152   \n15 Unhealthy     3    35 0.0263  \n16 Unhealthy     4     8 0.00602 \n17 Unhealthy     5     1 0.000752\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dist_sentimentsAFINN, mapping = aes(x = condition, y = prop, fill = value)) +\ngeom_bar(stat = \"identity\")\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\n\nJust as I predicted, the results converge on the same point! An additional piece of information gleamed from the AFINN sentiment analysis is that no participant in either condition utilized verbiage that could be classified as extremely positive (a score of 5 in AFINN) or extremely negative (a score of -5 in AFINN).\n\n::: text-center\n### **Additional Visualizations**\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dist_sentimentsAFINN, aes(x = value, fill = condition)) + \n  geom_density(alpha = 0.5) + \n  theme_gdocs() +\n  ggtitle(\"AFINN Score Densities\")\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(reshape2)\n\nwordfreq %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"red\", \"blue\"),\n                   max.words = 200, scale=c(0.50,0.50), title.size = 1.5)\n```\n\n::: {.cell-output-display}\n![](NLPSentiment_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n",
    "supporting": [
      "NLPSentiment_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}