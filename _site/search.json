[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Matthew Swanson, Ph.D.",
    "section": "",
    "text": "I am a recent Ph.D. graduate from the University of Nebraska Omaha’s Industrial Organizational (IO) Psychology program. My research focuses primarily on diversity, equity, and inclusion (DEI) in organizations, especially concealable identities (e.g., religious identity, LGBTQ+ identity, and disability), meaningful work, data analysis and statistical techniques, and authentic self-expression.\n‍\nI am excited to present my portfolio showcasing my academic and professional accomplishments. This portfolio reflects my expertise in research design, data analysis, consulting, as well as my commitment to continuous learning and self-development. Step into the world of IO psychology with me, where the science of human behavior and performance in the workplace meets the art of creating meaningful and impactful change. If you want to learn more about my journey thus far, feel free to head over to my about page!\nCheck out my current articles at IOATWORK:\nWhy Allyship Is Important For Transgender Employees\nWhen Will Employees Speak Up In Response to Abusive Leadership?\nWhen I was a graduate student, I created several department Newsletters:\nThe University of Nebraska Omaha’s 2020 IO department newsletter\nThe University of Nebraska Omaha’s 2021 IO department newsletter"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Matthew Swanson, Ph.D.",
    "section": "",
    "text": "Welcome!\n\n\n\n\n\nI’m an IO psychologist who has spent the past 7 years gaining knowledge and expertise in the areas of organizational effectiveness, data analysis, DEI, and statistical methodology. My current stream of research centers on organizational conflict management, addressing systems of racial disparity in higher education, and promoting employee authenticity.\n\nMy goal with this website is to showcase my current skill set and provide a platform for others interested in IO psychology and data analytics to hopefully learn something about the field.\n\n\nMy Career Thus Far\n\n\n\n\n\nI have worked in both industry and academia and have learned a lot over these years! I’ve had the pleasure of teaching and supporting graduate level analysis of variance (ANOVA) at the University of Nebraska Omaha using both SAS and R for the past three years. While COVID certainly added barriers to the teaching process, it gave me a great opportunity to learn and teach data analysis in R at the graduate level (hence the Zoom screenshot).\nConcurrently, I’ve helped organizations recognize, analyze, and address common issues such as turnover, training effectiveness, and job performance. I have also helped organizations survey and assess the DEI climate of their workforce, worked with selection procedures to determine adverse impact, built statistical models to predict turnover likelihood, worked on developing psychometrically sound assessments, and served as lead on qualitative and quantitative data collection efforts. Additionally, I have served as a guest editor for the Journal of Social Issues and as editor for research conferences and academic awards.\nIn my spare time I love jamming out with my cello!\n\n\nDissertation\n\nI spent a lot of time working on my dissertation and I would love to share what I found with anyone interested! For my dissertation, I studied how organizational psychological safety (which I experimentally manipulated) influenced perceptions of authenticity at work as well as feelings of well-being and belongingness for both heterosexual and LGBTQ employees. My dissertation was also mixed-methods, so I got to assess the qualitative nuance behind participant’s perceptions of psychologically safe and unsafe work experiences!\nMy dissertation is hosted on ProQuest. I am currently reworking it for publication so be on the lookout for that article!"
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume / CV",
    "section": "",
    "text": "Education\n\n\n\n\n\n\n\n\n\n2019 - 2022\nUNIVERSITY OF NEBRASKA OMAHA\nPh.D. in Industrial Organizational Psychology\nGPA = 4.00\n2016 - 2018\nUNIVERSITY OF Akron\nM.A. in Industrial Organizational Psychology\nGPA = 3.78\n2013 - 2016\nKENT STATE UNIVERSITY\nB.S. in Psychology\nGPA = 3.75\n\n\n\n\n\n\n\n\n\nExperience\n\n\n\n\n\n\n\n\nWORK EXPERIENCE:\n2022 - Present\nWriter - IOATWORK\n\nTranslated academic research to an applied audience via monthly research article reviews\nAssessed and reported research designs and advanced statistics to a practitioner audience\n\n\n\n\n2019 - 2021\nExternal Consultant - The Center for Applied Psychological Services\n\nActed as project lead and managed data collection procedures (both for large- and small-scale data sets)\nAnalyzed big data using Excel, SPSS, and R to create and present technical reports\nUtilized dashboard/visualization toolsets (Tableau) for data presentation and analysis\nServed as the expert for people analytics and data reporting\nDeveloped Knowledge, Skills, & Ability-linked items for evidence-based employee selection\nConducted a variety of data analyses (Regression, Validity, Frequencies, Data Visualization)\nWorked with law enforcement to develop officer promotional exams\n\n\n\n\n2017 - 2019\nIO Analyst, Client Solutions & Program Management - Corporate College\n\nConducted job analyses and redesigned hiring procedures and evaluative criteria\nDeveloped over 70 evidence-based training courses targeting workplace competencies such as Diversity, Equity, and Inclusion, change management, and accountability\nEnsured data quality and proper collection standards Converted data into business insights through predictive modeling\nCreated predictive models to assess satisfaction, turnover, and organizational climate & culture\nImproved the frontline and leadership talent of dozens of clients via organizational training\nWorked with companies like American Greetings, Cleveland Cavalier and Oatey to address absenteeism and training issues, resulting in healthier work environments and improved retention\nTrained a small team on how to evaluate and score evaluations\n\n\n\n\n2017 - 2017\nConsultant - Center for Organizational Research\n\nConducted data analyses and compiled results into professional reports\nCustomized tests, measures, survey, and selection systems\nCreated and validated surveys to assess perceptions of success for client’s internal projects\n\n\n\n\n\n\n\n\n\n\n\nTEACHING AND PROFESSIONAL ACTIVITIES:\n2019 - 2022\nTeaching Assistant - University of Nebraska Omaha\n\nDeveloped course content, taught graduate-level R coding, and graded coursework\nLectured weekly for graduate-level analysis of variance (ANOVA)\n\n\n\n\n2020 - 2023\nConference Reviewer\n\nReviewed submissions, provided feedback, and determined application status for research submitted to the following conferences:\n\nMidwest Academy of Management\nSociety for the Psychological Study of Social Issues\nReviewer for APS Student Research & Grant Award\n\n\n\n\n\n2023 - 2023\nJournal Editor\n\nServed as Guest Editor for a special edition of the Journal of Social Issues\n\n\n\n\n\n\n\n\n\n\n\nRESEARCH EXPERIENCE:\n2019 - Present\nLab Researcher - Diversity and Inclusion Research Lab\n\nProvided input to research methodology and presentation efforts\nDeveloped empirical work to test questions regarding diversity and inclusion at work\nAnalyzed data sets using R, SPSS, SAS, and Python, and wrote empirical findings for both academic and practitioner audiences\n\n\n\n\n2019 - 2021\nExternal Research Consultant - Tri-Faith\n\nServed as a research consultant to Tri-Faith’s research initiatives\nHelped align project ideas with research questions\n\n\n\n\n2015 - 2016\nResearch Assistant - Emotion, Stress, and Relationships Lab\n\nOversaw clinical trials targeted at developing a language-based psychotherapy\n\n\n\n\n\nConference Presentations & Posters\n\nFolberg, A., Votruba, A., Marshburn, C., Swanson, M., Crawford, D., Kaiser, C. (2023). Reimagining Resolution: Addressing Racism in Academic Institutions with Conflict Resolution. Interactive discussion to be presented at the annual conference for the Society for the Psychological Study of Social Issues, Denver, CO.\n\nXimenes, M., Folberg, A., Swanson, M. A., Dueland, L., Stepanek, S., Ryan C. (2023). The Role of Conservatism in Evaluations of Diversity Statements. Poster to be presented at the Midwestern Psychological Association, Chicago, IL.\n\nSwanson, M. A.(2022). Can I Remain True to Myself at Work? An Experimental Study of Psychologically Safe versus Unsafe Workplaces on LGBTQ+ and Heterosexual Perceptions of Authenticity, Belongingness, Vigilance, and Resiliency. Poster presented at the Student Research and Creative Activity Fair, Omaha, NE. \n\nStepanek, S., Dueland, L., Folberg, A. M., Swanson, M. A., & Ryan, C. S. (2021).Whites (vs. Blacks) and conservatives exhibit less interest in applying for jobs that request diversity statements in application materials. Poster presented at the annual conference of the Association for Psychological Science, Virtual. \n\n‍Swanson, M. A.(2021). Essential Meaningful Work: A Multistage Proposal for the Development and Validation of the Essential Meaningful Work Inventory (EMWI). Poster presented at the annual conference of the Association for Psychological Science, Virtual. \n\nCrawford, D., Swanson, M. A., Dueland, L. B., Stepanek, S., & Ryan, C. (2021). A Missing Component of Diversity Training and Diversity Initiatives: Conflict Management Training. Poster presented at the annual conference for the Society for the Psychological Study of Social Issues, Virtual.\n\n‍Dodds, B. L., Ryan, C. S., Swanson, M. A. (2021). The Relationships of Perceived Parental Social Support to Vigilance and Resilience among LGBTQ and Straight Cisgender Adults. Poster presented at the University of Nebraska Omaha’s University Honors Program, Omaha, NE. \n\nDueland, L. B., Folberg, A. M., Swanson, M. A., & Ryan, C. S. (2020). Perceptions of Requests for Diversity Statements in Job Advertisements. Poster presented at the annual meeting of the Society for the Psychological Study of Social Issues, Denver, CO. (Conference cancelled) \n\nCrawford, D., Swanson, M. A., Dueland, L. B., Stepanek, S., & Ryan, C. (2020).Conflict management techniques within diversity initiatives: A critical missing link. Interactive discussion facilitated at the Society for the Psychological Study of Social Issues Conference, Denver, CO. (Conference cancelled) \nDueland, L. B., Folberg, A., Swanson, M. A., & Ryan, C. (2020). Reactions to selection processes involving diversity statements. Poster presented at the Society for Industrial Organizational Psychology Conference, Austin, TX.(Conference cancelled) \n\n‍Swanson,M. A. (2015) The Effects of Positive Teacher-Child Relationships on School Achievement and Motivation in Adolescence. Poster presented at the Undergraduate Research Conference, Kent, OH.\n\nSkills & Coursework\n\n\n\n\n\n\n\n\nSkills\nCoursework\n\n\nStatistical Analysis Software: R, SPSS,PROCESS, SAS, Excel, Mplus, LIWC, SQL\n\nExperience using SQL, R, Python, SAS, Mplus, and SPSS for predictive data modeling and analyses\nExpertise in qualitative data collection and analysis procedures using natural language processing and textual analysis with programs like R and LIWC\nWed design using HMTL, YAML and CSS\n\nData Collection Software: Qualtrics, Survey Monkey, Cloud Research\n\nData sets ranged from a few dozen to over 50,000 sampled individuals\n\n\nAfrican American Psychology\nDiversity in Organizations\nGroups and Teams\nIndustrial Motivation and Morale\nLeadership\nLearning\nMultilevel Modeling in R\nResearch Methods\nSocial Psychology\nStructural Equation Modeling\nAdvanced Psychological Tests and Measurements\nIndustrial Organizational Psychology\nMultivariate and Computational Methods in Psychology\nOrganizational Psychology\nPerformance Feedback and Evaluations\nPersonnel Selection and Advanced App Test ISS\nPsychological Research: Quantitative and Computational Methods 1\nPsychological Research: Quantitative and Computational Methods 2\nRole of Attitudes and Values in Industrial Organizational Psychology\nTraining"
  },
  {
    "objectID": "Resume.html#conference-presentations-posters",
    "href": "Resume.html#conference-presentations-posters",
    "title": "Resume / CV",
    "section": "Conference Presentations & Posters",
    "text": "Conference Presentations & Posters"
  },
  {
    "objectID": "Resume.html#skills-coursework",
    "href": "Resume.html#skills-coursework",
    "title": "Resume / CV",
    "section": "Skills & Coursework",
    "text": "Skills & Coursework"
  },
  {
    "objectID": "Mainblog.html",
    "href": "Mainblog.html",
    "title": "Matthew Swanson’s Blog",
    "section": "",
    "text": "Welcome To My Blog!\n\n\n1 min\n\n\n\nIntro\n\n\n1st Post\n\n\n\n\n\n\n\nMatthew Swanson\n\n\nApr 25, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog pages/Mainblog.html",
    "href": "blog pages/Mainblog.html",
    "title": "Matthew Swanson’s Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog pages/Welcome Blog.html",
    "href": "blog pages/Welcome Blog.html",
    "title": "Welcome To My Blog!",
    "section": "",
    "text": "Hello and welcome to my first post! As a passionate enthusiast of of Industrial Organizational Psychology, data analysis, and coding, I am thrilled to share my insights, experiences, and knowledge through this platform. Whether you’re a fellow professional in the field or simply curious about these topics, this blog aims to provide engaging and informative content that will ignite your curiosity and spark insightful discussions. So, grab your favorite beverage, settle in, and let’s embark on this exciting journey together!\n\nI believe my next blog post will discuss the importance of contrast coding and its application to people analytics. Stay tuned for that!"
  },
  {
    "objectID": "Portfolio pages/Repeated Measures.html",
    "href": "Portfolio pages/Repeated Measures.html",
    "title": "Does Birth Order Impact SAT Scores?",
    "section": "",
    "text": "The overarching goal of this project is to teach readers how to run a repeated measures ANOVA in R. I will walk through the code below but readers should be familiar with R code prior to working through this code.\nThis data contains SAT scores for six families, with each family consisting of an older, middle, and younger child. Higher values indicate better SAT scores. I am interested in assessing if birth order in a family with three children effects the child’s SAT score.\nFirst I will need to read in the data and a few packages. I only do a bit of cleaning at this stage (i.e., reformatting the dataframe) so prior data cleaning should have already been completed.\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ez)\nlibrary(tidyr)\nlibrary(tidyverse)\n\nhead(Data)\n\n# A tibble: 6 × 4\n  family young middle oldest\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1      1    54     55     65\n2      2    48     63     59\n3      3    57     54     67\n4      4    61     61     62\n5      5    63     60     61\n6      6    52     54     55\nIf you look at the data file, you will notice that participants are listed column wise and not row wise since the same family has multiple evaluation points (i.e., three children in a family). I need to flip this so that the data is in long form.\n#Need to convert data set to long format - it is currently in wide format\n\nDataLong &lt;- Data %&gt;%\ngather(key = \"order\", value = \"score\", young, middle, oldest) \n#I called these new variables order and score (you can name them what you like so long as it makes sense). \n\n#Here you want to gather by the grouping factor and make sure the values by group are contained in a new variable, row-wise\n\nDataLong$family &lt;- as.factor(DataLong$family)\nDataLong$order &lt;- as.factor(DataLong$order)\nDataLong\n\n# A tibble: 30 × 3\n   family order score\n   &lt;fct&gt;  &lt;fct&gt; &lt;dbl&gt;\n 1 1      young    54\n 2 2      young    48\n 3 3      young    57\n 4 4      young    61\n 5 5      young    63\n 6 6      young    52\n 7 7      young    43\n 8 8      young    69\n 9 9      young    50\n10 10     young    58\n# … with 20 more rows\nCheck how the long version of this data set and the original data set compare. This should help signal how I converted the data to long form and why I had to do so. Next, I want to check that the design is balanced. Unbalanced designs typically violate important assumptions of equal variance (among other issues) so great caution should be taken when conducting unbalanced repeated measures ANOVA.\nDataLong %&gt;%\ngroup_by(order) %&gt;%\nsummarise(n = n(), sd = sd(score), var = var(score))\n\n# A tibble: 3 × 4\n  order      n    sd   var\n  &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 middle    10  6.09  37.1\n2 oldest    10  8.63  74.4\n3 young     10  7.71  59.4\nEach cell has the same n size so this design is balanced. Now I am going to run this repeated measures ANOVA three different ways to get different information and so that subsequent functions have the correct object to run. Let’s assess if birth order in a family with three children effects the child’s SAT score.\nRepeated &lt;- ezANOVA(DataLong, dv = score, wid = family, within = order, detailed = TRUE, return_aov = TRUE)\n\nRepeated\n\n$ANOVA\n       Effect DFn DFd         SSn       SSd          F            p p&lt;.05\n1 (Intercept)   1   9 98957.63333 1267.3667 702.731675 7.476640e-10     *\n2       order   2  18    95.26667  270.7333   3.166954 6.630493e-02      \n         ges\n1 0.98469487\n2 0.05832534\n\n$`Mauchly's Test for Sphericity`\n  Effect       W         p p&lt;.05\n2  order 0.96018 0.8499836      \n\n$`Sphericity Corrections`\n  Effect       GGe      p[GG] p[GG]&lt;.05      HFe      p[HF] p[HF]&lt;.05\n2  order 0.9617049 0.06888936           1.217684 0.06630493          \n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 57.43333\n\nStratum 1: family\n\nTerms:\n                Residuals\nSum of Squares   1267.367\nDeg. of Freedom         9\n\nResidual standard error: 11.8667\n\nStratum 2: family:order\n\nTerms:\n                    order Residuals\nSum of Squares   95.26667 270.73333\nDeg. of Freedom         2        18\n\nResidual standard error: 3.878239\nEstimated effects may be unbalanced\n\nModel &lt;- aov(score ~ order + Error(family/order), DataLong) \n#Because order is crossed with the random factor family (i.e., each order exists in a particular family), you must specify the error term for order, which in this case is family by order. Do this by adding the term Error(family/order) to the factor order, as shown above.\n\nsummary(Model)\n\n\nError: family\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals  9   1267   140.8               \n\nError: family:order\n          Df Sum Sq Mean Sq F value Pr(&gt;F)  \norder      2  95.27   47.63   3.167 0.0663 .\nResiduals 18 270.73   15.04                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(rstatix)\nSphereCorr &lt;- anova_test(DataLong, dv = score, wid = family, within = order)\nSphereCorr\n\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd     F     p p&lt;.05   ges\n1  order   2  18 3.167 0.066       0.058\n\n$`Mauchly's Test for Sphericity`\n  Effect    W    p p&lt;.05\n1  order 0.96 0.85      \n\n$`Sphericity Corrections`\n  Effect   GGe      DF[GG] p[GG] p[GG]&lt;.05   HFe      DF[HF] p[HF] p[HF]&lt;.05\n1  order 0.962 1.92, 17.31 0.069           1.218 2.44, 21.92 0.066\nResults indicate that there is no order effect here on SAT scores, F(2, 18) = 3.17, p = .066 (effect is marginal so we will interpret it for the sake of this example).\nSome notes on the output: GES refers to the generalized eta square value. W refers to the Machly’s W statistic, a non-significant p value indicates that sphericity assumption is met. GGe is the greenhouse-geisser epsilon value and HFe is the Huynh-Feldt epsilon value (use these tests if the spherictiy assumption isn’t met). If you want the correct df for either epsilon value, look at the output from the “anova_test” function.\nNote that sphericity output is only provided when you have at least 3 factors for an IV (the results are the same for 2 levels of a factor so no output is provided).\n# Post Hoc Testing\nlibrary(emmeans)\n\nCell_Means &lt;- emmeans(Model, ~ order)\nCell_Means\n\n order  emmean   SE df lower.CL upper.CL\n middle   57.0 2.39 13     51.8     62.2\n oldest   59.8 2.39 13     54.6     65.0\n young    55.5 2.39 13     50.3     60.7\n\nWarning: EMMs are biased unless design is perfectly balanced \nConfidence level used: 0.95 \n\npwc &lt;- DataLong %&gt;%\npairwise_t_test(score ~ order, paired = TRUE,p.adjust.method = \"bonferroni\")\n\npwc\n\n# A tibble: 3 × 10\n  .y.   group1 group2    n1    n2 statistic    df     p p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       \n1 score middle oldest    10    10    -1.51      9 0.164 0.492 ns          \n2 score middle young     10    10     0.841     9 0.422 1     ns          \n3 score oldest young     10    10     2.76      9 0.022 0.066 ns\nUsing the pairwise t test code above, I can compare levels of the factor to each other just like in previous weeks. For example, t-test results indicate that the oldest siblings had marginally larger SAT scores (M = 59.8) than the youngest siblings (M = 55.5) within each family t(9) = 2.76, p = .07. Again, none of these results meet traditional p-value cutoff scores, so we would conclude that SAT scores did not depend on birth order.\nIn this data, children were ordered by birth and grouped within family and SAT values were compared between children. However, all data were collected at one time point. How might this data be analyzed if each child had multiple SAT scores? I cover how to conduct a between and within repeated measures ANOVA in another project already posted in my portfolio tab so feel free to check it out if you are curious!"
  },
  {
    "objectID": "Portfolio pages/NLPSentiment.html",
    "href": "Portfolio pages/NLPSentiment.html",
    "title": "NLP Sentiment Analysis",
    "section": "",
    "text": "For this project, I am working with a large scale qualitative data set of responses to a research question by adult employees in the United States. There are over 50,000 words housed in several hundred rows of participant responses and it is of interest to the researcher (me) to understand if there are unique words used in one particular condition. It was also of interest to determine if the characteristics of participant’s shaped what words they utilized to respond to the experimental prompt.\nI decided to use Natural Language Processing, in particular sentiment analysis, to analyze the words present in the data set. I also decided to set my tokenization parameter at the word level.\nFirst, I need to load in the data and set the tokenization of the text corpus.\nlibrary(tidytext)\nlibrary(readxl)\nlibrary(tidyverse)\nglimpse(HealthResp)\n\nRows: 595\nColumns: 2\n$ ProlificID             &lt;chr&gt; \"5e8ea20ad1aa0d164f407023\", \"6029785ce4c6ff34c7…\n$ Healthy_Work_Condition &lt;chr&gt; NA, NA, NA, \"Last week one of the employees hus…\n\nHealthResp_tidy &lt;- HealthResp %&gt;%\nunnest_tokens(output = word, input = Healthy_Work_Condition, token = \"words\")\nhead(HealthResp_tidy)\n\n# A tibble: 6 × 2\n  ProlificID               word \n  &lt;chr&gt;                    &lt;chr&gt;\n1 5e8ea20ad1aa0d164f407023 &lt;NA&gt; \n2 6029785ce4c6ff34c77a50ea &lt;NA&gt; \n3 60380d3c5275b918ad26e8b5 &lt;NA&gt; \n4 5d9e9204340c7700150ab74c last \n5 5d9e9204340c7700150ab74c week \n6 5d9e9204340c7700150ab74c one\nI can see that the tokenization was successful since each word has been separated as its own row, grouped at the participant level. Now lets look at some basic things such as word frequencies and counts.\nhead(HealthResp_tidy %&gt;%\ncount(word, sort= TRUE), n = 10)\n\n# A tibble: 10 × 2\n   word      n\n   &lt;chr&gt; &lt;int&gt;\n 1 to     1008\n 2 and     988\n 3 i       952\n 4 the     746\n 5 a       732\n 6 my      562\n 7 was     489\n 8 of      410\n 9 me      407\n10 that    376\nAs revealed in the tibble above, the 10 most used words are articles and connectives, and likely will not be of use to my analysis. I want to remove these words but also take a conservative approach so that I don’t remove too many words that might be of interest. The tidytext package has a data set called “stop_words” containing a lexicon of words comprised of article words such as “to”, “and”, “the” which I would like to remove.\ndata(\"stop_words\")\n\nHealthResp_tidy &lt;- anti_join(HealthResp_tidy, stop_words)\n\nHealthResp_Freq &lt;- HealthResp_tidy %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  filter(word != \"NA\")\n\nhead(HealthResp_Freq, n = 10)\n\n# A tibble: 10 × 2\n   word            n\n   &lt;chr&gt;       &lt;int&gt;\n 1 time          110\n 2 job            95\n 3 environment    87\n 4 feel           83\n 5 team           77\n 6 healthy        74\n 7 stands         72\n 8 boss           67\n 9 day            65\n10 moment         56\nNow the most frequent words better reflect words of interest to my sentiment analysis. Before moving forward, I visualized the frequency of words that occurred over 50 times in participant’s responses.\nlibrary(ggthemes)\nHealthResp_Freq %&gt;%\n  filter(n &gt; 50) %&gt;%\n  filter(word != \"NA\") %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n    ggplot(aes(word, n)) +\n    geom_bar(stat = \"identity\") +\n    xlab(NULL) +\n    coord_flip() +\n    ggtitle(\"Most Commonly Used Words\\n in Healthy Condition\") +\n    theme_clean()\nI also created a word cloud visualization of these words, setting the parameters to a max of 50 words used in the visualization.\nlibrary(wordcloud)\nlibrary(RColorBrewer)\n\nHealthResp_Freq %&gt;%\nwith(wordcloud(word, n, max.words = 100, colors = brewer.pal(12, \"Paired\"), scale=c(3.5,0.25)))\nYou may have noticed that I have only been analyzing words from one condition, called healthy. It is now time to repeat the above analysis for the second condition, called unhealthy.\nglimpse(UnhealthResp)\n\nRows: 595\nColumns: 2\n$ ProlificID               &lt;chr&gt; \"5e8ea20ad1aa0d164f407023\", \"6029785ce4c6ff34…\n$ Unhealthy_Work_Condition &lt;chr&gt; \"My job involves processing payroll, however,…\n\nUnhealthResp_tidy &lt;- UnhealthResp %&gt;%\n  unnest_tokens(output = word, input = Unhealthy_Work_Condition, token = \"words\") %&gt;%\n    anti_join(stop_words, by = \"word\")\n\nUnhealthResp_Freq &lt;- UnhealthResp_tidy %&gt;%\n  count(word, sort = TRUE) %&gt;%\n  filter(word != \"NA\")\nhead(UnhealthResp_Freq, 10)\n\n# A tibble: 10 × 2\n   word            n\n   &lt;chr&gt;       &lt;int&gt;\n 1 job           149\n 2 time          106\n 3 feel          102\n 4 environment    79\n 5 unhealthy      76\n 6 people         74\n 7 stands         73\n 8 boss           72\n 9 supervisor     65\n10 manager        61\nI will now generate some visualizations of this condition before comparing the two conditions.\nUnhealthResp_Freq %&gt;%\n  filter(n &gt; 50) %&gt;%\n  filter(word != \"NA\") %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n    ggplot(aes(word, n)) +\n    geom_bar(stat = \"identity\") +\n    xlab(NULL) +\n    coord_flip() +\n    ggtitle(\"Most Commonly Used Words\\n in Unhealthy Condition\") +\n    theme_clean()\n\n\n\nUnhealthResp_Freq %&gt;%\nwith(wordcloud(word, n, max.words = 100, colors = brewer.pal(9, \"Set1\"), scale=c(3.5,0.25)))\nI’ve looked at each condition separately, now I will merge the two cleaned data sets back together and run analyses on this new data set.\nnames(HealthResp_tidy)\n\n[1] \"ProlificID\" \"word\"      \n\nnames(UnhealthResp_tidy) #Both data sets now have the same names for all variables in the same order\n\n[1] \"ProlificID\" \"word\"      \n\nwordfreq &lt;- bind_rows(mutate(HealthResp_tidy, condition = \"Healthy\"),mutate(UnhealthResp_tidy, condition = \"Unhealthy\"))\n\nwordfreqtotal &lt;- wordfreq %&gt;%\n  count(condition, word) %&gt;%\n  group_by(condition) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  select(condition, word, proportion) %&gt;%\n  spread(condition, proportion) %&gt;%\n    filter(Healthy &gt; .002 | Unhealthy &gt; .002)\n\nhead(wordfreqtotal, 10)\n\n# A tibble: 10 × 3\n   word         Healthy Unhealthy\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1 ago         0.00333   0.00325 \n 2 angry       0.000513  0.00302 \n 3 bad         0.00154   0.00290 \n 4 boss        0.00859   0.00835 \n 5 call        0.00128   0.00209 \n 6 called      0.00179   0.00255 \n 7 care        0.00359   0.00104 \n 8 cared       0.00218   0.000696\n 9 client      0.000897  0.00290 \n10 comfortable 0.00205   0.00139\nThis new data frame contains three columns: the first column contains the utilized words, the second column is the proportion that a particular word appears across all words used in the healthy condition, the third column is the same as the second column except the proportion is compared to words used in the unhealthy condition. Like above, it is important to visualize these words in conjunction to each other.\nggplot(data = wordfreqtotal, mapping = aes(x = Healthy, y = Unhealthy, label = word)) +\n  scale_x_log10() + scale_y_log10() +\n  geom_text(alpha = .7, size = 3) +\n  geom_abline(lty = 2) +\n  theme_few()\nWords closer to the diagonal line appear at similar rates in both conditions while words farther out to the top-left or bottom-right occur more in the unhealthy or healthy condition, respectively. For example, words like coworker, manager, job, and COVID are right on the diagonal line, indicating that they occurred for similar proportions in both conditions. This makes sense as the original prompt presented to participants asked about their job experiences in 2020-21. However, words like care, supportive, and understanding occurred more frequently in the healthy condition while words like angry, uncomfortable, and bad occurred more often in the unhealthy condition.\nNow that I have a good feel about the sorts of words that participants used to describe their work experiences across and within conditions, I want to analyze the word tokens for emotional valance (i.e., the general perception of positive or negative contained within the words used in each condition).\nlibrary(textdata)\n\nnrc &lt;- get_sentiments(\"nrc\")\nAFINN &lt;- get_sentiments(\"afinn\")\nBING &lt;- get_sentiments(\"bing\")\n\nsort(unique(nrc$sentiment)) #Use this to see the unique codes that are present in the nrc sentiment column\n\n [1] \"anger\"        \"anticipation\" \"disgust\"      \"fear\"         \"joy\"         \n [6] \"negative\"     \"positive\"     \"sadness\"      \"surprise\"     \"trust\"       \n\nwordfreq &lt;- bind_rows(mutate(HealthResp_tidy, condition = \"Healthy\"),\n  mutate(UnhealthResp_tidy, condition = \"Unhealthy\"))%&gt;%\n    count(condition, word) %&gt;%\n    group_by(condition) %&gt;%\n  mutate(proportion = n / sum(n))\nThe nrc, afinn, and bing sentiments compare a corpus of words to their predefined emotions or word valance lexicons. For example, evaluating corpus sentiments using the nrc column evaluates the degree of emotions or feelings like anger, anticipation, and disgust present in the analyzed corpus. You can find more detailed information about the nrc sentiment data frame here.\nBecause I want to provide evidence that the experimental conditions produced differently valanced words in either condition, determining how positive or negative the overall words used in either condition is important. I will first analyze by a particular emotion and then will use all three popular sentiment lexicons to get a more complete understanding of the sentiments that participants had in both conditions.\n#Look at the proportion of fear based words per condition\n\ncondition_fear &lt;- nrc %&gt;%\n  filter(sentiment == \"fear\") %&gt;%\n    inner_join(wordfreq, by = \"word\") %&gt;%\n    arrange(desc(proportion))\nhead(condition_fear, 20)\n\n# A tibble: 20 × 5\n   word      sentiment condition     n proportion\n   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1 unhealthy fear      Unhealthy    76   0.00882 \n 2 feeling   fear      Healthy      27   0.00346 \n 3 bad       fear      Unhealthy    25   0.00290 \n 4 pandemic  fear      Healthy      14   0.00179 \n 5 feeling   fear      Unhealthy    15   0.00174 \n 6 pandemic  fear      Unhealthy    15   0.00174 \n 7 bad       fear      Healthy      12   0.00154 \n 8 difficult fear      Healthy      11   0.00141 \n 9 worry     fear      Healthy      10   0.00128 \n10 insecure  fear      Unhealthy    10   0.00116 \n11 change    fear      Healthy       9   0.00115 \n12 difficult fear      Unhealthy     9   0.00104 \n13 fire      fear      Unhealthy     9   0.00104 \n14 hospital  fear      Healthy       8   0.00103 \n15 hostile   fear      Unhealthy     8   0.000928\n16 nervous   fear      Healthy       7   0.000897\n17 punished  fear      Unhealthy     6   0.000696\n18 afraid    fear      Healthy       5   0.000641\n19 honest    fear      Healthy       5   0.000641\n20 medical   fear      Healthy       5   0.000641\nJust by looking at the fear emotion alone, I have determined that both conditions use fear words pretty regularly. This likely captures some of the COVID anxiety that participants described in their responses across both conditions. However, looking at the proportion of these words, the most used fear word, “unhealthy”, occurs three or more times as much as any other word and occurred at this rate in the unhealthy condition. While expected, this does provide evidence that participants are at least paying attention to the instruction prompts in their respective conditions.\nNow I will expand this analysis to all sentiment categories contained in the nrc lexicon and provide some visualizations of this data.\n#Distribution of sentiments across both conditions using nrc (this uses positive/negative/ and 8 emotion words)\n\ndist_sentiments &lt;- nrc %&gt;%\n  inner_join(wordfreq, by = \"word\") %&gt;%\n  group_by(condition, sentiment) %&gt;%\n  summarize(n = sum(n)) %&gt;%\n  mutate(prop = n/sum(n)) %&gt;%\n  arrange(desc(prop))\ndist_sentiments\n\n# A tibble: 20 × 4\n# Groups:   condition [2]\n   condition sentiment        n   prop\n   &lt;chr&gt;     &lt;chr&gt;        &lt;int&gt;  &lt;dbl&gt;\n 1 Healthy   positive      1237 0.283 \n 2 Unhealthy positive      1004 0.197 \n 3 Unhealthy negative       952 0.187 \n 4 Healthy   trust          714 0.163 \n 5 Healthy   anticipation   517 0.118 \n 6 Healthy   negative       472 0.108 \n 7 Unhealthy trust          528 0.103 \n 8 Unhealthy sadness        510 0.0999\n 9 Unhealthy fear           457 0.0895\n10 Unhealthy anticipation   448 0.0878\n11 Healthy   joy            377 0.0863\n12 Unhealthy anger          438 0.0858\n13 Healthy   sadness        302 0.0691\n14 Unhealthy disgust        352 0.0690\n15 Healthy   fear           270 0.0618\n16 Unhealthy joy            254 0.0498\n17 Healthy   anger          189 0.0432\n18 Healthy   surprise       169 0.0387\n19 Unhealthy surprise       161 0.0315\n20 Healthy   disgust        123 0.0281\n\nggplot(data = dist_sentiments, mapping = aes(x = condition, y = prop, fill = sentiment)) +\ngeom_bar(stat = \"identity\")\nResults of this sentiment analysis support the effectiveness of the experiment: that is, participants in the healthy condition provided a greater proportion of positively-valanced words than participants in the unhealthy condition (28.3% vs. 19.7% of words), and participants provided a greater proportion of negatively-valanced words in the unhealthy condition than those in the healthy condition (18.7% vs. 10.8%). Glancing at the ggplot also highlights a greater proportion of anger, disgust, fear and sadness words in the unhealthy condition and a greater proportion of anticipation, joy, and trust words in the healthy condition.\nFor the sake of robustness, I will also analyse the corpus of words using the BING and AFINN lexicons. The results should converge on the same point but may be slightly different as different words are used to create each specific lexicon.\n#Look at different sentiment lexicons - BING (just positive/negative)\n\ndist_sentimentsbing &lt;- BING %&gt;%\n  inner_join(wordfreq, by = \"word\") %&gt;%\n  group_by(condition, sentiment) %&gt;%\n  summarize(n = sum(n)) %&gt;%\n  mutate(prop = n/sum(n))\ndist_sentimentsbing\n\n# A tibble: 4 × 4\n# Groups:   condition [2]\n  condition sentiment     n  prop\n  &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;\n1 Healthy   negative    525 0.414\n2 Healthy   positive    744 0.586\n3 Unhealthy negative   1097 0.758\n4 Unhealthy positive    351 0.242\n\nggplot(data = dist_sentimentsbing, mapping = aes(x = condition, y = prop, fill = sentiment)) +\ngeom_bar(stat = \"identity\")\n\n\n\n#AFINN lexicon - This uses a scale ranging from 5- -5 with higher values indicating more positively associated words; 0 is neutral\n\ndist_sentimentsAFINN &lt;- AFINN %&gt;%\n  inner_join(wordfreq, by = \"word\") %&gt;%\n  group_by(condition, value) %&gt;%\n  summarize(n = sum(n)) %&gt;%\n  mutate(prop = n/sum(n))\n  dist_sentimentsAFINN\n\n# A tibble: 17 × 4\n# Groups:   condition [2]\n   condition value     n     prop\n   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;\n 1 Healthy      -4     2 0.00177 \n 2 Healthy      -3    74 0.0655  \n 3 Healthy      -2   212 0.188   \n 4 Healthy      -1    92 0.0814  \n 5 Healthy       1   195 0.173   \n 6 Healthy       2   443 0.392   \n 7 Healthy       3    95 0.0841  \n 8 Healthy       4    17 0.0150  \n 9 Unhealthy    -4    11 0.00828 \n10 Unhealthy    -3   155 0.117   \n11 Unhealthy    -2   606 0.456   \n12 Unhealthy    -1   174 0.131   \n13 Unhealthy     1   137 0.103   \n14 Unhealthy     2   202 0.152   \n15 Unhealthy     3    35 0.0263  \n16 Unhealthy     4     8 0.00602 \n17 Unhealthy     5     1 0.000752\n\nggplot(data = dist_sentimentsAFINN, mapping = aes(x = condition, y = prop, fill = value)) +\ngeom_bar(stat = \"identity\")\nJust as I predicted, the results converge on the same point! An additional piece of information gleamed from the AFINN sentiment analysis is that no participant in either condition utilized verbiage that could be classified as extremely positive (a score of 5 in AFINN) or extremely negative (a score of -5 in AFINN).\nggplot(dist_sentimentsAFINN, aes(x = value, fill = condition)) + \n  geom_density(alpha = 0.5) + \n  theme_gdocs() +\n  ggtitle(\"AFINN Score Densities\")\n\n\n\nlibrary(reshape2)\n\nwordfreq %&gt;%\n  inner_join(get_sentiments(\"bing\")) %&gt;%\n  count(word, sentiment, sort = TRUE) %&gt;%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %&gt;%\n  comparison.cloud(colors = c(\"red\", \"blue\"),\n                   max.words = 200, scale=c(0.50,0.50), title.size = 1.5)"
  },
  {
    "objectID": "Portfolio pages/NLPSentiment.html#visualization",
    "href": "Portfolio pages/NLPSentiment.html#visualization",
    "title": "NLP Sentiment Analysis",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "Portfolio pages/BWRepeart.html",
    "href": "Portfolio pages/BWRepeart.html",
    "title": "Between and Within Repeated Measures ANOVA in R",
    "section": "",
    "text": "A researcher is interested in how memory for a list of words can be influenced by instructions on how to process the words. She assigns participants to one of three instruction conditions (COND): no instructions (coded as 1), rote memorization (told to just rehearse each word, coded as 2), and image (told to form an image for each word, coded as 3). Participants are presented with a list of 30 words and the researcher records the number out of 30 words that each participant recalls correctly. Because she is interested in practice effects, she presents each subject with two lists, one after another, and records performance on each list (LIST1 and LIST2).\nFirst, I will read in the data and check the data type (i.e., is the data wide or long?).\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ez)\nlibrary(tidyr)\nlibrary(tidyverse)\n\nhead(Data)\n\n# A tibble: 6 × 4\n  subjid  cond list1 list2\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1     1    21    25\n2      2     1    11    12\n3      3     1    15    20\n4      4     1    11    12\n5      5     1    18    15\n6      6     1    12    12\n\n#Need to convert data set to long format - it is currently in wide format\n\n#Changing data to long format - we want to gather by list as this is the repeated variable\nDataLong &lt;- Data %&gt;%\ngather(key = \"list\", value = \"score\", list1, list2)\nDataLong$list &lt;- as.factor(DataLong$list)\nDataLong$cond &lt;- as.factor(DataLong$cond)\nDataLong$subjid &lt;- as.factor(DataLong$subjid)\nhead(DataLong)\n\n# A tibble: 6 × 4\n  subjid cond  list  score\n  &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;\n1 1      1     list1    21\n2 2      1     list1    11\n3 3      1     list1    15\n4 4      1     list1    11\n5 5      1     list1    18\n6 6      1     list1    12\nNow, let’s double check that the design is balanced.\nDataLong %&gt;%\ngroup_by(list, cond) %&gt;%\nsummarise(n = n(), sd = sd(score), var = var(score))\n\n# A tibble: 6 × 5\n# Groups:   list [2]\n  list  cond      n    sd   var\n  &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 list1 1        10  3.33 11.1 \n2 list1 2        10  2.59  6.71\n3 list1 3        10  4.06 16.5 \n4 list2 1        10  4.37 19.1 \n5 list2 2        10  2.42  5.88\n6 list2 3        10  3.73 13.9\nWe have a balanced design. Now let’s analyze the data. We are interested in how memory for a list of words can be influenced by instructions on how to process the words.\nlibrary(rstatix)\nRepeated &lt;- ezANOVA(DataLong, dv = score, wid = subjid, within = list, between = cond, detailed = TRUE, return_aov = TRUE, type = 3)\nRepeated\n\n$ANOVA\n       Effect DFn DFd         SSn    SSd          F            p p&lt;.05\n1 (Intercept)   1  27 13053.75000 584.35 603.150937 5.272153e-20     *\n2        cond   2  27   206.40000 584.35   4.768375 1.684833e-02     *\n3        list   1  27   198.01667  73.95  72.298174 4.077683e-09     *\n4   cond:list   2  27    32.53333  73.95   5.939148 7.283889e-03     *\n         ges\n1 0.95199113\n2 0.23869550\n3 0.23124234\n4 0.04709288\n\n$aov\n\nCall:\naov(formula = formula(aov_formula), data = data)\n\nGrand Mean: 14.75\n\nStratum 1: subjid\n\nTerms:\n                  cond Residuals\nSum of Squares  206.40    584.35\nDeg. of Freedom      2        27\n\nResidual standard error: 4.65216\n2 out of 4 effects not estimable\nEstimated effects may be unbalanced\n\nStratum 2: subjid:list\n\nTerms:\n                     list cond:list Residuals\nSum of Squares  198.01667  32.53333  73.95000\nDeg. of Freedom         1         2        27\n\nResidual standard error: 1.654959\nEstimated effects may be unbalanced\n\n#Additional ways to estimate this model\nModel &lt;- aov(score ~ list*cond + Error(subjid/list), DataLong)\n#summary(Model)\n\n#SphereCorr &lt;- anova_test(DataLong, dv = score, wid = subjid, within = list, between = cond)\n#SphereCorr\n\nlibrary(ggpubr)\n\nbxp &lt;- ggboxplot(DataLong, x = \"list\", y = \"score\",color = \"cond\", palette = \"jco\")\nbxp\nSince the interaction term is significant, F(2,27) = 5.94, p = .047, that means that values in one factor depend, in part, on the values in the other factor so we must look at pairwise comparisons (simple effects and simple effects comparison). As denoted in the figure and output, there are some significant mean memory score differences between list 1 and list 2 of words for each condition.\nLet’s directly calculate these means and the marginal means to aid in our interpretation of this data.\nlibrary(emmeans)\n\n#the pairs function comes from the emmeans package - verbiage should feel similar to emmeans commands in SPSS\nSimpleCond &lt;- emmeans(Model, pairwise ~ cond, adjust = \"bonferroni\")\nSimpleCond\n\n$emmeans\n cond emmean   SE df lower.CL upper.CL\n 1      15.8 1.04 27     13.6     17.9\n 2      12.2 1.04 27     10.0     14.3\n 3      16.4 1.04 27     14.2     18.5\n\nResults are averaged over the levels of: list \nWarning: EMMs are biased unless design is perfectly balanced \nConfidence level used: 0.95 \n\n$contrasts\n contrast      estimate   SE df t.ratio p.value\n cond1 - cond2      3.6 1.47 27   2.447  0.0636\n cond1 - cond3     -0.6 1.47 27  -0.408  1.0000\n cond2 - cond3     -4.2 1.47 27  -2.855  0.0245\n\nResults are averaged over the levels of: list \nP value adjustment: bonferroni method for 3 tests \n\nSimpleList &lt;- emmeans(Model, pairwise ~ list, adjust = \"bonferroni\")\nSimpleList\n\n$emmeans\n list  emmean    SE   df lower.CL upper.CL\n list1   12.9 0.637 33.7     11.6     14.2\n list2   16.6 0.637 33.7     15.3     17.9\n\nResults are averaged over the levels of: cond \nWarning: EMMs are biased unless design is perfectly balanced \nConfidence level used: 0.95 \n\n$contrasts\n contrast      estimate    SE df t.ratio p.value\n list1 - list2    -3.63 0.427 27  -8.503  &lt;.0001\n\nResults are averaged over the levels of: cond\nLet’s interpret a few of these results. Across lists, participants told to form an image of the words in the mind recalled significantly greater words (M = 16.4) than those who practice rote memorization of the words (M = 12.2), t(27) = -2.86, p = 03. Additionally, the practice effect has strongest for participants in the rote memory condition as more words were recalled in the second list (M = 14.9) as compared to the first list (M = 9.4), t(27) = -7.43, p &lt;.001. In other words, participants recalled more words overall when asked to assign an image to each word, however, they learned the best (i.e., the practice effect was the strongest) when they were asked to recall words via rote memory."
  },
  {
    "objectID": "Portfolio pages/FactorialANOVA.html",
    "href": "Portfolio pages/FactorialANOVA.html",
    "title": "Religion and Politics Factorial ANOVA in R",
    "section": "",
    "text": "A client requested to better understand the religious attendance of their constituents and how both their constituent’s race and political identity shape religious attendance (with higher scores indicating greater attendance to religious gatherings/events). Additionally, the client specifically requested to compare White, Black, and Hispanic constituents. Thus, the goal of this project was to clean the data and understand how identity shapes religious attendance.\nFirst, the data needs to be cleaned:\nlibrary(readxl)\nlibrary(dplyr)\n\nData &lt;- subset(Data, PARTYID!= 1 & PARTYID!= 2 & PARTYID!= 3 & PARTYID!= 4 & PARTYID!= 5 & PARTYID!= 9)\nData &lt;- subset(Data, ATTEND!= 9)\nData %&gt;%\nmutate(RACECEN1 = case_when(RACECEN1 == 1 ~ 1,\n                            RACECEN1 ==2 ~ 2,\n                            RACECEN1 ==16 ~ 3,\n                            RACECEN1 ==3 ~ 4,\n                            RACECEN1 ==4 ~ 4,\n                            RACECEN1 == 5 ~ 4,\n                            RACECEN1 ==6 ~ 4,\n                            RACECEN1 ==7 ~ 4,\n                            RACECEN1 ==8 ~ 4,\n                            RACECEN1 ==9 ~ 4,\n                            RACECEN1 == 10 ~ 4,\n                            RACECEN1 ==11 ~ 4,\n                            RACECEN1 ==12 ~ 4,\n                            RACECEN1 ==13 ~ 4,\n                            RACECEN1 ==14 ~ 4,\n                            RACECEN1 ==15 ~ 4,\n                            TRUE ~ 99)) -&gt; Data\n\nData &lt;- subset(Data, RACECEN1!= 99)\nData$PARTYID &lt;- as.factor(Data$PARTYID)\nData$RACECEN1 &lt;- as.factor(Data$RACECEN1)\nData$RACECEN1 &lt;- recode_factor(Data$RACECEN1, '1' = \"White\", '2' = \"Black\", '3' = \"Hispanic\", '4' = \"Other\")\nData$PARTYID &lt;- recode_factor(Data$PARTYID, '0' = \"Democratic\", '6' = \"Republican\", '7' = \"Other\")\nstr(Data)\n\ntibble [797 × 3] (S3: tbl_df/tbl/data.frame)\n $ ATTEND  : num [1:797] 6 0 5 3 6 8 5 2 8 0 ...\n $ PARTYID : Factor w/ 3 levels \"Democratic\",\"Republican\",..: 1 2 1 2 1 1 1 1 1 1 ...\n $ RACECEN1: Factor w/ 4 levels \"White\",\"Black\",..: 2 1 2 1 2 3 2 1 1 1 ...\n\nhead(Data)\n\n# A tibble: 6 × 3\n  ATTEND PARTYID    RACECEN1\n   &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;   \n1      6 Democratic Black   \n2      0 Republican White   \n3      5 Democratic Black   \n4      3 Republican White   \n5      6 Democratic Black   \n6      8 Democratic Hispanic\nThe original “Religion Data 2” has several values in each factor that we do not want to look at (either coded as missing or an ambiguous code like “independent but more democratic”). We also wanted to look at Black, White, Hispanic individuals as compared to the rest of the participants so we need to write code that recodes the race variable into something more meaningful (there is originally 16 levels in this variable - some with just single digit cell sizes). I also wanted to assign labels to each level of the factor to aid in clarity. You can see these new labels reflected in the structure code output.\nNow, let’s build our two-way ANOVA model and look at the output.\nAov &lt;- aov(ATTEND ~ RACECEN1*PARTYID, Data)\nsummary(Aov)\n\n                  Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nRACECEN1           3    228   76.12  10.384 1.05e-06 ***\nPARTYID            2    392  195.88  26.721 5.93e-12 ***\nRACECEN1:PARTYID   6     91   15.14   2.066    0.055 .  \nResiduals        785   5754    7.33                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResults of the two-way ANOVA indicate both a significant main effect for race, F(3,785) = 10.38, p &lt;.001, and for political party, F(2,785) = 26.721, p&lt;.001, and also a marginally significant interaction, F(6,785) = 2.07, p = .06. For the sake of this client’s project, we are going to determine that the marginal p value is close enough to our arbitrary alpha level so we will go ahead and look at the simple effects.\nFirst, we want to get the condition means and the cell means.\nlibrary(emmeans)\n\nCondition_Means &lt;- emmeans(Aov, ~ RACECEN1*PARTYID)\nCondition_Means\n\n RACECEN1 PARTYID    emmean    SE  df lower.CL upper.CL\n White    Democratic   2.75 0.172 785    2.417     3.09\n Black    Democratic   4.88 0.212 785    4.461     5.29\n Hispanic Democratic   4.59 0.577 785    3.458     5.72\n Other    Democratic   3.44 0.541 785    2.377     4.50\n White    Republican   4.44 0.173 785    4.104     4.78\n Black    Republican   4.83 0.782 785    3.299     6.37\n Hispanic Republican   5.00 1.914 785    1.242     8.76\n Other    Republican   4.44 0.902 785    2.673     6.22\n White    Other        2.60 0.365 785    1.883     3.32\n Black    Other        2.50 0.957 785    0.621     4.38\n Hispanic Other        1.33 1.563 785   -1.735     4.40\n Other    Other        4.50 1.354 785    1.843     7.16\n\nConfidence level used: 0.95 \n\nMarginal_MeansRace &lt;- emmeans(Aov, ~ RACECEN1)\nMarginal_MeansRace\n\n RACECEN1 emmean    SE  df lower.CL upper.CL\n White      3.27 0.146 785     2.98     3.55\n Black      4.07 0.418 785     3.25     4.89\n Hispanic   3.64 0.846 785     1.98     5.30\n Other      4.13 0.572 785     3.01     5.25\n\nResults are averaged over the levels of: PARTYID \nConfidence level used: 0.95 \n\nMarginal_MeansParty &lt;- emmeans(Aov, ~ PARTYID)\nMarginal_MeansParty\n\n PARTYID    emmean    SE  df lower.CL upper.CL\n Democratic   3.92 0.209 785     3.50     4.33\n Republican   4.68 0.566 785     3.57     5.79\n Other        2.73 0.577 785     1.60     3.87\n\nResults are averaged over the levels of: RACECEN1 \nConfidence level used: 0.95\nYou can also get these means using the dplyr. However, you have to be cautious on the marginal mean calculation which is why I used the emmeans function.\nNow that we found a significant interaction, we want to look at the simple effects. In other words, we want to look at the relationship between one predictor on the DV, across all levels of the other predictor. The testinteractions function in the phia package allows us to do this. Note that we have to convert our aov model to a lm model to fit the first argument of this function.\nlibrary(phia)\n\nLM &lt;- lm(ATTEND ~ RACECEN1*PARTYID, Data)\nTest1 &lt;- testInteractions(LM, fixed = \"RACECEN1\", across = \"PARTYID\", adjustment = \"bonferroni\")\nTest1\n\nF Test: \nP-value adjustment method: bonferroni\n          PARTYID1 PARTYID2  Df Sum of Sq       F    Pr(&gt;F)    \n   White    0.1540   1.8431   2     401.3 27.3745 1.287e-11 ***\n   Black    2.3773   2.3333   2      43.1  2.9430    0.2132    \nHispanic    3.2576   3.6667   2      29.2  1.9917    0.5486    \n   Other   -1.0600  -0.0556   2       8.9  0.6093    1.0000    \nResiduals                   785    5754.5                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTest2 &lt;- testInteractions(LM, fixed = \"PARTYID\", across = \"RACECEN1\", adjustment = \"bonferroni\")\nTest2\n\nF Test: \nP-value adjustment method: bonferroni\n           RACECEN11 RACECEN12 RACECEN13  Df Sum of Sq       F    Pr(&gt;F)    \nDemocratic  -0.68597   1.43730    1.1509   3     465.1 21.1483 1.052e-12 ***\nRepublican  -0.00136   0.38889    0.5556   3       2.3  0.1056         1    \n     Other  -1.90000  -2.00000   -3.1667   3      19.2  0.8733         1    \nResiduals                                785    5754.5                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResults indicate that the effect of political party within White individuals is significant, F(2,785) = 27.38, p &lt;.001. Results also indicate that the effect of race within Democratic individuals is significant, F(3,785) = 21.15, p &lt;.001. Since we found several significant simple effects, we can now follow it up with a simple effects comparison. This is a pairwise comparison of cell means, similar to post-hocs from a one-way ANOVA. We need to break down the multiple degree of freedom effects into single degree of freedom tests so that we know exactly where the difference lies for each effect.\nSimple &lt;- testInteractions(LM, pairwise = \"RACECEN1\", fixed = \"PARTYID\", adjustment = \"bonferroni\")\nSimple\n\nF Test: \nP-value adjustment method: bonferroni\n                              Value  Df Sum of Sq       F    Pr(&gt;F)    \n   White-Black : Democratic -2.1233   1     443.4 60.4882 4.189e-13 ***\nWhite-Hispanic : Democratic -1.8369   1      68.2  9.3011   0.04261 *  \n   White-Other : Democratic -0.6860   1      10.7  1.4578   1.00000    \nBlack-Hispanic : Democratic  0.2864   1       1.6  0.2169   1.00000    \n   Black-Other : Democratic  1.4373   1      44.8  6.1084   0.24597    \nHispanic-Other : Democratic  1.1509   1      15.5  2.1145   1.00000    \n   White-Black : Republican -0.3902   1       1.7  0.2377   1.00000    \nWhite-Hispanic : Republican -0.5569   1       0.6  0.0839   1.00000    \n   White-Other : Republican -0.0014   1       0.0  0.0000   1.00000    \nBlack-Hispanic : Republican -0.1667   1       0.0  0.0065   1.00000    \n   Black-Other : Republican  0.3889   1       0.8  0.1061   1.00000    \nHispanic-Other : Republican  0.5556   1       0.5  0.0689   1.00000    \n   White-Black :      Other  0.1000   1       0.1  0.0095   1.00000    \nWhite-Hispanic :      Other  1.2667   1       4.6  0.6227   1.00000    \n   White-Other :      Other -1.9000   1      13.5  1.8363   1.00000    \nBlack-Hispanic :      Other  1.1667   1       3.0  0.4051   1.00000    \n   Black-Other :      Other -2.0000   1      10.7  1.4551   1.00000    \nHispanic-Other :      Other -3.1667   1      17.2  2.3450   1.00000    \nResiduals                           785    5754.5                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLooking at the simple effects comparison test output, several results are significant. Specifically, the White-Black difference in religious attendance scores for democrats is significant, F(1, 785) = 60.49, p &lt;.001. Since the value is negative, we know that the mean of Black individuals is larger than the mean of White individuals. Sure enough, the mean religious attendance for White democrats (M = 2.75) is significantly smaller than the mean religious attendance for Black democrats (M = 4.88). Additionally, the White-Hispanic difference for religious attendance for democrats is significant, F(1,785) = 9.30, p = .04. The effect is also negative, so we know the mean for Hispanic democrats is larger. Indeed, the mean religious attendance scores for White democrats (M = 2.75) is smaller than the mean religious attendance scores for Hispanic democrats (M = 4.59). We can also look at more pairwise comparisons (the mean of republican Whites vs. Other Hispanics) - but this requires additional codes and considerations. The pairwise function in the superanova package can do this - it is the commented out lines in the chunk of code above. I will show you the output but we will not interpret these results here (there are over 66 effects tested!).\nWe can also look at interactions by contrast coding for each effect in both main effects and their interactions. This is especially applicable since both main effects and the interaction are significant (while marginal). Since we have a total of 12 groups (3X4 design) we need 11 contrast coded predictors. Race has 4 levels so it needs 3 contrast coded predictors and political party has 3 levels so it needs 2 contrast coded predictors. Then each effect will be crossed, resulting in 5 interaction contrast coded predictors (3 + 2 + 5 = 11). Contrast codes that are assigned to each predictor have to satisfy two conditions to be orthogonal: sum across each group equal zero and the sum of the product of all pairs equal zero (Data Analysis: A Model Comparison Approach to Regression, ANOVA, and Beyond by Judd, McClelland, & Ryan, 2017provides excellent background on the necessity and development of contrast coding for those curious).\nData%&gt;%\nmutate(x1 = case_when(RACECEN1 ==\"White\" ~ -3,\n                      RACECEN1 ==\"Black\" ~ 1,\n                      RACECEN1 ==\"Hispanic\" ~ 1,\n                      RACECEN1 == \"Other\" ~ 1,\n                      TRUE ~ 99),\nx2 = case_when(RACECEN1 ==\"White\" ~ 0,\n                      RACECEN1 ==\"Black\" ~ -2,\n                      RACECEN1 ==\"Hispanic\" ~ 1,\n                      RACECEN1 == \"Other\" ~ 1,\n                      TRUE ~ 99),\nx3 = case_when(RACECEN1 == \"White\" ~ 0,\n                      RACECEN1 == \"Black\" ~ 0,\n                      RACECEN1 == \"Hispanic\" ~ -1,\n                      RACECEN1 == \"Other\" ~ 1,\n                      TRUE ~ 99),\nx4 = case_when(PARTYID == \"Democratic\" ~ -2,\n                      PARTYID == \"Republican\" ~ 1,\n                      PARTYID == \"Other\" ~ 1,\n                      TRUE ~ 99),\nx5 = case_when(PARTYID == \"Democratic\" ~ 0,\n                      PARTYID == \"Republican\" ~ -1,\n                      PARTYID == \"Other\" ~ 1,\n                      TRUE ~ 99),\nx6 = x1 * x4,\nx7 = x1 * x5,\nx8 = x2 * x4,\nx9 = x2 * x5,\nx10 = x3 * x4,\nx11 = x3 * x5) -&gt; Data\n\nAov2 &lt;- aov(ATTEND ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11, Data)\nsummary(Aov2)\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nx1            1    195  195.24  26.634 3.12e-07 ***\nx2            1     30   29.62   4.041  0.04475 *  \nx3            1      3    3.48   0.475  0.49080    \nx4            1    169  169.40  23.109 1.83e-06 ***\nx5            1    222  222.36  30.333 4.93e-08 ***\nx6            1     53   52.62   7.179  0.00753 ** \nx7            1      0    0.11   0.015  0.90155    \nx8            1      9    8.87   1.209  0.27180    \nx9            1      1    1.38   0.188  0.66474    \nx10           1     16   16.28   2.220  0.13660    \nx11           1     12   11.60   1.582  0.20880    \nResiduals   785   5754    7.33                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nNeed to be clear on what each contrast coded predictor codes for:\nx1: difference between White and the average of Black, Hispanic, and other races, across political party\nx2: difference between Black and the average of Hispanic and other races, across political party\nx3: difference between Hispanic and other races, across political party\nx4: difference between democratic and the average of republican and other, across race\nx5: difference between republican and other, across race\nx6-x11: the interaction of the above contrasts\nI won’t interpret all effects that are significant, but let’s look at a few. x1 codes the difference between White individuals and the average of Black, Hispanic, and other races. This effect is significant, F(1,785) = 26.63, p &lt;.001. Page 217 of the textbook will aid in the following information. Since we are comparing White individuals to the average of all other groups across political party, we need to average together some means. The marginal mean for White individuals is 3.27, now we need to get the means for the other racial groups. The average of the other 9 conditions (Black/Hispanic/Other for all 3 political parties) is 3.95 (this is also the mean of the three marginal means of race not include White). So then, x1 is coding the difference between 3.27 and 3.95, which is significant, providing evidence that White individuals attended religious institutions significantly less than the three other racial groups.\nx2 codes the difference between democrats and the average of both republicans and others, across race. Looking at marginal means, this effect is coding the difference between a mean of 3.92 for democrats, and a mean of 3.71 for both republicans and others. This effect is significant, suggesting that democrats attended religious institutions significantly more than both republicans and others, F(1,785) = 23.11, p &lt;.001.\nx6 codes if the difference between White and the average of Black, Hispanic, and other races is the same for democrats and the average of republicans and others. The difference for democrats can be found by getting the difference between mean of White dems and the average of the three other racial groups = this difference is -1.55. This value is being compared to a difference between mean of White republican and other and the average of Black, Hispanic, and other individuals in both republic and other groups - this value is -.25. In other words, Whites were less likely to go to religious attendance than the three other racial groups, and this is more true for White democrats, as compared to White republicans and others."
  },
  {
    "objectID": "Portfolio pages/FactorialANOVA.html#solution-1",
    "href": "Portfolio pages/FactorialANOVA.html#solution-1",
    "title": "Religion and Politics Factorial ANOVA in R",
    "section": "Solution 1",
    "text": "Solution 1"
  },
  {
    "objectID": "Portfolio pages/FactorialANOVA.html#solution-2",
    "href": "Portfolio pages/FactorialANOVA.html#solution-2",
    "title": "Religion and Politics Factorial ANOVA in R",
    "section": "Solution 2",
    "text": "Solution 2"
  },
  {
    "objectID": "Portfolio pages/FactorPower.html",
    "href": "Portfolio pages/FactorPower.html",
    "title": "Factorial Anova and Power Analysis in R",
    "section": "",
    "text": "It is of interest to a client to analyze data from a clinical trial on teeth growth. It is of particular interest to the client to ascertain how different dosage amounts and different types of supplements influence teeth growth. First, we will need to load the data set and calculate data descriptives and run some ANOVAs.\nLoad in data first.\ndata(\"ToothGrowth\")\nhead(ToothGrowth)\n\n   len supp dose\n1  4.2   VC  0.5\n2 11.5   VC  0.5\n3  7.3   VC  0.5\n4  5.8   VC  0.5\n5  6.4   VC  0.5\n6 10.0   VC  0.5\nNeed cell means and variances next.\nlibrary(dplyr)\nToothGrowth %&gt;%\ngroup_by(supp, dose)%&gt;%\nsummarize(group_mean = mean(len), n = n(), var = var(len)) \n\n# A tibble: 6 × 5\n# Groups:   supp [2]\n  supp   dose group_mean     n   var\n  &lt;fct&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1 OJ      0.5      13.2     10 19.9 \n2 OJ      1        22.7     10 15.3 \n3 OJ      2        26.1     10  7.05\n4 VC      0.5       7.98    10  7.54\n5 VC      1        16.8     10  6.33\n6 VC      2        26.1     10 23.0\nGlancing at these cell means a similar patterns seems to emerge. Namely, that across supplement, as dosage increases, tooth length increases. It also appears like across dosage, the OJ supplement produces longer teeth growth than the VC supplement. However, to determine if these mean differences are significant, we will need to conduct a factorial ANOVA.\n#Need to ensure that R reads factor variables as factors first\n\nToothGrowth$supp &lt;- as.factor(ToothGrowth$supp)\nToothGrowth$dose &lt;- as.factor(ToothGrowth$dose)\nFactorANOVA &lt;- aov(len ~ dose*supp, ToothGrowth) #you can also just add in dose*supp and R understands to include the interaction and both main effects in the model - nice way to shorten code\n\nsummary(FactorANOVA)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ndose         2 2426.4  1213.2  92.000  &lt; 2e-16 ***\nsupp         1  205.4   205.4  15.572 0.000231 ***\ndose:supp    2  108.3    54.2   4.107 0.021860 *  \nResiduals   54  712.1    13.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Calculating Marginal Means\n\nlibrary(emmeans)\n\nCondition_Means &lt;- emmeans(FactorANOVA, ~ supp*dose)\nCondition_Means\n\n supp dose emmean   SE df lower.CL upper.CL\n OJ   0.5   13.23 1.15 54    10.93     15.5\n VC   0.5    7.98 1.15 54     5.68     10.3\n OJ   1     22.70 1.15 54    20.40     25.0\n VC   1     16.77 1.15 54    14.47     19.1\n OJ   2     26.06 1.15 54    23.76     28.4\n VC   2     26.14 1.15 54    23.84     28.4\n\nConfidence level used: 0.95 \n\nMarginal_MeansSupp &lt;- emmeans(FactorANOVA, ~ supp)\nMarginal_MeansSupp\n\n supp emmean    SE df lower.CL upper.CL\n OJ     20.7 0.663 54     19.3     22.0\n VC     17.0 0.663 54     15.6     18.3\n\nResults are averaged over the levels of: dose \nConfidence level used: 0.95 \n\nMarginal_MeansDose &lt;- emmeans(FactorANOVA, ~ dose)\nMarginal_MeansDose\n\n dose emmean    SE df lower.CL upper.CL\n 0.5    10.6 0.812 54     8.98     12.2\n 1      19.7 0.812 54    18.11     21.4\n 2      26.1 0.812 54    24.47     27.7\n\nResults are averaged over the levels of: supp \nConfidence level used: 0.95\nA quick glance at the output highlights that both the main effects of dose and supplement are significant as well as their interaction. Across supplement type, the means of tooth length were significantly different among three dosage conditions: 0.5 dosage (M = 10.61), 1.0 dosage (M = 19.74), and 2.0 dosage (M = 26.10), F(2,54) = 92.00, p &lt;.001. There was also a statistically significant difference in the average tooth length between supplement type, across dosage: OJ (M = 20.66) and VC condition (M = 16.96), F(1,54) = 15.57, p &lt;.001. The interaction between dosage amount and supplement type was significant, F(2,54) = 4.11, p =.02.\nGiven the significant interaction, we know that the effects of one IV depends on the levels of the other IV. One way to understand this effect is to look at the simple effects.\nlibrary(phia)\n\nlm1 &lt;- lm(len ~ dose*supp, ToothGrowth)\n\nTest1 &lt;- testInteractions(lm1, fixed = \"dose\", across = \"supp\")\nTest1\n\nF Test: \nP-value adjustment method: holm\n          Value Df Sum of Sq       F   Pr(&gt;F)   \n0.5        5.25  1    137.81 10.4505 0.004185 **\n  1        5.93  1    175.82 13.3330 0.001769 **\n  2       -0.08  1      0.03  0.0024 0.960893   \nResiduals       54    712.11                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTest2 &lt;- testInteractions(lm1, fixed = \"supp\", across = \"dose\")\nTest2\n\nF Test: \nP-value adjustment method: holm\n           dose1 dose2 Df Sum of Sq      F    Pr(&gt;F)    \nOJ        -12.83 -3.36  2    885.26 33.565 3.363e-10 ***\nVC        -18.16 -9.37  2   1649.49 62.541 1.751e-14 ***\nResiduals              54    712.11                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncontrast(Condition_Means, \"revpairwise\", by= \"dose\", adjust = \"none\")\n\ndose = 0.5:\n contrast estimate   SE df t.ratio p.value\n VC - OJ     -5.25 1.62 54  -3.233  0.0021\n\ndose = 1:\n contrast estimate   SE df t.ratio p.value\n VC - OJ     -5.93 1.62 54  -3.651  0.0006\n\ndose = 2:\n contrast estimate   SE df t.ratio p.value\n VC - OJ      0.08 1.62 54   0.049  0.9609\nNote here the significance levels: for example, the effects of supplement within 0.5, 1.0 dosage levels are significant. Additionally, the effects of dosage within OJ and VC supplement are also significant.\nNow let’s collect both biased and unbiased estimates of effect size for our three effects in this model. This will help clarify the magnitude of effect of both dosage and supplement type.\nlibrary(lsr)\nlibrary(effectsize)\n\nEta &lt;- etaSquared(FactorANOVA, type = 2, anova = TRUE)\nEta\n\n              eta.sq eta.sq.part       SS df         MS         F            p\ndose      0.70286419   0.7731092 2426.434  2 1213.21717 91.999965 0.0000000000\nsupp      0.05948365   0.2238254  205.350  1  205.35000 15.571979 0.0002311828\ndose:supp 0.03137672   0.1320279  108.319  2   54.15950  4.106991 0.0218602690\nResiduals 0.20627544          NA  712.106 54   13.18715        NA           NA\n\nomega_squared(FactorANOVA, partial = FALSE, ci = 0.95)\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 |       95% CI\n---------------------------------\ndose      |   0.69 | [0.57, 1.00]\nsupp      |   0.06 | [0.00, 1.00]\ndose:supp |   0.02 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\nomega_squared(FactorANOVA, partial = TRUE, ci = 0.95)\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 (partial) |       95% CI\n-------------------------------------------\ndose      |             0.75 | [0.65, 1.00]\nsupp      |             0.20 | [0.06, 1.00]\ndose:supp |             0.09 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\nThe eta squared value associated with the interaction between dosage and supplement is .03. In other words, the interaction term explains approximately 3% of the variance in tooth length. Its’ respective partial eta squared value is .13, indicating that the interaction term explains about 13% of the unique variance in tooth length, accounting for any shared variance with dosage and supplement. The interaction term’s omega squared and partial omega squared values are slightly smaller as these effect sizes have been corrected for bias but the interpretation stays the same.\nNow, I will calculate power for this analysis.\nlibrary(pwr)\n\nf &lt;- sqrt(0.031376 / (1-0.031376))\npwr.anova.test(k = 6, n = 10, f = f, sig.level = .95)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 6\n              n = 10\n              f = 0.1799787\n      sig.level = 0.95\n          power = 0.9778168\n\nNOTE: n is number in each group\nWe have about a 98% power level to detect the interaction effect in our data, should the effect truly exist. What about the main effect of supplement?\nf &lt;- sqrt(0.05948365 / (1-0.05948365))\npwr.anova.test(k = 2, n = 30, f = f, sig.level = .95)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 2\n              n = 30\n              f = 0.2514871\n      sig.level = 0.95\n          power = 0.9924828\n\nNOTE: n is number in each group\nWe have a 99% power level to detect the effect of supplement, should the effect exist.\nThe client also requested some visualizations, so let’s create a bar and line graph of the above group means.\nlibrary(ggplot2)\n\nggplot(ToothGrowth, aes(x =as.factor(dose), y = len, fill = as.factor(supp))) + \n  stat_summary(fun='mean',geom='bar', position = \"dodge\") +\n  labs(x = \"Dosage\", y = \"Tooth Length\", fill = \"Supplement Type\", title = \"Figure 1\", subtitle = \"Mean Tooth Length Scores by Dosage and Supplement\")+\n  theme(plot.title = element_text(face = \"bold\"),\n        plot.subtitle = element_text(face = \"italic\")) +\n  scale_fill_manual(values = c(\"#D71920\", \"#002266\"))\n\n\n\ninteraction.plot(x.factor = ToothGrowth$dose, #x-axis variable\n                 trace.factor = ToothGrowth$supp, #variable for lines\n                 response = ToothGrowth$len, #y-axis variable\n                 fun = mean, #metric to plot\n                 ylab = \"Tooth Length\",\n                 xlab = \"Dosage\",\n                 col = c(\"pink\", \"blue\"),\n                 lty = 1, #line type\n                 lwd = 2, #line width\n                 trace.label = \"Supplement Type\")"
  },
  {
    "objectID": "PortMain.html",
    "href": "PortMain.html",
    "title": "Portfolio Projects",
    "section": "",
    "text": "Check out my portfolio and research projects!\n\n\n\n\n\n\n\n\n\n\n\n\n\nBetween and Within Repeated Measures ANOVA in R\n\n\n3 min\n\n\n\nRepeated Measures ANOVA\n\n\nR\n\n\nEmmeans\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Birth Order Impact SAT Scores?\n\n\n4 min\n\n\n\nRepeated Measures ANOVA\n\n\nR\n\n\nemmeans\n\n\nData Conversion\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nEmployee Turnover: A Survival Analysis\n\n\n7 min\n\n\n\nSurvival Analysis\n\n\nTurnover\n\n\nR\n\n\nVisualizations\n\n\nsurvminer\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nEngagement and Diversity\n\n\n12 min\n\n\n\nEngagement\n\n\nDiversity\n\n\nR\n\n\nVisualizations\n\n\nConfirmatory Factor Analysis\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nFactorial Anova and Power Analysis in R\n\n\n5 min\n\n\n\nFactorial ANOVA\n\n\nR\n\n\nPower Analysis\n\n\nEffect Size\n\n\nClinical Trial Data\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nNLP Sentiment Analysis\n\n\n9 min\n\n\n\nNatural Language Processing\n\n\nSentiment Analysis\n\n\nR\n\n\nVisualizations\n\n\nTokenization\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nReligion and Politics Factorial ANOVA in R\n\n\n12 min\n\n\n\nFactorial ANOVA\n\n\nR\n\n\nReligion\n\n\nConstrast Coding\n\n\nphia\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Multilevel Modeling To Understand Engagement, Autonomy, and Team Cohesion\n\n\n6 min\n\n\n\nMultilevel Modeling\n\n\nR\n\n\nlavaan\n\n\nICC1 & 2\n\n\nEngagement\n\n\nTeam Cohesion\n\n\nInter-rater Reliability\n\n\nSimple Slopes\n\n\n\n\n\n\n\nMatthew Swanson\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "DataViz.html",
    "href": "DataViz.html",
    "title": "Data Viz Portfolio",
    "section": "",
    "text": "Here is a collection of data visualizations that I have conducted. Many of these visualizations I created in one of my portfolio projects so feel free to check them out to see how I coded these graphs and my interpretations!\n\n\n\n\n\n\n \n\n                  \n\n\n\n\n\n\n\nWord Tokens by Condition | © Matthew Swanson 2023\n\n\n\n\n\n\n\nMultilevel Interaction | © Matthew Swanson 2023\n\n\n\n\n\n\n\n\n\nStructural Data Modeling | © Matthew Swanson 2023\n\n\n\n\n\n\n\nSurvival Analysis Grouped by Coaching and Commuting Preference | © Matthew Swanson\n\n\n\n\n\n\n\n\n\nSentiment Analysis Density Plot | © Matthew Swanson 2023\n\n\n\n\n\n\n\nANOVA Box Plot | © Matthew Swanson 2023\n\n\n\n\n\n\n\n\n\nFactorial ANOVA Bar Plot | © Matthew Swanson 2023\n\n\n\n\n\n\n\nSurvival Analysis | © Matthew Swanson\n\n\n\n\n\n\n\n\n\nWord Cloud Grouped by Valance | © Matthew Swanson\n\n\n\n\n\n\n\nNLP Sentiment Analysis Frequency by Condition | © Matthew Swanson 2023"
  },
  {
    "objectID": "Portfolio pages/Turnover.html",
    "href": "Portfolio pages/Turnover.html",
    "title": "Employee Turnover: A Survival Analysis",
    "section": "",
    "text": "Employees choose to leave organizations for many reasons. Thus, it is sometimes important for Human Resources and People Analytic departments to identify variables that may influence the likelihood that employees will turnover.\nUsing this real employee dataset shared by Edward Babushkin and housed on Kaggle, I will analyze several factors that influence the likelihood that an employee will leave their company. Also, a big thank you to Keith McNulty, Alex LoPilato, and Liz Romero for their people analytics course on github.\nData columns:\nFirst, I will load in the data and make any necessary corrections.\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(psych)\n\n\n#Need to change string data to factors\nTurnData$event &lt;- factor(TurnData$event, labels = c(\"no\", \"yes\"))\nnames &lt;- c('gender', 'industry', 'profession', 'traffic', 'coach', 'head_gender', 'greywage', 'way')\nTurnData[,names] &lt;- lapply(TurnData[,names], factor)\nTurnData &lt;- TurnData  %&gt;%\n    dplyr::mutate(\n    Coach = dplyr::case_when(\n      coach == \"no\" ~ \"no\",\n      coach == \"yes\" ~ \"yes\",\n      coach == \"my head\" ~ \"no\"))\nTurnData$Coach &lt;- as.factor(TurnData$Coach)\nstr(TurnData)\n\n'data.frame':   1129 obs. of  17 variables:\n $ stag        : num  7.03 22.97 15.93 15.93 8.41 ...\n $ event       : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 2 2 2 2 2 2 ...\n $ gender      : Factor w/ 2 levels \"f\",\"m\": 2 2 1 1 2 1 1 1 1 1 ...\n $ age         : num  35 33 35 35 32 42 42 28 29 30 ...\n $ industry    : Factor w/ 16 levels \" HoReCa\",\"Agriculture\",..: 3 3 11 11 13 8 8 13 3 5 ...\n $ profession  : Factor w/ 15 levels \"Finan\\xf1e\",\"Accounting\",..: 8 8 8 8 4 8 8 8 8 12 ...\n $ traffic     : Factor w/ 8 levels \"advert\",\"empjs\",..: 5 2 5 5 8 2 2 7 2 8 ...\n $ coach       : Factor w/ 3 levels \"my head\",\"no\",..: 2 2 2 2 3 3 3 2 2 3 ...\n $ head_gender : Factor w/ 2 levels \"f\",\"m\": 1 2 2 2 1 2 2 2 1 2 ...\n $ greywage    : Factor w/ 2 levels \"grey\",\"white\": 2 2 2 2 2 2 2 2 2 2 ...\n $ way         : Factor w/ 3 levels \"bus\",\"car\",\"foot\": 1 1 1 1 1 1 1 1 1 1 ...\n $ extraversion: num  6.2 6.2 6.2 5.4 3 6.2 6.2 3.8 8.6 5.4 ...\n $ independ    : num  4.1 4.1 6.2 7.6 4.1 6.2 6.2 5.5 6.9 5.5 ...\n $ selfcontrol : num  5.7 5.7 2.6 4.9 8 4.1 4.1 8 2.6 3.3 ...\n $ anxiety     : num  7.1 7.1 4.8 2.5 7.1 5.6 5.6 4 4 7.9 ...\n $ novator     : num  8.3 8.3 8.3 6.7 3.7 6.7 6.7 4.4 7.5 8.3 ...\n $ Coach       : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 2 2 2 1 1 2 ...\nFactors have been made - now I will look at the descriptives of the data.\nlibrary(ggplot2)\nDescriptives &lt;- describe(TurnData)\nDescriptives\n\n             vars    n  mean    sd median trimmed   mad   min    max  range\nstag            1 1129 36.63 34.10  24.34   31.05 24.50  0.39 179.45 179.06\nevent*          2 1129  1.51  0.50   2.00    1.51  0.00  1.00   2.00   1.00\ngender*         3 1129  1.24  0.43   1.00    1.18  0.00  1.00   2.00   1.00\nage             4 1129 31.07  7.00  30.00   30.54  7.41 18.00  58.00  40.00\nindustry*       5 1129  9.00  4.07   8.00    9.04  5.93  1.00  16.00  15.00\nprofession*     6 1129  8.21  2.39   8.00    8.13  0.00  1.00  15.00  14.00\ntraffic*        7 1129  5.00  2.42   5.00    5.04  4.45  1.00   8.00   7.00\ncoach*          8 1129  1.84  0.61   2.00    1.80  0.00  1.00   3.00   2.00\nhead_gender*    9 1129  1.52  0.50   2.00    1.52  0.00  1.00   2.00   1.00\ngreywage*      10 1129  1.89  0.32   2.00    1.98  0.00  1.00   2.00   1.00\nway*           11 1129  1.50  0.68   1.00    1.38  0.00  1.00   3.00   2.00\nextraversion   12 1129  5.59  1.85   5.40    5.58  2.37  1.00  10.00   9.00\nindepend       13 1129  5.48  1.70   5.50    5.48  2.08  1.00  10.00   9.00\nselfcontrol    14 1129  5.60  1.98   5.70    5.59  2.22  1.00  10.00   9.00\nanxiety        15 1129  5.67  1.71   5.60    5.63  2.22  1.70  10.00   8.30\nnovator        16 1129  5.88  1.90   6.00    5.94  2.22  1.00  10.00   9.00\nCoach*         17 1129  1.12  0.32   1.00    1.02  0.00  1.00   2.00   1.00\n              skew kurtosis   se\nstag          1.49     2.02 1.01\nevent*       -0.02    -2.00 0.01\ngender*       1.19    -0.59 0.01\nage           0.66     0.06 0.21\nindustry*    -0.03    -1.28 0.12\nprofession*   0.26     2.52 0.07\ntraffic*     -0.03    -1.50 0.07\ncoach*        0.10    -0.43 0.02\nhead_gender* -0.07    -2.00 0.01\ngreywage*    -2.45     4.00 0.01\nway*          1.00    -0.23 0.02\nextraversion  0.01    -0.40 0.06\nindepend     -0.01    -0.34 0.05\nselfcontrol   0.03    -0.63 0.06\nanxiety       0.15    -0.48 0.05\nnovator      -0.25    -0.48 0.06\nCoach*        2.38     3.67 0.01\n\nsum(is.na(TurnData))\n\n[1] 0\nSince each data point represents an employee who has either left the organization or is currently employed, and there are no missing data points, I will move on to model building and running some analyses on the data.\nFirst, I conducted a survival analysis and related the survival object to several of the variables that were measured during the employee on-boarding period.\nlibrary(survival)\nlibrary(survminer)\nlibrary(lubridate)\nlibrary(ggfortify)\n# Create a censor indicator variable that is 1 if the employee has left and 0 otherwise\nTurnData &lt;-\n  TurnData %&gt;%\n    dplyr::mutate(\n    CENSOR = dplyr::case_when(\n      event == \"no\" ~ 0,\n      TRUE ~ 1))\n\n# Create a survival object\nsurv_object &lt;- survival::Surv(\n  event = TurnData$CENSOR,\n  time = TurnData$stag\n)\n\n# Estimate survival probabilities using Kaplan Meier estimator\nSurvProb &lt;- survival::survfit(\n  surv_object ~ 1,\n  data = TurnData)\nhead(fortify(SurvProb),10)\n\n        time n.risk n.event n.censor      surv      std.err     upper     lower\n1  0.3942505   1129       1        0 0.9991143 0.0008861321 1.0000000 0.9973805\n2  0.4271047   1128       1        0 0.9982285 0.0012537359 1.0000000 0.9957786\n3  0.4928131   1127       0        3 0.9982285 0.0012537359 1.0000000 0.9957786\n4  0.5256674   1124       0        1 0.9982285 0.0012537359 1.0000000 0.9957786\n5  0.6899384   1123       0        1 0.9982285 0.0012537359 1.0000000 0.9957786\n6  0.7556468   1122       1        0 0.9973388 0.0015384787 1.0000000 0.9943360\n7  0.7885010   1121       0        1 0.9973388 0.0015384787 1.0000000 0.9943360\n8  0.8870637   1120       0        1 0.9973388 0.0015384787 1.0000000 0.9943360\n9  0.9199179   1119       1        0 0.9964476 0.0017793961 0.9999288 0.9929784\n10 1.1170431   1118       2        0 0.9946650 0.0021838533 0.9989316 0.9904167\n\nSurvProbcalc &lt;- \n  tibble::tibble(\n    time = SurvProb$time,\n    n.risk = SurvProb$n.risk,\n    n.censor = SurvProb$n.censor,\n    n.event = SurvProb$n.event,\n    survival = SurvProb$surv\n  )\n\nsum(SurvProbcalc$n.event)\n\n[1] 571\n\nsum(SurvProbcalc$n.censor)\n\n[1] 558\n\nmin(which(SurvProbcalc$n.censor != 0))\n\n[1] 3\nFYI: To reduce the length of the printed data, I only asked for the first 10 rows but a row is created until the “surv” column reaches zero so this output can become quite long.\nThe first item I notice from this output is that turnover occurs at a relatively rapid rate at this company (this interpretation may slightly change if the organization is a massive company - total N size is not accessable). Since the time metric is in months, by the first year, approximately 297 employees (1129 - 832) are predicted to turnover, for a survival percentage of about 85%. Additionally, I would expect only half of the employees to remain at the company about 4 years into the job (approximately 50 months).\nI also determined that 571 employees turned over at this company and there are 558 censored observations. These censored observations are participants who have not yet experienced the event of interest in this dataset: turnover. Also, the first censored participant showed up at time point three (about 2 weeks).\nNow I will visualize the Kaplan Meier estimator output.\nsurvminer::ggsurvplot(\n  SurvProb,\n  pval = TRUE,\n  conf.int = TRUE,\n  risk.table = TRUE,\n  xlab = \"Months since Hire\",\n  ylab = \"Probability of Staying at Company\"\n)\nConsidering no other explanatory variables, results of my survival analysis predicts that most employees will turnover about 175 months (14.5 years) into their tenure at the company. However, perhaps additional variables, such a the presence of a coach and commuting style better explain the tenure trajectory of employees at this company.\nSurvProb_Coach &lt;- survival::survfit(surv_object ~ Coach, data = TurnData)\nhead(fortify(SurvProb_Coach), 10)\n\n        time n.risk n.event n.censor      surv     std.err     upper     lower\n1  0.3942505    997       1        0 0.9989970 0.001003512 1.0000000 0.9970340\n2  0.4928131    996       0        3 0.9989970 0.001003512 1.0000000 0.9970340\n3  0.5256674    993       0        1 0.9989970 0.001003512 1.0000000 0.9970340\n4  0.6899384    992       0        1 0.9989970 0.001003512 1.0000000 0.9970340\n5  0.7556468    991       1        0 0.9979889 0.001423486 1.0000000 0.9952084\n6  0.7885010    990       0        1 0.9979889 0.001423486 1.0000000 0.9952084\n7  0.8870637    989       0        1 0.9979889 0.001423486 1.0000000 0.9952084\n8  1.1170431    988       2        0 0.9959687 0.002019739 0.9999192 0.9920338\n9  1.1498973    986       0        1 0.9959687 0.002019739 0.9999192 0.9920338\n10 1.1827515    985       0        2 0.9959687 0.002019739 0.9999192 0.9920338\n   strata\n1      no\n2      no\n3      no\n4      no\n5      no\n6      no\n7      no\n8      no\n9      no\n10     no\nAt a quick glance, it appears that the presence of a coach speeds up the attrition rate at this company! Perhaps the company should investigate the coaches they have employed to work with their staff as employees have a lower survival rate when paired with a coach than those who do not have a coach. However, I want a statistical test to tell the difference between these two survival curves. I will now visualize these survival rates and ask for a test of the difference in survival curves.\nsurvminer::ggsurvplot(\n  SurvProb_Coach,\n  pval = TRUE,\n  conf.int = TRUE,\n  xlab = \"Months since Hire\",\n  ylab = \"Probability of Staying at Company\"\n)\nAs is made more clear by this graph, the survival curves for those who had and did not have a coach did not significantly differ from each other, log-likelihood p = .27. I am also curious how commuting style (if the employee commuted by way of a bus, car, or by foot) impacted attrition and if commuting style interacted with coaching. First, I will change my model to include commuting style and will plot the model.\nSurvProb_Way &lt;- survival::survfit(surv_object ~ way, data = TurnData)\n#summary(SurvProb_Sup)\nsurvminer::ggsurvplot(\n  SurvProb_Way,\n  pval = TRUE,\n  conf.int = TRUE,\n  xlab = \"Months since Hire\",\n  ylab = \"Probability of Staying at Company\"\n)\nResults indicate that commuting style did significantly change the attrition estimate for employees. Since there are more than two curves, this only tells me that at least one of the curves differs from the others, but not which curves those are. I will come back to this issue in a moment.\nNow I want to see how the occurrence of coaching potentially interacts with commuting style in predicting attrition rates.\nIntModel &lt;- survival::survfit(surv_object ~ Coach + way, data = TurnData)\nsurvminer::ggsurvplot(IntModel, \n  pval = TRUE,\n  xlab = \"Months since Hire\",\n  ylab = \"Probability of Staying at Company\")\nNote here the significant log-likelihood p value. I also removed the shading for confidence intervals to aid in readability. To really understand the group differences in survivability, the Cox-Proportional Hazards Model, a semi-parametric regression model, will be utilized. I also decided to add in participant’s conscientiousness scores to the model.\nCoxMod &lt;- survival::coxph(\n  surv_object ~  Coach + way + selfcontrol + Coach*way,\n  data = TurnData)\nsummary(CoxMod)\n\nCall:\nsurvival::coxph(formula = surv_object ~ Coach + way + selfcontrol + \n    Coach * way, data = TurnData)\n\n  n= 1129, number of events= 571 \n\n                     coef exp(coef) se(coef)      z Pr(&gt;|z|)   \nCoachyes          0.20012   1.22155  0.15303  1.308  0.19097   \nwaycar           -0.22041   0.80219  0.09940 -2.217  0.02659 * \nwayfoot          -0.42755   0.65210  0.17874 -2.392  0.01675 * \nselfcontrol      -0.05915   0.94257  0.02118 -2.793  0.00522 **\nCoachyes:waycar  -0.19537   0.82253  0.29951 -0.652  0.51421   \nCoachyes:wayfoot -0.24507   0.78265  0.42224 -0.580  0.56165   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                 exp(coef) exp(-coef) lower .95 upper .95\nCoachyes            1.2215     0.8186    0.9050    1.6488\nwaycar              0.8022     1.2466    0.6602    0.9747\nwayfoot             0.6521     1.5335    0.4594    0.9257\nselfcontrol         0.9426     1.0609    0.9042    0.9825\nCoachyes:waycar     0.8225     1.2158    0.4573    1.4794\nCoachyes:wayfoot    0.7827     1.2777    0.3421    1.7905\n\nConcordance= 0.552  (se = 0.013 )\nLikelihood ratio test= 21.52  on 6 df,   p=0.001\nWald test            = 21.13  on 6 df,   p=0.002\nScore (logrank) test = 21.29  on 6 df,   p=0.002\nResults indicate that coaching style did not significantly interact with commuting type, all ps&gt;.05, nor was there any group difference for participants who had a coach vs. those who did not, b = 0.20, p = .19. However, the difference between riding the bus to work and commuting by either car, b = -0.22, p = .03, or by foot, b = -0.43, p = .02, were significant and negative. This suggests that when compared to riding the bus, driving to work reduces the hazard (of attrition) by a factor of .80 and walking to work reduces the hazard by .65. Self-control was also a significant predictor, such that every unit increase in conscientiousness reduces the hazard by a factor of .94.\nIt is my recommendation that the company evaluates the utility of their coaching program, as employees are no less likely to leave the company when they have a coach, compared to those who do not have coaches. Conscientious and commuting style stand out as significant predictors of the survival curves. Thus, it may be advantageous to the company to consider adding conscientiousness personality tests to their selection battery (when it makes sense with established job analyses), as more conscientious employees left the company at slower rates. Also, the company may want to encourage carpooling and reduce barriers to walking to work (e.g., keeping sidewalks clean; providing flexible start times so that employees have ample time to walk to work where applicable; etc.)."
  },
  {
    "objectID": "Portfolio pages/Turnover.html#about-this-data",
    "href": "Portfolio pages/Turnover.html#about-this-data",
    "title": "Employee Turnover: A Survival Analysis",
    "section": "About This Data",
    "text": "About This Data"
  },
  {
    "objectID": "Portfolio pages/Engagement and Diversity.html",
    "href": "Portfolio pages/Engagement and Diversity.html",
    "title": "Engagement and Diversity",
    "section": "",
    "text": "The overarching goal of this project is to better understand the demographic makeup of this company using their HR data and to assess how engaged these employees are.\nThis HR data set was provided on Kaggle here. Data is houses in four text files:\nFirst, I want to clean and match up the data and provide some general oversights on the demographic makeup of the employees at this company.\nFirst, the data needs to be read in and then match up using indicator keys in the data sets.\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\nMerge1 &lt;- merge(CompanyData, DiversityData, by.x = \"EmployeeID\")\nMasterData &lt;- merge(Merge1, EngagementData, by.x = \"EmployeeID\")\nnames &lt;- c('level', 'Department', 'Gender', 'Gender.Identity', 'Race.Ethnicity', 'Veteran', 'Disability', 'Education', 'Sexual.Orientation')\nMasterData[,names] &lt;- lapply(MasterData[,names], factor)\nNow to calculate some general demographic statistics.\nmean(MasterData$Age)\n\n[1] 44.18465\n\nsd(MasterData$Age)\n\n[1] 12.76855\n\nMasterData %&gt;%\n  group_by(Veteran) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\n# A tibble: 2 × 3\n  Veteran     n   freq\n  &lt;fct&gt;   &lt;int&gt;  &lt;dbl&gt;\n1 0        2688 0.951 \n2 1         139 0.0492\n\nMasterData %&gt;%\n  group_by(Disability) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\n# A tibble: 2 × 3\n  Disability     n   freq\n  &lt;fct&gt;      &lt;int&gt;  &lt;dbl&gt;\n1 0           2696 0.954 \n2 1            131 0.0463\n\nMasterData %&gt;%\n  group_by(Race.Ethnicity) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\n# A tibble: 10 × 3\n   Race.Ethnicity                                  n     freq\n   &lt;fct&gt;                                       &lt;int&gt;    &lt;dbl&gt;\n 1 \"\"                                            321 0.114   \n 2 \"American Indian or Alaska Native\"              1 0.000354\n 3 \"Asian\"                                       721 0.255   \n 4 \"Black or African American\"                    89 0.0315  \n 5 \"Hispanic or Latino\"                          117 0.0414  \n 6 \"Native American or Alaska Native\"              3 0.00106 \n 7 \"Native Hawaiian or Other Pacific Islander\"     2 0.000707\n 8 \"Native Hawaiian or Pacific Islander\"           7 0.00248 \n 9 \"Two or More Races\"                            31 0.0110  \n10 \"White\"                                      1535 0.543   \n\nMasterData %&gt;%\n  group_by(Gender.Identity) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\n# A tibble: 5 × 3\n  Gender.Identity             n   freq\n  &lt;fct&gt;                   &lt;int&gt;  &lt;dbl&gt;\n1 female                   1232 0.436 \n2 male                     1298 0.459 \n3 Non-binary/third gender    75 0.0265\n4 Prefer not to say         166 0.0587\n5 Prefer to self-describe    56 0.0198\n\nMasterData %&gt;%\n  group_by(Sexual.Orientation) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\n# A tibble: 6 × 3\n  Sexual.Orientation     n   freq\n  &lt;fct&gt;              &lt;int&gt;  &lt;dbl&gt;\n1 Bisexual              55 0.0195\n2 Gay                   60 0.0212\n3 Heterosexual        1817 0.643 \n4 Lesbian               43 0.0152\n5 Missing              749 0.265 \n6 Other LGBTQ+         103 0.0364\n\nMasterData %&gt;%\n  group_by(Education) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\n# A tibble: 5 × 3\n  Education         n   freq\n  &lt;fct&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 Graduate        197 0.0697\n2 High School     481 0.170 \n3 PhD              68 0.0241\n4 Some College    177 0.0626\n5 Undergraduate  1904 0.674\nFrom this output, I can tell that the average employee is 44 years of age, typically not a veteran (approx. %5 of employees are a veteran), and did not report a disability (approx. 5% of employees reported a disability status). Further, the organization is 55% White with Asian employees making up the next most frequent category at 26%. Employees are about even split between male and female (around 44% each), most identify as heterosexual (64%), and about 67% have an undergraduate degree.\nThe client is particularly interested in the gender and racial makeup of each level of their organization (i.e., individual contributor, manager, director, etc.) and to have some visualizations made up.\nLevelG &lt;- MasterData %&gt;%\n  group_by(level, Gender.Identity) %&gt;%\n  filter(Gender.Identity != \"Prefer not to say\")%&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\nLevelR &lt;- MasterData %&gt;%\n  group_by(level, Race.Ethnicity) %&gt;%\n  filter(Race.Ethnicity != \"\")%&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(freq = n / sum(n))\n\nggdotchart(LevelG, x = \"level\", y = \"freq\",\n           color = \"Gender.Identity\",                                \n           sorting = \"asc\", sort.by.groups = TRUE,                      \n           add = \"segments\",                            \n           add.params = list(color = \"lightgray\", size = 2), \n           group = \"Gender.Identity\",                                \n           dot.size = 4,                                 \n           ggtheme = theme_pubclean()\n           )+\n  font(\"x.text\", size = 8, vjust = 0.5)\n\n\n\nggplot(LevelR, aes(fill=Race.Ethnicity, y=freq, x=level)) + \n    geom_bar(position=\"stack\", stat=\"identity\") +\n  geom_text(aes(label = scales::percent(freq, accuracy = 1)),\n            position = position_stack(vjust = .5), size = 1.5) +\n  scale_x_discrete(guide=guide_axis(n.dodge=4))\nNow that I have a sense of the demographic breakdown of the employees at this company, my next goal is to better understand how engaged the employees feel at work and if these engagement perceptions significantly differ depending on employee’s identities. First, I was asked to create a composite engagement variable and assess the reliability and validity of the scale. However, looking at the items, I doubt that the items will play together since the “engagement” items cover topics such as perspectives on DEI, market survivability of their company, compensation, and engagement.\nNote: none of the engagement items were reverse coded so there is no need to reverse score any items.\nlibrary(psych)\n#Create composite engagement score\nMasterData %&gt;%\n  rowwise()%&gt;%\n  mutate(Engagement = mean(c(E1, E2, E3, E4, E5, E6, E7, E8, E9, E10, E11, E12, E13, E14, E15, E16, E17, E18, E19)))-&gt; MasterData\n#Create engagement scale Reliability Analysis\nEngagementScale &lt;- select(MasterData, E1, E2, E3, E4, E5, E6, E7, E8, E9, E10, E11, E12, E13, E14, E15, E16, E17, E18, E19)\npsych::alpha(EngagementScale)\n\nSome items ( E2 E4 E7 E9 E11 E13 E14 E15 E16 ) were negatively correlated with the total scale and \nprobably should be reversed.  \nTo do this, run the function again with the 'check.keys=TRUE' option\n\n\n\nReliability analysis   \nCall: psych::alpha(x = EngagementScale)\n\n  raw_alpha std.alpha G6(smc) average_r    S/N   ase mean   sd median_r\n    0.0073    0.0074   0.013   0.00039 0.0074 0.027  2.9 0.23  -0.0012\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt    -0.05  0.01  0.06\nDuhachek -0.05  0.01  0.06\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r     S/N alpha se   var.r    med.r\nE1     0.0022    0.0020  0.0075   1.1e-04  0.0020    0.027 0.00033 -0.00104\nE2     0.0119    0.0119  0.0164   6.7e-04  0.0120    0.027 0.00030 -0.00083\nE3     0.0079    0.0078  0.0130   4.4e-04  0.0079    0.027 0.00033 -0.00125\nE4     0.0093    0.0093  0.0142   5.2e-04  0.0094    0.027 0.00032 -0.00116\nE5    -0.0084   -0.0085 -0.0024  -4.7e-04 -0.0085    0.028 0.00033 -0.00302\nE6     0.0033    0.0035  0.0090   1.9e-04  0.0035    0.027 0.00033 -0.00125\nE7     0.0148    0.0149  0.0196   8.4e-04  0.0151    0.027 0.00033 -0.00083\nE8     0.0190    0.0191  0.0231   1.1e-03  0.0195    0.027 0.00030 -0.00116\nE9     0.0053    0.0053  0.0107   3.0e-04  0.0053    0.027 0.00033 -0.00083\nE10   -0.0040   -0.0042  0.0015  -2.3e-04 -0.0042    0.027 0.00032 -0.00189\nE11    0.0084    0.0085  0.0137   4.8e-04  0.0086    0.027 0.00033 -0.00125\nE12    0.0156    0.0154  0.0200   8.7e-04  0.0157    0.027 0.00032 -0.00083\nE13    0.0038    0.0041  0.0095   2.3e-04  0.0041    0.027 0.00033 -0.00125\nE14    0.0121    0.0124  0.0175   7.0e-04  0.0126    0.027 0.00034 -0.00034\nE15    0.0144    0.0147  0.0194   8.3e-04  0.0149    0.027 0.00033 -0.00011\nE16    0.0018    0.0019  0.0073   1.0e-04  0.0019    0.027 0.00032 -0.00189\nE17   -0.0044   -0.0040  0.0019  -2.2e-04 -0.0040    0.027 0.00033 -0.00189\nE18    0.0190    0.0189  0.0232   1.1e-03  0.0192    0.027 0.00032 -0.00104\nE19   -0.0012   -0.0010  0.0045  -5.7e-05 -0.0010    0.027 0.00032 -0.00189\n\n Item statistics \n       n raw.r std.r   r.cor   r.drop mean   sd\nE1  2827  0.24  0.24  0.1106  0.01138  2.9 0.99\nE2  2827  0.22  0.22 -0.0537 -0.00826  2.9 1.03\nE3  2827  0.23  0.23  0.0095 -0.00028  2.9 1.00\nE4  2827  0.23  0.23 -0.0127 -0.00308  2.9 1.02\nE5  2827  0.26  0.26  0.2903  0.03292  2.9 1.00\nE6  2827  0.24  0.24  0.0843  0.00890  2.9 1.01\nE7  2827  0.21  0.21 -0.1128 -0.01433  2.9 1.01\nE8  2827  0.20  0.21 -0.1791 -0.02317  2.9 1.00\nE9  2827  0.23  0.23  0.0530  0.00504  2.9 1.00\nE10 2827  0.25  0.25  0.2207  0.02397  2.9 1.00\nE11 2827  0.23  0.23 -0.0031 -0.00136  2.9 1.02\nE12 2827  0.21  0.21 -0.1204 -0.01591  2.9 1.01\nE13 2827  0.24  0.24  0.0755  0.00801  2.9 1.02\nE14 2827  0.22  0.22 -0.0726 -0.00897  2.9 1.00\nE15 2827  0.21  0.21 -0.1093 -0.01360  2.9 1.00\nE16 2827  0.24  0.24  0.1158  0.01200  2.9 1.02\nE17 2827  0.26  0.25  0.2135  0.02398  2.9 1.03\nE18 2827  0.21  0.21 -0.1803 -0.02255  2.9 1.02\nE19 2827  0.25  0.25  0.1667  0.01776  2.9 1.02\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nE1  0.09 0.25 0.31 0.34 0.01    0\nE2  0.10 0.24 0.28 0.36 0.01    0\nE3  0.09 0.25 0.30 0.35 0.01    0\nE4  0.10 0.25 0.28 0.35 0.01    0\nE5  0.09 0.27 0.30 0.32 0.01    0\nE6  0.11 0.24 0.31 0.33 0.01    0\nE7  0.09 0.25 0.29 0.35 0.01    0\nE8  0.09 0.26 0.29 0.35 0.01    0\nE9  0.09 0.25 0.29 0.36 0.01    0\nE10 0.09 0.25 0.31 0.35 0.01    0\nE11 0.10 0.24 0.29 0.35 0.01    0\nE12 0.09 0.25 0.29 0.36 0.01    0\nE13 0.10 0.24 0.30 0.35 0.01    0\nE14 0.10 0.24 0.31 0.35 0.01    0\nE15 0.10 0.25 0.30 0.34 0.01    0\nE16 0.10 0.24 0.29 0.35 0.01    0\nE17 0.11 0.25 0.30 0.33 0.01    0\nE18 0.10 0.25 0.27 0.37 0.01    0\nE19 0.11 0.24 0.30 0.35 0.01    0\nIndeed, analyses support my contention that combining all “engagement” items into one scale makes sense from a measurement standpoint. Already there is strong evidence that there is a lack of reliability here from a composite scale perspective. Cronbach’s alpha for this scale is unacceptable, sitting at α= .01 (I would accept values above .70). I also ran a confirmatory factor analysis and none of the items loaded onto a global latent factor of engagement together, all factor loadings are less than .255. I would like to see loadings of at least .40 and realistic CFI and TLI values (within 0-1 with values close to 1 without exceeding 1).\nlibrary(lavaan)\nCFA1  &lt;- 'Engage =~ E1 + E2 + E3 + E4 + E5 + E6 + E7 + E8 + E9 + E10 + E11 + E12 + E13 + E14 + E15 + E16 + E17 + E18 + E19'\nCFAOut &lt;- cfa(CFA1, data=MasterData) \nsummary(CFAOut, fit.measures=TRUE, standardized=TRUE)\n\nlavaan 0.6.15 ended normally after 19 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        38\n\n  Number of observations                          2827\n\nModel Test User Model:\n                                                      \n  Test statistic                               157.795\n  Degrees of freedom                               152\n  P-value (Chi-square)                           0.357\n\nModel Test Baseline Model:\n\n  Test statistic                               157.795\n  Degrees of freedom                               171\n  P-value                                        0.757\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.000\n  Tucker-Lewis Index (TLI)                       1.494\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -76775.576\n  Loglikelihood unrestricted model (H1)     -76696.678\n                                                      \n  Akaike (AIC)                              153627.152\n  Bayesian (BIC)                            153853.136\n  Sample-size adjusted Bayesian (SABIC)     153732.397\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.004\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.010\n  P-value H_0: RMSEA &lt;= 0.050                    1.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.017\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  Engage =~                                                             \n    E1                1.000                               0.003    0.003\n    E2               -0.058 1529.201   -0.000    1.000   -0.000   -0.000\n    E3                0.117 1727.173    0.000    1.000    0.000    0.000\n    E4                0.175 2079.327    0.000    1.000    0.001    0.001\n    E5                0.031 1429.437    0.000    1.000    0.000    0.000\n    E6                0.021 1439.041    0.000    1.000    0.000    0.000\n    E7                0.111 1707.275    0.000    1.000    0.000    0.000\n    E8                0.213 2328.665    0.000    1.000    0.001    0.001\n    E9               -0.005 1413.694   -0.000    1.000   -0.000   -0.000\n    E10               0.048 1464.347    0.000    1.000    0.000    0.000\n    E11               0.095 1646.012    0.000    1.000    0.000    0.000\n    E12              -0.062 1521.521   -0.000    1.000   -0.000   -0.000\n    E13              -0.254 2653.472   -0.000    1.000   -0.001   -0.001\n    E14              -0.142 1862.255   -0.000    1.000   -0.000   -0.000\n    E15              -0.013 1417.918   -0.000    1.000   -0.000   -0.000\n    E16               0.006 1440.679    0.000    1.000    0.000    0.000\n    E17              -0.245 2587.500   -0.000    1.000   -0.001   -0.001\n    E18               0.019 1451.525    0.000    1.000    0.000    0.000\n    E19               0.192 2198.624    0.000    1.000    0.001    0.001\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .E1                0.980    0.122    8.025    0.000    0.980    1.000\n   .E2                1.052    0.028   37.502    0.000    1.052    1.000\n   .E3                1.003    0.027   37.182    0.000    1.003    1.000\n   .E4                1.033    0.028   36.621    0.000    1.033    1.000\n   .E5                0.991    0.026   37.568    0.000    0.991    1.000\n   .E6                1.024    0.027   37.584    0.000    1.024    1.000\n   .E7                1.019    0.027   37.232    0.000    1.019    1.000\n   .E8                1.004    0.028   36.006    0.000    1.004    1.000\n   .E9                1.003    0.027   37.596    0.000    1.003    1.000\n   .E10               0.995    0.027   37.530    0.000    0.995    1.000\n   .E11               1.036    0.028   37.338    0.000    1.036    1.000\n   .E12               1.025    0.027   37.487    0.000    1.025    1.000\n   .E13               1.041    0.030   35.268    0.000    1.041    1.000\n   .E14               0.996    0.027   36.954    0.000    0.996    1.000\n   .E15               1.004    0.027   37.592    0.000    1.004    1.000\n   .E16               1.042    0.028   37.596    0.000    1.042    1.000\n   .E17               1.063    0.030   35.525    0.000    1.063    1.000\n   .E18               1.045    0.028   37.586    0.000    1.045    1.000\n   .E19               1.049    0.029   36.414    0.000    1.049    1.000\n    Engage            0.000    0.119    0.000    1.000    1.000    1.000\nThus, I will focus on three items that the client was particularly interested in understanding their employee’s perspectives on.\nThe three items of interest are:\nFirst I will grab means and standard deviations for these three items and then break the means up by gender, race, and sexual orientation.\nNote: greater scores on these items indicate greater agreement with the item.\nShortData &lt;- subset(MasterData,Sexual.Orientation != \"Missing\" & Race.Ethnicity != \"\", select=c('Race.Ethnicity','Gender.Identity','Sexual.Orientation', 'E2', 'E5', 'E11'))\n\ndescribe(ShortData)\n\n                    vars    n mean   sd median trimmed  mad min max range  skew\nRace.Ethnicity*        1 1844 7.49 3.24     10    7.74 0.00   2  10     8 -0.56\nGender.Identity*       2 1844 1.79 0.92      2    1.61 1.48   1   5     4  1.54\nSexual.Orientation*    3 1844 3.09 0.78      3    3.00 0.00   1   6     5  2.04\nE2                     4 1844 2.92 1.03      3    3.01 1.48   1   5     4 -0.37\nE5                     5 1844 2.88 1.00      3    2.96 1.48   1   5     4 -0.28\nE11                    6 1844 2.92 1.02      3    3.02 1.48   1   5     4 -0.36\n                    kurtosis   se\nRace.Ethnicity*        -1.64 0.08\nGender.Identity*        2.41 0.02\nSexual.Orientation*     8.35 0.02\nE2                     -0.95 0.02\nE5                     -0.98 0.02\nE11                    -0.97 0.02\n\nShortData %&gt;%\n  group_by(Race.Ethnicity) %&gt;%\n  summarise_at(vars(c(\"E2\", \"E5\", \"E11\")), list(mean = mean))\n\n# A tibble: 9 × 4\n  Race.Ethnicity                            E2_mean E5_mean E11_mean\n  &lt;fct&gt;                                       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 American Indian or Alaska Native             4       3        4   \n2 Asian                                        2.93    2.89     2.89\n3 Black or African American                    2.89    2.77     3.01\n4 Hispanic or Latino                           3.01    3.09     3.01\n5 Native American or Alaska Native             3       3        1.5 \n6 Native Hawaiian or Other Pacific Islander    3.5     3.5      4   \n7 Native Hawaiian or Pacific Islander          3.29    2.71     2.57\n8 Two or More Races                            3.19    3.05     2.48\n9 White                                        2.90    2.87     2.94\n\nShortData %&gt;%\n  group_by(Gender.Identity) %&gt;%\n  summarise_at(vars(c(\"E2\", \"E5\", \"E11\")), list(mean = mean))\n\n# A tibble: 5 × 4\n  Gender.Identity         E2_mean E5_mean E11_mean\n  &lt;fct&gt;                     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 female                     2.93    2.86     2.93\n2 male                       2.92    2.91     2.94\n3 Non-binary/third gender    2.78    2.80     2.81\n4 Prefer not to say          2.97    2.88     2.77\n5 Prefer to self-describe    2.87    2.82     2.89\n\nShortData %&gt;%\n  group_by(Sexual.Orientation) %&gt;%\n  summarise_at(vars(c(\"E2\", \"E5\", \"E11\")), list(mean = mean))\n\n# A tibble: 5 × 4\n  Sexual.Orientation E2_mean E5_mean E11_mean\n  &lt;fct&gt;                &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 Bisexual              2.76    2.71     2.69\n2 Gay                   2.89    2.88     2.68\n3 Heterosexual          2.93    2.88     2.93\n4 Lesbian               2.77    3.08     3.03\n5 Other LGBTQ+          2.99    2.89     2.97\nThere are a lot of calculated means so I will first visualize them and then conduct a few ANOVAs to test for significant mean differences.\nStarting with question E2, which is “I feel engaged in my work”:\nggplot(ShortData, aes(x=Race.Ethnicity, y=E2, fill=Race.Ethnicity)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n  scale_x_discrete(guide=guide_axis(n.dodge=6)) +\n  theme(axis.text.x = element_text(size = 5)) +\n  labs(y = \"I feel engaged in my work\")\n\n\n\nggplot(ShortData, aes(x=Gender.Identity, y=E2, fill=Gender.Identity)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n  scale_x_discrete(guide=guide_axis(n.dodge=2)) +\n  theme(axis.text.x = element_text(size = 10)) +\n  labs(y = \"I feel engaged in my work\")\n\n\n\nggplot(ShortData, aes(x=Sexual.Orientation, y=E2, fill=Sexual.Orientation)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n    theme(axis.text.x = element_text(size = 10)) +\n  labs(y = \"I feel engaged in my work\")\nGlancing at the graphs, there does not seem to be a lot of variability for this question. Most participants across race, gender, and sexual orientation felt positively about how engaged they feel at work. The exception here may be that Native Hawaiian or Other Pacific Islanders may feel less engaged than other groups of people.\nNext, question E5, “The company cares about Diversity, Equity, and Inclusion”:\nggplot(ShortData, aes(x=Race.Ethnicity, y=E5, fill=Race.Ethnicity)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n  scale_x_discrete(guide=guide_axis(n.dodge=6)) +\n  theme(axis.text.x = element_text(size = 5)) +\n  theme(axis.title.y = element_text(size = 8)) +\n  labs(y = \"The company cares about Diversity, Equity, and Inclusion\")\n\n\n\nggplot(ShortData, aes(x=Gender.Identity, y=E5, fill=Gender.Identity)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n  scale_x_discrete(guide=guide_axis(n.dodge=2)) +\n  theme(axis.text.x = element_text(size = 10)) +\n  theme(axis.title.y = element_text(size = 8)) +\n  labs(y = \"The company cares about Diversity, Equity, and Inclusion\")\n\n\n\nggplot(ShortData, aes(x=Sexual.Orientation, y=E5, fill=Sexual.Orientation)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n    theme(axis.text.x = element_text(size = 10)) +\n  theme(axis.title.y = element_text(size = 8)) +\n  labs(y = \"The company cares about Diversity, Equity, and Inclusion\")\nSimilar to question E2, most participants felt that their company does care about diversity, equity, and inclusion, with the exceptions potentially being American Indians or Alaska Natives and Native Hawaiians or Other Pacific Islanders. I will not know if these differences are significant until I run an ANOVA.\nLastly, question E11, “I believe there are good career opportunities for me at the company”:\nggplot(ShortData, aes(x=Race.Ethnicity, y=E11, fill=Race.Ethnicity)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n  scale_x_discrete(guide=guide_axis(n.dodge=6)) +\n  theme(axis.text.x = element_text(size = 5)) +\n  theme(axis.title.y = element_text(size = 8)) +\n  labs(y = \"I believe there are good career opportunities for me at the company\")\n\n\n\nggplot(ShortData, aes(x=Gender.Identity, y=E11, fill=Gender.Identity)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n  scale_x_discrete(guide=guide_axis(n.dodge=2)) +\n  theme(axis.text.x = element_text(size = 10)) +\n  theme(axis.title.y = element_text(size = 8)) +\n  labs(y = \"I believe there are good career opportunities for me at the company\")\n\n\n\nggplot(ShortData, aes(x=Sexual.Orientation, y=E11, fill=Sexual.Orientation)) + \n    geom_bar(position=position_dodge(), stat=\"identity\") +\n    theme(axis.text.x = element_text(size = 10)) +\n  theme(axis.title.y = element_text(size = 8)) +\n  labs(y = \"I believe there are good career opportunities for me at the company\")\nPretty similar across the board with the exception of Native Hawaiian or Other Pacific Islanders who do not agree that there are good opportunities for them at their company. Now I will run three ANOVAs with each engagement item as the dependent variable and the three identity variables, race, gender, and sexual orientation, as predictors in each model.\nE2Model &lt;- aov(E2 ~ Race.Ethnicity + Gender.Identity + Sexual.Orientation, ShortData)\nsummary(E2Model)\n\n                     Df Sum Sq Mean Sq F value Pr(&gt;F)\nRace.Ethnicity        8    5.5  0.6902   0.650  0.736\nGender.Identity       4    1.4  0.3430   0.323  0.863\nSexual.Orientation    4    2.7  0.6729   0.634  0.639\nResiduals          1827 1940.3  1.0620               \n\nE5Model &lt;- aov(E5 ~ Race.Ethnicity + Gender.Identity + Sexual.Orientation, ShortData)\nsummary(E5Model)\n\n                     Df Sum Sq Mean Sq F value Pr(&gt;F)\nRace.Ethnicity        8    6.1  0.7574   0.757  0.641\nGender.Identity       4    1.6  0.3972   0.397  0.811\nSexual.Orientation    4    3.4  0.8585   0.858  0.488\nResiduals          1827 1828.1  1.0006               \n\nE11Model &lt;- aov(E11 ~ Race.Ethnicity + Gender.Identity + Sexual.Orientation, ShortData)\nsummary(E11Model)\n\n                     Df Sum Sq Mean Sq F value Pr(&gt;F)  \nRace.Ethnicity        8   14.7  1.8353   1.764 0.0798 .\nGender.Identity       4    3.3  0.8231   0.791 0.5309  \nSexual.Orientation    4    7.5  1.8780   1.805 0.1253  \nResiduals          1827 1901.3  1.0407                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Does identity interact in predicting perceptions of the DEI culture at their company?\nE5INTModel &lt;- aov(E5 ~ Race.Ethnicity*Gender.Identity*Sexual.Orientation, ShortData)\nsummary(E5INTModel)\n\n                                                    Df Sum Sq Mean Sq F value\nRace.Ethnicity                                       8    6.1  0.7574   0.759\nGender.Identity                                      4    1.6  0.3972   0.398\nSexual.Orientation                                   4    3.4  0.8585   0.860\nRace.Ethnicity:Gender.Identity                      15   18.9  1.2583   1.261\nRace.Ethnicity:Sexual.Orientation                   14    8.7  0.6244   0.625\nGender.Identity:Sexual.Orientation                  13   21.6  1.6619   1.665\nRace.Ethnicity:Gender.Identity:Sexual.Orientation    8    5.0  0.6239   0.625\nResiduals                                         1777 1773.9  0.9982        \n                                                  Pr(&gt;F)  \nRace.Ethnicity                                    0.6394  \nGender.Identity                                   0.8103  \nSexual.Orientation                                0.4872  \nRace.Ethnicity:Gender.Identity                    0.2194  \nRace.Ethnicity:Sexual.Orientation                 0.8458  \nGender.Identity:Sexual.Orientation                0.0623 .\nRace.Ethnicity:Gender.Identity:Sexual.Orientation 0.7574  \nResiduals                                                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nNote that I am have not contrast coded these variables which would aid greatly in interpretation of significant effects. However, since none of the main effects are significant (likely due to small cell sizes in some categories), I will not go back and contrast code these main effects. I show how to contrast code and the interpretation of those effects in a different project here.\nResults across the board indicate that race, gender, and sexual orientation were not significant predictors of perceptions of engagement, DEI culture, and career opportunities, all ps &gt; .05. Also, identity does not interact in predicting perceptions of the DEI culture, all ps &gt; .05.\nmean(ShortData$E2)\n\n[1] 2.922451\n\nmean(ShortData$E5)\n\n[1] 2.883948\n\nmean(ShortData$E11)\n\n[1] 2.921909\nLooking at the overall means of those three items and considering that each item was rated on a scale of 1-5 with 5 representing a “strongly agree” anchor, it seems that across the board, employees feel relatively neutral with regards to their engagement levels, the DEI culture of their company, and how their career opportunities at their company. These perceptions did not significantly differ across racial, gender, and sexual orientation groups. However, glancing back at the bar charts that displayed the spread of employees across industry level, it is clear that only White and Asian employees work in the executive and C-Suite level at this company, which certainly limits the voices of other groups of people in major decision making roles.\nThus, my recommendation is to collect more effective data. For example, psychometric engagement scales should be utilized to obtain reliable and valid engagement scores in this company; the current data collection process contains many items that have nothing to do with engagement nor do they load onto the same latent factor of engagement, even though they are considered to be engagement items in this company’s data. Next, qualitative data should be collecting, allowing for employees to voice their concerns and provide nuance to the responses they have to the engagement items. Last, some work should be done to look at the current selection procedure for management and executive positions at this company. There could be a case for adverse impact if the company is not careful on their hiring strategy."
  },
  {
    "objectID": "Portfolio pages/Engagement and Diversity.html#about-this-data",
    "href": "Portfolio pages/Engagement and Diversity.html#about-this-data",
    "title": "Engagement and Diversity",
    "section": "About This Data",
    "text": "About This Data"
  },
  {
    "objectID": "Portfolio pages/MLMEngageTeam.html",
    "href": "Portfolio pages/MLMEngageTeam.html",
    "title": "Using Multilevel Modeling To Understand Engagement, Autonomy, and Team Cohesion",
    "section": "",
    "text": "A company has collected employee data and wants to understand the factors that shape the engagement of their workers. They collected data on the pay structure, autonomy level, and team cohesion each employee has with the overall goal of relating these variables to individual level engagement. Unique to this data is the level 1 / level 2 structure. For example, pay, engagement, and job autonomy (all level 1 variables) are assessed at the individual level, while team cohesion (a level 2 variable) is assessed at the team level. Thus, individuals are nested in teams. My goal is to use these variables to predict engagement.\nVariables need to be centered and scaled prior to entering them into a multilevel model.\nlibrary(multilevel)\nlibrary(readxl)\nlibrary(robumeta)\n\n\nhead(data)\n\n  level1_id grpid      engage      cohes      jobsat        pay     jobauto\n1         1     1  0.76164141 -0.5461742  0.73576787 -0.2145807 -0.10330841\n2         2     1 -0.05155921 -0.5461742  0.09589171 -1.1725662  0.01494606\n3         3     1  1.60837420 -0.5461742  0.47694372 -0.9820727 -0.04202197\n4         4     1  1.23486381 -0.5461742  0.58489184 -0.4141129 -0.42891177\n5         5     1  6.73776145 -0.5461742 -0.83047804  1.9041059  0.68604898\n6         6     1  6.54714955 -0.5461742  1.58131185  0.2765618  1.19430414\n  commitment1 commitment2 commitment3\n1           4           5           4\n2           5           5           5\n3           1           2           2\n4           3           4           3\n5           5           5           5\n6           3           4           4\n\noptions(scipen=999)\n\ndata$cohesion.grand.c &lt;- scale(data$cohes, scale = FALSE)\ndata$autonomy.grp.c &lt;- group.center(data$jobauto, data$grpid)\ndata$jobsat.grp.c &lt;- group.center(data$jobsat, data$grpid)\ndata$pay.grp.c &lt;- group.center(data$pay, data$grpid)\nNow that I have group and grand mean centered the data, I will begin building some models to predict engagement. First I will add the predictors into a model with engagement as the dependent variable. I also added in interactions between autonomy and pay and cohesion and pay to the model.\nModel1 &lt;- lme(engage~ 1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c + cohesion.grand.c + pay.grp.c:cohesion.grand.c, random = ~1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c|grpid,\ndata = data, control = lmeControl(opt = \"optim\"))\n\nsummary(Model1)\n\nLinear mixed-effects model fit by REML\n  Data: data \n       AIC      BIC    logLik\n  3599.774 3678.179 -1782.887\n\nRandom effects:\n Formula: ~1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n                         StdDev    Corr                \n(Intercept)              0.4298969 (Intr) py.gr. atnm..\npay.grp.c                0.7669658 -0.169              \nautonomy.grp.c           0.6277085 -0.215  0.131       \npay.grp.c:autonomy.grp.c 1.2852694  0.317  0.288  0.117\nResidual                 2.3189244                     \n\nFixed effects:  engage ~ 1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c +      cohesion.grand.c + pay.grp.c:cohesion.grand.c \n                               Value Std.Error  DF   t-value p-value\n(Intercept)                2.7311089 0.1061344 696 25.732554  0.0000\npay.grp.c                  0.3836225 0.1410103 696  2.720528  0.0067\nautonomy.grp.c             0.6181183 0.1337924 696  4.619980  0.0000\ncohesion.grand.c           0.1544943 0.1241618  48  1.244298  0.2194\npay.grp.c:autonomy.grp.c   0.3487103 0.2123779 696  1.641933  0.1011\npay.grp.c:cohesion.grand.c 0.5352599 0.1663569 696  3.217540  0.0014\n Correlation: \n                           (Intr) py.gr. atnm.. chsn.. py.grp.c:t..\npay.grp.c                  -0.074                                  \nautonomy.grp.c             -0.083  0.070                           \ncohesion.grand.c            0.007 -0.003 -0.001                    \npay.grp.c:autonomy.grp.c    0.166  0.182  0.012  0.014             \npay.grp.c:cohesion.grand.c -0.001  0.001  0.008 -0.112  0.032      \n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.4868889 -0.6959695 -0.1058310  0.5644816  3.9079997 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n\nVarCorr(Model1)\n\ngrpid = pdLogChol(1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c) \n                         Variance  StdDev    Corr                \n(Intercept)              0.1848114 0.4298969 (Intr) py.gr. atnm..\npay.grp.c                0.5882365 0.7669658 -0.169              \nautonomy.grp.c           0.3940179 0.6277085 -0.215  0.131       \npay.grp.c:autonomy.grp.c 1.6519175 1.2852694  0.317  0.288  0.117\nResidual                 5.3774103 2.3189244                     \n\nlibrary(lme4)\nlibrary(interactions)\nlibrary(jtools)\nlibrary(lmerTest)\n\nMod1 &lt;- lmer(engage ~ 1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c + cohesion.grand.c + pay.grp.c:cohesion.grand.c + (1 + pay.grp.c + autonomy.grp.c + pay.grp.c:autonomy.grp.c|grpid), data = data, control = lmerControl(calc.derivs = FALSE))\nSeveral significant results emerged from these models. Specifically, employee pay was significantly related to individual levels of work engagement b=0.384, t(696)=2.721, p=.007. Additionally, results suggest that for every unit increase in pay, work engagement will increase by a value of 0.384, when autonomy and team cohesion are zero. However, job autonomy was did not moderate the relationship between pay and work engagement, b=0.349, t(696)=1.642, p=.101.\nRegarding the level 2 predictor, team cohesion, results indicate that team cohesion was found to moderate the relationship between pay and work engagement, b=0.535, t(696)=3.218, p=.001.\nGiven the significant interaction, I will now plot the interaction and calculate the simple slopes of this interaction to aid in interpretation.\ninteract_plot(model = Mod1, pred = pay.grp.c, modx = cohesion.grand.c,\nx.label = \"Pay\",\nmain.title = \"Interaction Between Team Cohesion and Pay Predicting Engagement\",\ny.label = \"Engagement\", legend.main = \"Team Cohesion\",\ncolors = c(\"Green\",\"Blue\")) + theme_apa(legend.use.title = T)\n\n\n\nsim_slopes(model = Mod1, pred = pay.grp.c, modx = cohesion.grand.c)\n\nJOHNSON-NEYMAN INTERVAL \n\nWhen cohesion.grand.c is OUTSIDE the interval [-2.10, -0.19], the slope of\npay.grp.c is p &lt; .05.\n\nNote: The range of observed values of cohesion.grand.c is [-2.23, 1.69]\n\nSIMPLE SLOPES ANALYSIS \n\nSlope of pay.grp.c when cohesion.grand.c = -0.83100000291645215177994 (- 1 SD): \n\n   Est.   S.E.   t val.      p\n------- ------ -------- ------\n  -0.06   0.20    -0.31   0.76\n\nSlope of pay.grp.c when cohesion.grand.c =  0.00000000000000001276756 (Mean): \n\n  Est.   S.E.   t val.      p\n------ ------ -------- ------\n  0.38   0.14     2.72   0.01\n\nSlope of pay.grp.c when cohesion.grand.c =  0.83100000291645215177994 (+ 1 SD): \n\n  Est.   S.E.   t val.      p\n------ ------ -------- ------\n  0.83   0.20     4.19   0.00\nThe relationship between pay and work engagement is stronger for individuals with higher levels of team cohesion. The slope for pay will increase by 0.535 with every unit change of team cohesion. In other words, the simple effect of engagement on pay gets strengthened, or more positive, p=.001.\nSimple slopes analysis reveals a significant moderated relationship between pay and engagement when autonomy is at its mean (b=0.38, t=2.72, p=.01) and when autonomy is one standard deviation above its mean (b=0.83, t=4.19, p&lt;.01), but not for those who indicated having levels of autonomy at work that was at least one standard deviation below the mean (b-0.06, t=-0.31, p=.76).\nThe client also collected data on job satisfaction and is interested in knowing if job satisfaction, at the individual level, also interacts with team-level cohesion in predicting work engagement. I also swapped dependent variables to test if pay was a significant predictor of job satisfaction.\nmodel2.1 &lt;- lme(engage ~pay.grp.c, random = ~1 + pay.grp.c|grpid, data = data, control = lmeControl(opt = \"optim\"))\nsummary(model2.1)\n\nLinear mixed-effects model fit by REML\n  Data: data \n       AIC      BIC    logLik\n  3768.164 3795.868 -1878.082\n\nRandom effects:\n Formula: ~1 + pay.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev    Corr  \n(Intercept) 0.2572344 (Intr)\npay.grp.c   0.8923049 0.552 \nResidual    2.8579445       \n\nFixed effects:  engage ~ pay.grp.c \n                Value Std.Error  DF   t-value p-value\n(Intercept) 2.9035266 0.1105163 699 26.272382  0.0000\npay.grp.c   0.4368898 0.1639982 699  2.663991  0.0079\n Correlation: \n          (Intr)\npay.grp.c 0.14  \n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.1116006 -0.6941114 -0.1975845  0.4728133  6.5971460 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n\nmodel2.2 &lt;- lme(jobsat ~ pay.grp.c, random = ~1 + pay.grp.c|grpid, data = data, control = lmeControl(opt = \"optim\"))\nsummary(model2.2)\n\nLinear mixed-effects model fit by REML\n  Data: data \n       AIC      BIC    logLik\n  2168.444 2196.148 -1078.222\n\nRandom effects:\n Formula: ~1 + pay.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev     Corr  \n(Intercept) 0.13429577 (Intr)\npay.grp.c   0.03052776 0.003 \nResidual    1.00544251       \n\nFixed effects:  jobsat ~ pay.grp.c \n                  Value  Std.Error  DF    t-value p-value\n(Intercept) -0.06326777 0.04133513 699 -1.5306053  0.1263\npay.grp.c    0.03569705 0.03633069 699  0.9825591  0.3262\n Correlation: \n          (Intr)\npay.grp.c 0     \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.80428971 -0.67306262  0.02052851  0.70766759  2.69852694 \n\nNumber of Observations: 750\nNumber of Groups: 50 \n\nmodel2.3 &lt;- lme(engage ~ pay.grp.c + jobsat.grp.c, random = ~1 + pay.grp.c + jobsat.grp.c|grpid, data = data,control = lmeControl(opt = \"optim\"))\nsummary(model2.3)\n\nLinear mixed-effects model fit by REML\n  Data: data \n      AIC      BIC    logLik\n  3758.69 3804.851 -1869.345\n\nRandom effects:\n Formula: ~1 + pay.grp.c + jobsat.grp.c | grpid\n Structure: General positive-definite, Log-Cholesky parametrization\n             StdDev    Corr         \n(Intercept)  0.3136581 (Intr) py.gr.\npay.grp.c    0.9135909  0.425       \njobsat.grp.c 0.5947158 -0.321  0.388\nResidual     2.7700579              \n\nFixed effects:  engage ~ pay.grp.c + jobsat.grp.c \n                 Value Std.Error  DF   t-value p-value\n(Intercept)  2.9035266 0.1104472 698 26.288815  0.0000\npay.grp.c    0.4211243 0.1653490 698  2.546882  0.0111\njobsat.grp.c 0.3767563 0.1374256 698  2.741530  0.0063\n Correlation: \n             (Intr) py.gr.\npay.grp.c     0.133       \njobsat.grp.c -0.079  0.175\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.1932653 -0.6760609 -0.1646372  0.4790537  6.6411560 \n\nNumber of Observations: 750\nNumber of Groups: 50\nWhile both pay (b=0.421, t(698)=2.547, p=.011) and job satisfaction (b=0.377, t(698)=2.742, p=.006) significantly predicted work engagement, pay was not a significant predictor of job satisfaction (b=0.036, t(699)=.983, p=.326).\nNow that I have determined which variables predict engagement, the question still remains of how strong these effects are. Given the multilevel nature of this data, I will analyze the ICC1 values which tells me the proportion of individual ratings that are due to group membership. I will also look at ICC2 values to establish the stability of mean ratings in discriminating between groups (participants are grouped by their work teams).\nmult.icc(data[, c(\"jobsat\", \"jobauto\")], data$grpid)\n\n  Variable       ICC1      ICC2\n1   jobsat 0.01743368 0.2102011\n2  jobauto 0.01826727 0.2182050\nICC1 for both job satisfaction (ICC1=.017) and autonomy (ICC1=.018), both of which would be considered “small” effects. The proportion of variance in ratings that is due to between-target differences is small, suggesting that individuals rating are only slightly attributable to group membership.\nThe ICC2 for job satisfaction (ICC2=.210) is larger than the ICC2 for autonomy (ICC2=.218), suggesting that the groups’ mean ratings were more stable and reliable for ratings of autonomy than for ratings of job satisfaction. In other words, the mean ratings of autonomy were better able to distinguish between groups than the mean ratings of job satisfaction.\nWhen looking at the data, I noticed that the commitment scale was created by aggregating three commitment items into an overall scale. To double-check that employees tended to rate similarly across the three items (i.e., an individual rating a score of 4 on the first commitment item would likely rate similarly for commitment items 2 & 3) and that it is appropriate to use an aggregate commitment scale, I will assess inter-rater agreement. Note: rwg is the symbol used to denote this form of inter-rater agreement and will be utilized in the code and interpretation below.\nrwg.commit1.un = rwg(data$commitment1, data$grpid, ranvar = 2.00)\nsummary(rwg.commit1.un)\n\n    grpid                rwg             gsize   \n Length:50          Min.   :0.0000   Min.   :15  \n Class :character   1st Qu.:0.2345   1st Qu.:15  \n Mode  :character   Median :0.4333   Median :15  \n                    Mean   :0.3962   Mean   :15  \n                    3rd Qu.:0.5571   3rd Qu.:15  \n                    Max.   :0.7952   Max.   :15  \n\nhist(rwg.commit1.un$rwg, xlab = \"Estimate of rwg\", ylab = \"Frequency\", main = \"Histogram of 1st Commitment Item's rwg Values\")\n\n\n\nrwgj.commit.un = rwg.j(data[, c(8:10)], data$grpid, ranvar = 2.00)\nsummary(rwgj.commit.un)\n\n    grpid               rwg.j            gsize   \n Length:50          Min.   :0.0000   Min.   :15  \n Class :character   1st Qu.:0.5202   1st Qu.:15  \n Mode  :character   Median :0.6825   Median :15  \n                    Mean   :0.6040   Mean   :15  \n                    3rd Qu.:0.7884   3rd Qu.:15  \n                    Max.   :0.8996   Max.   :15  \n\nhist(rwgj.commit.un$rwg, xlab = \"Estimate of rwg\", ylab = \"Frequency\", main = \"Histogram of Commitment Scale's rwg Values\")\nThe mean rwg value for the first commitment item is 0.396 and the median is .433. Since this value is below the standard cutoff of .70, it is apparent that raters had low levels of agreement for the first commitment item. The mean rwg.j value for the commitment scale is .604 and the median is .683. While still below the cutoff score of .70 for high inter-rater agreement, the agreement level did increase when all three commitment items were considered, as compared to a single commitment item, helping support the usability of the composite score over a particular commitment item."
  },
  {
    "objectID": "Portfolio pages/MLMEngageTeam.html#preparing-data-for-model-building",
    "href": "Portfolio pages/MLMEngageTeam.html#preparing-data-for-model-building",
    "title": "Using Multilevel Modeling To Understand Engagement, Autonomy, and Team Cohesion",
    "section": "Preparing Data for Model Building",
    "text": "Preparing Data for Model Building"
  },
  {
    "objectID": "Portfolio pages/Repeated Measures.html#post-hoc-tests",
    "href": "Portfolio pages/Repeated Measures.html#post-hoc-tests",
    "title": "Does Birth Order Impact SAT Scores?",
    "section": "Post Hoc Tests",
    "text": "Post Hoc Tests"
  },
  {
    "objectID": "Portfolio pages/BWRepeart.html#marginal-means",
    "href": "Portfolio pages/BWRepeart.html#marginal-means",
    "title": "Between and Within Repeated Measures ANOVA in R",
    "section": "Marginal Means",
    "text": "Marginal Means"
  },
  {
    "objectID": "Portfolio pages/Engagement and Diversity.html#factorial-anova",
    "href": "Portfolio pages/Engagement and Diversity.html#factorial-anova",
    "title": "Engagement and Diversity",
    "section": "Factorial ANOVA",
    "text": "Factorial ANOVA"
  },
  {
    "objectID": "Portfolio pages/FactorPower.html#simple-effects",
    "href": "Portfolio pages/FactorPower.html#simple-effects",
    "title": "Factorial Anova and Power Analysis in R",
    "section": "Simple Effects",
    "text": "Simple Effects"
  },
  {
    "objectID": "Portfolio pages/FactorPower.html#effect-sizes",
    "href": "Portfolio pages/FactorPower.html#effect-sizes",
    "title": "Factorial Anova and Power Analysis in R",
    "section": "Effect Sizes",
    "text": "Effect Sizes"
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Matthew Swanson, Ph.D.",
    "section": "Featured Projects",
    "text": "Featured Projects"
  }
]